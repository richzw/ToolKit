- [Introduction to Retrieval Augmented Generation (RAG)](https://weaviate.io/blog/introduction-to-rag)
  - [Advanced RAG Techniques](https://weaviate.io/blog/advanced-rag)
  - [The Ultimate Guide to RAGs â€” Each Component Dissected](https://towardsdatascience.com/the-ultimate-guide-to-rags-each-component-dissected-3cd51c4c0212)
  - [RAG 2.0]()
    - åŸºç¡€æ£€ç´¢ç”Ÿæˆï¼ˆNaive RAGï¼‰â†’ æ£€ç´¢å…¨æµç¨‹ä¼˜åŒ–ï¼ˆAdvanced RAGï¼‰â†’ å…·å¤‡åæ€èƒ½åŠ›çš„æ¨¡å—åŒ–ç³»ç»Ÿï¼ˆModular RAGï¼‰
    - å…¨æ–‡æœç´¢ with BM25Â +Â ç¨ å¯†å‘é‡ï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰Â +Â ç¨€ç–å‘é‡ï¼ˆå…³é”®è¯å¢å¼ºï¼‰
- [RAGé€Ÿé€š](https://mp.weixin.qq.com/s/11NcuacIALFWcAtQ9rWaMA)
  - RAGä¼˜åŒ–æ ¸å¿ƒç­–ç•¥ä¸»è¦åŸºäºInformation Retrievalçš„2-stageç»å…¸æ€è·¯å±•å¼€ï¼šå³åŒæ—¶ä¿è¯é«˜å¬å›ç‡å’Œç²¾åº¦
    - ç¬¬ä¸€é˜¶æ®µï¼šæœ€å¤§åŒ–å¬å›ç‡(High Recall)ï¼ŒåŒæ—¶æ¥å—è¾ƒä½çš„ç²¾åº¦( Low Precision)ã€‚æ­¤é˜¶æ®µæ¶µç›–RAGçš„Indexingå’ŒRetrievaléƒ¨åˆ†
    - ç¬¬äºŒé˜¶æ®µï¼šæå‡ç²¾åº¦ï¼ˆHigher Precisionï¼‰ã€‚æ­¤é˜¶æ®µç”±æ–°å¢çš„Rerankingéƒ¨åˆ†æ„æˆï¼Œå…¶ç›®çš„æ˜¯åœ¨åˆ‡ç‰‡æ–‡æ¡£è¢«è·å–åè¿›è¡Œâ€œPostprocessingâ€ï¼Œä»¥æå‡Top_Kçš„ç²¾åº¦ï¼Œé™ä½é€å¾€å¤§æ¨¡å‹æ–‡æ¡£åˆ‡ç‰‡çš„å™ªå£°
  - ä¾æ®å®é™…ä¸šåŠ¡éœ€æ±‚å˜æ¸…ä¼˜åŒ–ç›®æ ‡ï¼Œæ˜ç¡®è¦åœ¨å“ªä¸€ä¸ªæˆ–è€…å¤šä¸ªéƒ¨åˆ†å®ç°ä¼˜åŒ–ã€‚Recallingã€Indexingå’ŒRerankingä¸‰éƒ¨åˆ†ä¼˜åŒ–ç›®æ ‡åˆ†åˆ«å¦‚ä¸‹ï¼š
    - Recallingçš„ç›®æ ‡æ˜¯å®Œå–„Queryä»¥å–å¾—æ›´é«˜çš„å¬å›ç‡ï¼›
    - Indexingçš„ä¼˜åŒ–ç›®æ ‡æ˜¯åœ¨æå‡å¬å›ç‡çš„åŒæ—¶ä¿è¯è¯­ä¹‰å®Œæ•´æ€§ï¼›
    - Rerankingçš„ä¼˜åŒ–ç›®æ ‡æ˜¯ä¿è¯Top_Kçš„ç²¾åº¦ã€‚
      -  bge-reranker
  - Question Transformationæ˜¯é€šè¿‡æ”¹å†™ã€æ‹“å±•å’Œä¸°å¯Œé—®é¢˜çš„è¯­ä¹‰ä»¥æå‡å¬å›ç‡ã€‚å½“å‰æ¯”è¾ƒæµè¡Œçš„æ–¹æ¡ˆåŒ…æ‹¬ï¼š
    - Rewrite-Retrieve-Readï¼šä½¿ç”¨å¤§æ¨¡å‹æ”¹å†™é—®é¢˜ï¼›
    - Step Back promptingï¼šä½¿ç”¨å¤§æ¨¡å‹äº§ç”Ÿé—®é¢˜çš„â€œStep-back Questionâ€ï¼Œå¹¶å°†é—®é¢˜å’ŒStep-backä¸€åŒç”¨äºå¬å›ï¼›
    - Follow Up Questionsï¼šå°†å†å²å¯¹è¯è®°å½•èå…¥å½“å‰é—®é¢˜è¿›è¡Œå¬å›ï¼›
    - Multi Query Retrievalï¼šä½¿ç”¨å¤§æ¨¡å‹åŸºäºåŸå§‹é—®é¢˜ï¼Œä»ä¸åŒè§’åº¦äº§ç”Ÿå¤šä¸ªæ–°é—®é¢˜ï¼Œå¹¶ä½¿ç”¨æ¯ä¸€ä¸ªæ–°é—®é¢˜è¿›è¡Œå¬å›ï¼›
    - HyDEï¼šä½¿ç”¨å¤§æ¨¡å‹äº§ç”Ÿé—®é¢˜çš„Hypotheticalç­”æ¡ˆï¼Œå¹¶å°†é—®é¢˜å’Œç­”æ¡ˆä¸€åŒç”¨äºå¬å›ã€‚
  - RAG-Fusion ç»“åˆMulti Query Retrieval å’ŒåŸºäºReciprocal Rank Fusion (RRFï¼‰ç®—æ³•çš„Rerankerï¼Œé€šè¿‡äº§ç”Ÿå¤šä¸ªé—®é¢˜å˜ç§ã€è¿›è¡Œå¤šæ¬¡å¬å›ï¼Œå†ç”¨RRFç®—æ³•è¿›è¡Œåˆå¹¶å’Œæ’åºæ¥æå‡å¬å›ç‡å’Œç²¾åº¦ã€‚
  - Hybrid Search åŒæ—¶æ‰§è¡ŒKeyword Searchå’ŒVector Searchï¼Œå¹¶ä½¿ç”¨RRFç®—æ³•åˆå¹¶ã€å¹¶é‡æ’ä¸¤ç§ä¸åŒæ£€ç´¢çš„ç»“æœ
  - Small-to-Bigé‡‡ç”¨åˆ†ç¦»ç´¢å¼•å’Œå†…å®¹çš„æ–¹å¼ä»¥æå‡Vector Searchçš„å®Œæ•´æ€§ é€šå¸¸é€šè¿‡ä¸€å°æ®µç´¢å¼•ï¼ˆèŠ‚ç‚¹ï¼‰å…³è”åˆ°ä¸€å¤§å—å®Œæ•´çš„åˆ‡ç‰‡ï¼Œä»¥å°åˆ‡ç‰‡æœç´¢çš„ç²¾ç¡®åº¦é©±åŠ¨å¤§åˆ‡ç‰‡å†…å®¹çš„å®Œæ•´æ€§ã€‚
    - Sentence-window retrievalï¼šç´¢å¼•å¥å­ï¼Œå…³è”åˆ°å¥å­çš„ä¸Šä¸‹æ–‡ï¼›
    - Auto-merging retrievalï¼šé€šè¿‡å­èŠ‚ç‚¹é€’å½’å…³è”çˆ¶èŠ‚ç‚¹ï¼›
    - Multiple-Vector Retrieverï¼šé€šè¿‡åˆ‡ç‰‡çš„Summaryï¼Œæ‰¾åˆ°å­˜å‚¨åœ¨Doc Storeä¸­çš„åˆ‡ç‰‡åŸæ–‡ã€‚
- [LLM å›ç­”æ›´åŠ å‡†ç¡®çš„ç§˜å¯†ï¼šä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ·»åŠ å¼•ç”¨æº](https://mp.weixin.qq.com/s/I01YcEs_dV8fkSD-HaQQxg)
  - RAG çš„å‡ºç°é‡ç‚¹è§£å†³äº†ç°æœ‰å¤§æ¨¡å‹çš„ä¸‰ä¸ªæŒ‘æˆ˜ï¼š
    - å¹»è§‰é—®é¢˜ï¼šç”Ÿæˆå†…å®¹ä¸æ­£ç¡®ï¼Œä¸äº‹å®ä¸ç¬¦ï¼Œç”šè‡³è’è°¬
    - å®æ—¶é—®é¢˜ï¼šæ— æ³•ç»™å‡ºæ—¶æ•ˆæ€§è¾ƒå¼ºé—®é¢˜çš„ç­”æ¡ˆï¼Œæˆ–è€…ç»™å‡ºé”™è¯¯ç­”æ¡ˆ
    - ç§åŸŸæ•°æ®é—®é¢˜ï¼šä¼ä¸šç§åŸŸæ•°æ®å› ä¸ºåˆè§„ç­‰é—®é¢˜æ— æ³•åœ¨å…¬ç½‘ä½œä¸ºå¤§æ¨¡å‹çš„è®­ç»ƒæ•°æ®
  - ä¸šç•Œæœ‰ä¸¤ç§ä¸»è¦è§£å†³æ–¹æ³•ï¼šå¾®è°ƒå’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰
    - å¾®è°ƒçš„æˆæœ¬æ›´é«˜ï¼Œéœ€è¦ä½¿ç”¨çš„æ•°æ®ä¹Ÿæ›´å¤šï¼Œå¹¶ä¸”æ¯ä¸€æ¬¡ fine-tune çš„æ—¶é—´æ¯”è¾ƒä¹…ï¼Œä¼ä¸šæ— æ³•ç»å¸¸å»åšè¿™ä¸ªäº‹æƒ…ï¼Œå› ä¸ºå®ƒçš„ cost éå¸¸é«˜. å› æ­¤ä¸»è¦é€‚ç”¨äºé£æ ¼è¿ç§»ï¼ˆstyle transferï¼‰çš„åœºæ™¯
    - RAG æ–¹æ³•ä½¿ç”¨ä¾‹å¦‚ Milvus ä¹‹ç±»çš„å‘é‡æ•°æ®åº“ï¼Œä»è€Œå°†çŸ¥è¯†å’Œæ•°æ®æ³¨å…¥åˆ°åº”ç”¨ä¸­ï¼Œæ›´é€‚ç”¨äºé€šç”¨åœºæ™¯
    - RAG æ–¹æ³•å°±æ„å‘³ç€ä½¿ç”¨å‘é‡æ•°æ®åº“å­˜å‚¨çœŸç†æ•°æ®ï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿åº”ç”¨è¿”å›æ­£ç¡®çš„ä¿¡æ¯å’ŒçŸ¥è¯†ï¼Œè€Œä¸æ˜¯åœ¨ç¼ºä¹æ•°æ®æ—¶äº§ç”Ÿå¹»è§‰ï¼Œæé€ å›ç­”
    - [Fine-Tuning vs. Retrieval-Augmented Generation](https://neo4j.com/developer-blog/fine-tuning-vs-rag/)
  - åœ¨LLMå¼€å‘é¢†åŸŸï¼Œæœ‰RAGï¼ŒMRKLï¼ŒRe-Actï¼ŒPlan-Executeç­‰æ¨¡å¼
  - å¤§æ¨¡å‹çš„å†…åœ¨åŸºå› 
    - åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬æ ¹æ®è§£å†³é—®é¢˜æ–¹æ³•ä¸åŒå°†æ¨¡å‹åˆ†ä¸ºä¸¤ç±»ï¼Œç”Ÿæˆå¼å’Œåˆ¤åˆ«å¼
    - åˆ¤åˆ«å¼æ˜¯ç›´æ¥å¯»æ‰¾P(y|x),å³yåœ¨xæ¡ä»¶ä¸‹çš„æ¦‚ç‡ï¼Œæ‰¾åˆ°å†³ç­–è¾¹ç•Œï¼Œå³æ ¹æ®xæ¥åˆ¤åˆ«yï¼Œæ•…å«åšåˆ¤åˆ«å¼
    - é¦–å…ˆä¼šç”ŸæˆP(x,y)çš„è”åˆåˆ†å¸ƒï¼Œå³è¯¥ç±»åˆ«å›ºæœ‰çš„æ•°å­¦åˆ†å¸ƒæ˜¯ä»€ä¹ˆæ ·çš„ï¼Œç„¶åç»§è€Œæ¨ç®—P(y|(x,y))ï¼Œè€Œyæœ¬èº«å°±æ˜¯è¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒç”Ÿæˆçš„ï¼Œæ‰€ä»¥å«åšç”Ÿæˆå¼ã€‚
  - RAG
    - ç¬¬ä¸€æ­¥æ˜¯ç”¨æˆ·å‘chatbotï¼ˆå³LLMåº”ç”¨ï¼‰æå‡ºé—®é¢˜ï¼Œ
    - ç¬¬äºŒæ­¥åŸºäºé—®é¢˜åœ¨æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³é—®é¢˜ï¼Œ
    - ç¬¬ä¸‰æ­¥ï¼Œå°†æ£€ç´¢ç»“æœtop nçš„æ•°æ®ä¼ ç»™chatbotï¼ŒchatbotåŸºäºç”¨æˆ·é—®é¢˜ä»¥åŠæ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯è¿›è¡Œåˆå¹¶å½¢æˆæœ€ç»ˆçš„promptï¼Œ
    - ç¬¬å››æ­¥ï¼Œå°†promptæäº¤ç»™å¤§æ¨¡å‹ï¼Œ
    - ç¬¬äº”æ­¥ï¼Œå¤§æ¨¡å‹äº§ç”Ÿè¾“å‡ºè¿”å›ç»™chatbotï¼Œè¿›è€Œè¿”å›ç»™ç”¨æˆ·ã€‚
    - ![img.png](ml_rag_pipeline.png)
  - å¥½å¤„
    - å®ƒèƒ½å¤ŸåŸºäºè¿™ç§æ¨¡å¼ï¼Œå°½é‡å‡å°‘å¤§æ¨¡å‹å¹»è§‰å¸¦æ¥çš„é—®é¢˜ã€‚
    - å®ƒå‡å°‘äº†ä¸ºäº†å¾®è°ƒè€Œå‡†å¤‡é—®ç­”å¯¹ï¼ˆå¸¦æ ‡è®°çš„æ ·æœ¬æ•°æ®ï¼‰ï¼Œå¤§å¤§å‡å°‘äº†å¤æ‚åº¦ã€‚
    - promptçš„æ„é€ è¿‡ç¨‹ï¼Œç»™äº†æˆ‘ä»¬å¾ˆå¤§çš„æ“ä½œç©ºé—´ï¼Œå¯¹äºæˆ‘ä»¬åç»­å¹²é¢„æ¨¡å‹æ•ˆæœï¼Œå®Œæˆç‰¹å®šä¸šåŠ¡éœ€æ±‚æä¾›äº†å¿…è¦çš„æ‰‹æ®µã€‚
- [MutiVector Retrieveræ”¯æŒRAGæ¶æ„ä¸‹è¡¨æ ¼æ–‡å­—æ··åˆå†…å®¹é—®ç­”](https://mp.weixin.qq.com/s/Rxwee3Hd-j1xcBqnW8PRDg)
  - 1ï¼‰åˆ©ç”¨ Unstructuredåº“æ¥è§£æpdfæ–‡æ¡£ä¸­çš„æ–‡æœ¬å’Œè¡¨æ ¼ã€‚
    - æŠ€æœ¯éš¾ç‚¹
      - PDF æ–‡ä»¶ä¸­çš„è¡¨æ ¼å¯èƒ½é‡‡ç”¨ä¸åŒçš„ç¼–ç å’Œå­—ä½“ï¼Œç”šè‡³ä»¥å›¾åƒå½¢å¼å­˜åœ¨ï¼Œéœ€è¦ä½¿ç”¨ OCR æŠ€æœ¯æ¥è¯†åˆ«ï¼Œè€Œå›¾åƒè´¨é‡å’Œå­—ä½“æ¨¡ç³Šå¯èƒ½å½±å“è¯†åˆ«çš„å‡†ç¡®æ€§
      - PDF æ–‡ä»¶ä¸­çš„è¡¨æ ¼å…·æœ‰å¤æ‚çš„æ ¼å¼å’Œå¸ƒå±€ï¼ŒåŒ…æ‹¬åˆå¹¶å•å…ƒæ ¼ã€åµŒå¥—è¡¨æ ¼å’Œå¤šåˆ—å¸ƒå±€ï¼Œä½¿å¾—è¯†åˆ«å’Œæå–è¡¨æ ¼æ•°æ®å˜å¾—å¤æ‚
    - Nougat æ–¹æ¡ˆ
      -  Meta å…¬å¸å¼€å‘çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å·¥å…·åŒ…ï¼Œæ—¨åœ¨ç®€åŒ–å¤šè¯­è¨€æ–‡æœ¬æ•°æ®çš„å¤„ç†å’Œåˆ†æ pip install nougata-ocr
      - Nougat æ˜¯ç”¨å­¦æœ¯è®ºæ–‡è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹ï¼Œå› æ­¤å¯¹å­¦æœ¯è®ºæ–‡æ–‡æ¡£è§£ææ•ˆæœå¾ˆå¥½ï¼Œä½†å…¶ä»–ç±»å‹çš„ PDF æ–‡æ¡£è§£ææ•ˆæœå¯èƒ½ä¸å°½äººæ„. éœ€è¦ GPU æœºå™¨è¿›è¡Œè§£æåŠ é€Ÿ
    - UnstructuredIO æ–¹æ¡ˆ
      - å…ˆå°† PDF æ–‡ä»¶è½¬æ¢æˆ HTML æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨ UnstructuredIO æ¥è§£æ HTML æ–‡ä»¶ï¼ŒLlamaIndex å·²ç»å¯¹ UnstructuredIO è¿›è¡Œäº†é›†æˆ. LlamaIndex åœ¨é›†æˆ UnstructuredIO æ—¶åªå®ç°äº†å¯¹ HTML æ–‡ä»¶çš„è§£æ
      - from llama_index.core.node_parser import UnstructuredElementNodeParser
      - æ— éœ€ä½¿ç”¨ OCR æŠ€æœ¯ æ— éœ€ä½¿ç”¨ GPU æœåŠ¡å™¨è¿›è¡Œæ¥è½¬æ¢ PDF æ–‡ä»¶
      - éœ€è¦ä½¿ç”¨ç¬¬ä¸‰æ–¹å·¥å…·å°† PDF æ–‡ä»¶è½¬æ¢ä¸º HTML æ–‡ä»¶ï¼Œ ç”¨æˆ·é—®é¢˜è¦ä¸è¡¨æ ¼çš„æ€»ç»“ä¿¡æ¯åŒ¹é…æ‰èƒ½è·å¾—æ­£ç¡®çš„æ£€ç´¢ç»“æœ
    - GPT4o
      - LlamaIndex çš„ LlamaParse å·¥å…·å·²ç»å¯¹ GPT4o è¿›è¡Œäº†é›†æˆï¼Œå¯ä»¥å°† PDF æ–‡ä»¶è½¬æ¢æˆ Markdown æ ¼å¼çš„å†…å®¹
      - å¯ä»¥ç›´æ¥è§£æ PDF æ–‡ä»¶ï¼Œæ— éœ€è½¬æ¢æˆå…¶ä»–æ ¼å¼çš„æ–‡ä»¶ ä¸ç®¡æ–‡ä»¶ä¸­çš„å†…å®¹æ˜¯æ–‡å­—è¿˜æ˜¯å›¾ç‰‡ï¼Œéƒ½å¯ä»¥è¿›è¡Œè§£æ
      - LlamaParse è™½ç„¶æ¯å¤©æœ‰å…è´¹çš„è°ƒç”¨æ¬¡æ•°ï¼Œä½†æ˜¯å¦‚æœéœ€è¦å¤§é‡è°ƒç”¨ï¼Œè¿˜æ˜¯éœ€è¦ä»˜è´¹ ç›®å‰ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹è§£æ PDF æ–‡ä»¶çš„å‡†ç¡®ç‡è¿˜æ˜¯æ¯”è¾ƒä½
  - 2ï¼‰åˆ©ç”¨multi_vectoræ¥å­˜å‚¨æ›´é€‚åˆæ£€ç´¢çš„åŸå§‹è¡¨ã€æ–‡æœ¬ä»¥åŠè¡¨æ‘˜è¦ã€‚
  - 3ï¼‰åˆ©ç”¨LangChain Expression Language (LCEL)æ¥å®ç°chainã€‚
- [æ”¹è¿›å¬å›ï¼ˆRetrievalï¼‰å’Œå¼•å…¥é‡æ’ï¼ˆRerankingï¼‰æå‡RAGæ¶æ„ä¸‹çš„LLMåº”ç”¨æ•ˆæœ]
  - RAGæ¶æ„å¾ˆå¥½çš„è§£å†³äº†å½“å‰å¤§æ¨¡å‹Prompt learningè¿‡ç¨‹ä¸­context windowé™åˆ¶ç­‰é—®é¢˜
  - Issue
    - ä»¥RAGå¬å›ä¸ºä¾‹ï¼Œæœ€åŸå§‹çš„åšæ³•æ˜¯é€šè¿‡top-kçš„æ–¹å¼ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢èƒŒæ™¯æ•°æ®ç„¶åç›´æ¥æäº¤ç»™LLMå»ç”Ÿæˆç­”æ¡ˆï¼Œä½†è¿™æ ·å­˜åœ¨æ£€ç´¢å‡ºæ¥çš„chunkså¹¶ä¸ä¸€å®šå®Œå…¨å’Œä¸Šä¸‹æ–‡ç›¸å…³çš„é—®é¢˜ï¼Œæœ€åå¯¼è‡´å¤§æ¨¡å‹ç”Ÿæˆçš„ç»“æœè´¨é‡ä¸ä½³
  - Solution
    - å€Ÿé‰´æ¨èç³»ç»Ÿåšæ³•ï¼Œå¼•å…¥ç²—æ’æˆ–é‡æ’çš„æ­¥éª¤æ¥æ”¹è¿›æ•ˆæœ
    - åŸæœ‰çš„top-kå‘é‡æ£€ç´¢å¬å›æ‰©å¤§å¬å›æ•°ç›®ï¼Œå†å¼•å…¥ç²—æ’æ¨¡å‹ï¼Œè¿™é‡Œçš„æ¨¡å‹å¯ä»¥æ˜¯ç­–ç•¥ï¼Œè½»é‡çº§çš„å°æ¨¡å‹ï¼Œæˆ–è€…æ˜¯LLMï¼Œå¯¹å¬å›ç»“æœç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œé‡æ’ï¼Œé€šè¿‡è¿™æ ·çš„æ”¹è¿›æ¨¡å¼å¯ä»¥æœ‰æ•ˆæå‡RAGçš„æ•ˆæœã€‚
    - åŸºäºLLMçš„å¬å›æˆ–é‡æ’
      - åœ¨é€»è¾‘æ¦‚å¿µä¸Šï¼Œè¿™ç§æ–¹æ³•ä½¿ç”¨ LLM æ¥å†³å®šå“ªäº›æ–‡æ¡£/æ–‡æœ¬å—ä¸ç»™å®šæŸ¥è¯¢ç›¸å…³ã€‚promptç”±ä¸€ç»„å€™é€‰æ–‡æ¡£ç»„æˆï¼Œè¿™æ—¶LLM çš„ä»»åŠ¡æ˜¯é€‰æ‹©ç›¸å…³çš„æ–‡æ¡£é›†ï¼Œå¹¶ç”¨å†…éƒ¨æŒ‡æ ‡å¯¹å…¶ç›¸å…³æ€§è¿›è¡Œè¯„åˆ†ã€‚
      - ä¸ºäº†é¿å…å› ä¸ºå¤§æ–‡æ¡£chunkåŒ–å¸¦æ¥çš„å†…å®¹åˆ†è£‚ï¼Œåœ¨å»ºåº“é˜¶æ®µä¹Ÿå¯åšäº†ä¸€å®šä¼˜åŒ–ï¼Œåˆ©ç”¨summary indexå¯¹å¤§æ–‡æ¡£è¿›è¡Œç´¢å¼•ã€‚
      - llama-indexæä¾›äº†ä¸¤ç§å½¢å¼çš„æŠ½è±¡ï¼šä½œä¸ºç‹¬ç«‹çš„æ£€ç´¢æ¨¡å—ï¼ˆListIndexLLMRetrieverï¼‰æˆ–é‡æ’æ¨¡å—ï¼ˆLLMRerankï¼‰ã€‚
    - åŸºäºç›¸å¯¹è½»é‡çš„æ¨¡å‹å’Œç®—æ³•
- [å¼•å…¥å…ƒæ•°æ®(metadata)æå‡RAG](https://mp.weixin.qq.com/s/b8cMhdqSyC7O275GTLb4aQ)
  - å¦‚æœæ‰€æœ‰ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£æ”¾åˆ°ä¸€ä¸ªcollection æ˜¯å¯ä»¥è®¾ç½®field ä¸ºç”¨æˆ·idç­‰æ ‡è¯†, ç„¶åé€šè¿‡langcchainå°è£…çš„milvusé‡Œé¢çš„å‚æ•° search_params æ¥ç­›é€‰å‡ºæ¥  è€ƒè™‘å»ºä¸¤ä¸ªcollectionï¼Œpublic å’Œ individual, ç„¶åæ ¹æ®ç”¨æˆ·é‰´æƒåˆ¤å®šæŸ¥è¯¢çš„collection
- [æ•°æ®é¢„å¤„ç†ä¹‹â€”â€”â€œå±€éƒ¨å‘é‡åŒ–å¤„ç†â€çš„å¦™ç”¨](https://mp.weixin.qq.com/s/rBKsfUwokp3jZss6do7YRg?from=groupmessage&isappinstalled=0&scene=1&clicktime=1695784465&enterid=1695784465)
  - æ–‡æ¡£å†…å®¹embedding
    - å¦‚ä½ æŠŠåˆ‡å‰²åçš„embeddingåšä¸€éç›¸ä¼¼åº¦å¯¹æ¯”ï¼Œåƒå†’æ³¡ä¸€æ ·å»çœ‹çœ‹æ•ˆæœ
    - QA botå†·å¯åŠ¨çš„ vector store è´¨é‡å¾ˆå…³é”®, è´¨é‡æ¯”è¾ƒé«˜çš„è¯ï¼Œåé¢ä½ æ‰èƒ½ä»ç”¨æˆ·è¾“å…¥å’Œç­”æ¡ˆé‡Œé¢ï¼Œæ‰¾ä¸€äº›ä¸é”™çš„æ·»åŠ åˆ°åº“ä¸­
  - Issue
    - åŸå§‹èµ„æ–™ä¿¡æ¯é‡å¤ªå¤§ï¼Œç¢°å·§è§¦å‘çš„ç›¸ä¼¼æˆåˆ†æ¯”è¾ƒå¤šï¼Œé‚£ä¹ˆç”Ÿæˆçš„æç¤ºå¢å¼ºä¿¡æ¯ä¹Ÿä¼šä¸€æ‰¯ä¸€ç®©ç­ã€‚
    - æš´åŠ›è¾“å‡ºç»™åˆ°å¤§æ¨¡å‹çš„å¢å¼ºPromptå¤ªé•¿ï¼ˆè¾“å…¥å’Œè¾“å‡ºéƒ½ä¼šæ¶ˆè€—Tokenï¼‰ï¼Œé€ æˆå“åº”æ…¢ã€è´¹Tokenã€å‡†ç¡®æ€§å¤§æ‰“æŠ˜æ‰£çš„åæœ
    - é¢å¯¹é«˜åº¦å‚ç›´çš„ä»»åŠ¡ç±»å‹æ—¶ï¼Œâ€œå±€éƒ¨å‘é‡åŒ–å¤„ç†â€ä¹Ÿèƒ½è·å¾—ä¸é”™çš„æ•ˆæœ
      - å‰æï¼šåšå¥½ç§‘å­¦çš„æ–‡æœ¬åˆ†å‰²ï¼ŒæŒ‰ç…§ä¸é‡ä¸æ¼(MECEï¼‰çš„åŸåˆ™ï¼Œåˆ†é—¨åˆ«ç±»ã€ä»¥åˆç†çš„é¢—ç²’åº¦å»ºç«‹ç›®å½•ç»“æ„
- [Milvus + Towhee æ­å»ºä¸€ä¸ªåŸºç¡€çš„ AI èŠå¤©æœºå™¨äºº](https://gist.github.com/egoebelbecker/07059b88a1c4daa96ec07937f8ca77b3)
- [æŒ‡ä»£æ¶ˆè§£](https://mp.weixin.qq.com/s/QYSdrMO6dGRy9_czCgqcKQ)
- [æ–‡æœ¬åˆ†å—(Chunking)](https://mp.weixin.qq.com/s?__biz=MzIyOTA5NTM1OA==&mid=2247484262&idx=1&sn=430270e10268c4b97c3b5d983fdfb75b&chksm=e846a1b7df3128a139091d31e4793e2fdcb391da2e866cd914d0f0ecf38ce2d9f285d78c9a03&scene=21#wechat_redirect)
  - åˆ†å—ï¼ˆchunkingï¼‰æ˜¯å°†å¤§å—æ–‡æœ¬åˆ†è§£æˆå°æ®µçš„è¿‡ç¨‹ã€‚
    - å½“æˆ‘ä»¬ä½¿ç”¨LLM embeddingå†…å®¹æ—¶ï¼Œè¿™æ˜¯ä¸€é¡¹å¿…è¦çš„æŠ€æœ¯ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¼˜åŒ–ä»å‘é‡æ•°æ®åº“è¢«å¬å›çš„å†…å®¹çš„å‡†ç¡®æ€§ã€‚
    - åˆ†å—çš„ä¸»è¦åŸå› æ˜¯å°½é‡å‡å°‘æˆ‘ä»¬Embeddingå†…å®¹çš„å™ªéŸ³ã€‚
    - å¦‚æœæ–‡æœ¬å—å°½é‡æ˜¯è¯­ä¹‰ç‹¬ç«‹çš„ï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰å¯¹ä¸Šä¸‹æ–‡å¾ˆå¼ºçš„ä¾èµ–ï¼Œè¿™æ ·å­å¯¹è¯­è¨€æ¨¡å‹æ¥è¯´æ˜¯æœ€æ˜“äºç†è§£çš„ã€‚å› æ­¤ï¼Œä¸ºè¯­æ–™åº“ä¸­çš„æ–‡æ¡£æ‰¾åˆ°æœ€ä½³å—å¤§å°å¯¹äºç¡®ä¿æœç´¢ç»“æœçš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§è‡³å…³é‡è¦ã€‚
    - ä¼šè¯Agent æˆ‘ä»¬ä½¿ç”¨embeddingçš„å—ä¸ºåŸºäºçŸ¥è¯†åº“çš„ä¼šè¯agentæ„å»ºä¸Šä¸‹æ–‡ï¼Œè¯¥çŸ¥è¯†åº“å°†ä»£ç†ç½®äºå¯ä¿¡ä¿¡æ¯ä¸­ã€‚å¯¹åˆ†å—ç­–ç•¥åšå‡ºæ­£ç¡®çš„é€‰æ‹©å¾ˆé‡è¦ï¼ŒåŸå› æœ‰
      - é¦–å…ˆï¼Œå®ƒå°†å†³å®šä¸Šä¸‹æ–‡æ˜¯å¦ä¸æˆ‘ä»¬çš„promptç›¸å…³ã€‚
      - å…¶æ¬¡ï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªè¯·æ±‚å‘é€çš„tokensæ•°é‡çš„é™åˆ¶ï¼Œå®ƒå°†å†³å®šæˆ‘ä»¬æ˜¯å¦èƒ½å¤Ÿåœ¨å°†æ£€ç´¢åˆ°çš„æ–‡æœ¬åˆå¹¶åˆ°promptä¸­å‘é€åˆ°å¤§æ¨¡å‹(å¦‚OpenAI)ã€‚
  - Embeddingé•¿çŸ­å†…å®¹
    - å½“æˆ‘ä»¬åœ¨åµŒå…¥å†…å®¹ï¼ˆä¹Ÿå°±æ˜¯embeddingï¼‰æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®å†…å®¹æ˜¯çŸ­ï¼ˆå¦‚å¥å­ï¼‰è¿˜æ˜¯é•¿ï¼ˆå¦‚æ®µè½æˆ–æ•´ä¸ªæ–‡æ¡£ï¼‰æ¥é¢„æµ‹ä¸åŒçš„è¡Œä¸º
    - å½“åµŒå…¥ä¸€ä¸ªå®Œæ•´çš„æ®µè½æˆ–æ–‡æ¡£æ—¶ï¼ŒEmbeddingè¿‡ç¨‹æ—¢è¦è€ƒè™‘æ•´ä¸ªä¸Šä¸‹æ–‡ï¼Œä¹Ÿè¦è€ƒè™‘æ–‡æœ¬ä¸­å¥å­å’ŒçŸ­è¯­ä¹‹é—´çš„å…³ç³»ã€‚è¿™å¯ä»¥äº§ç”Ÿæ›´å…¨é¢çš„å‘é‡è¡¨ç¤ºï¼Œä»è€Œæ•è·æ–‡æœ¬çš„æ›´å¹¿æ³›çš„å«ä¹‰å’Œä¸»é¢˜ã€‚
    - å¦ä¸€æ–¹é¢ï¼Œè¾ƒå¤§çš„è¾“å…¥æ–‡æœ¬å¤§å°å¯èƒ½ä¼šå¼•å…¥å™ªå£°æˆ–æ·¡åŒ–å•ä¸ªå¥å­æˆ–çŸ­è¯­çš„é‡è¦æ€§ï¼Œä»è€Œåœ¨æŸ¥è¯¢ç´¢å¼•æ—¶æ›´éš¾ä»¥æ‰¾åˆ°ç²¾ç¡®çš„åŒ¹é…ã€‚
    - æŸ¥è¯¢çš„é•¿åº¦ä¹Ÿä¼šå½±å“Embeddingsä¹‹é—´çš„å…³ç³»ã€‚è¾ƒçŸ­çš„æŸ¥è¯¢ï¼Œå¦‚å•ä¸ªå¥å­æˆ–çŸ­è¯­ï¼Œå°†ä¸“æ³¨äºç»†èŠ‚ï¼Œå¯èƒ½æ›´é€‚åˆä¸å¥å­çº§Embeddingè¿›è¡ŒåŒ¹é…ã€‚
  - åˆ†å—éœ€è¦è€ƒè™‘çš„å› ç´ 
    - è¢«ç´¢å¼•å†…å®¹çš„æ€§è´¨æ˜¯ä»€ä¹ˆ? è¿™å¯èƒ½å·®åˆ«ä¼šå¾ˆå¤§ï¼Œæ˜¯å¤„ç†è¾ƒé•¿çš„æ–‡æ¡£(å¦‚æ–‡ç« æˆ–ä¹¦ç±)ï¼Œè¿˜æ˜¯å¤„ç†è¾ƒçŸ­çš„å†…å®¹(å¦‚å¾®åšæˆ–å³æ—¶æ¶ˆæ¯)ï¼Ÿç­”æ¡ˆå°†å†³å®šå“ªç§æ¨¡å‹æ›´é€‚åˆæ‚¨çš„ç›®æ ‡ï¼Œä»è€Œå†³å®šåº”ç”¨å“ªç§åˆ†å—ç­–ç•¥ã€‚
    - æ‚¨ä½¿ç”¨çš„æ˜¯å“ªç§Embeddingæ¨¡å‹ï¼Œå®ƒåœ¨å¤šå¤§çš„å—å¤§å°ä¸Šè¡¨ç°æœ€ä½³ï¼Ÿä¾‹å¦‚ï¼Œsentence-transformeræ¨¡å‹åœ¨å•ä¸ªå¥å­ä¸Šå·¥ä½œå¾—å¾ˆå¥½ï¼Œä½†åƒtext- embedt-ada -002~[2]~è¿™æ ·çš„æ¨¡å‹åœ¨åŒ…å«256æˆ–512ä¸ªtokensçš„å—ä¸Šè¡¨ç°å¾—æ›´å¥½ã€‚
    - ä½ å¯¹ç”¨æˆ·æŸ¥è¯¢çš„é•¿åº¦å’Œå¤æ‚æ€§æœ‰ä»€ä¹ˆæœŸæœ›ï¼Ÿç”¨æˆ·è¾“å…¥çš„é—®é¢˜æ–‡æœ¬æ˜¯ç®€çŸ­è€Œå…·ä½“çš„è¿˜æ˜¯å†—é•¿è€Œå¤æ‚çš„ï¼Ÿè¿™ä¹Ÿç›´æ¥å½±å“åˆ°æˆ‘ä»¬é€‰æ‹©åˆ†ç»„å†…å®¹çš„æ–¹å¼ï¼Œä»¥ä¾¿åœ¨åµŒå…¥æŸ¥è¯¢å’ŒåµŒå…¥æ–‡æœ¬å—ä¹‹é—´æœ‰æ›´ç´§å¯†çš„ç›¸å…³æ€§ã€‚
    - å¦‚ä½•åœ¨æ‚¨çš„ç‰¹å®šåº”ç”¨ç¨‹åºä¸­ä½¿ç”¨æ£€ç´¢ç»“æœï¼Ÿ ä¾‹å¦‚ï¼Œå®ƒä»¬æ˜¯å¦ç”¨äºè¯­ä¹‰æœç´¢ã€é—®ç­”ã€æ‘˜è¦æˆ–å…¶ä»–ç›®çš„ï¼Ÿä¾‹å¦‚ï¼Œå’Œä½ åº•å±‚è¿æ¥çš„LLMæ˜¯æœ‰ç›´æ¥å…³ç³»çš„ï¼ŒLLMçš„tokensé™åˆ¶ä¼šè®©ä½ ä¸å¾—ä¸è€ƒè™‘åˆ†å—çš„å¤§å°ã€‚
  - [åˆ†å—çš„æ–¹æ³•](https://stackoverflow.blog/2024/06/06/breaking-up-is-hard-to-do-chunking-in-rag-applications/)
    - å›ºå®šå¤§å°åˆ†å—
      - æˆ‘ä»¬ä¼šåœ¨å—ä¹‹é—´ä¿æŒä¸€äº›é‡å ï¼Œä»¥ç¡®ä¿è¯­ä¹‰ä¸Šä¸‹æ–‡ä¸ä¼šåœ¨å—ä¹‹é—´ä¸¢å¤±ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå›ºå®šå¤§å°çš„åˆ†å—å°†æ˜¯æœ€ä½³æ–¹å¼
    - random chunk sizes
      - his approach can potentially capture a wider variety of semantic contexts and topics without relying on the conventions of any given document type
    - sliding windows
    - adaptive chunking
      - It chunks based on the content of each document. Many adaptive chunking techniques use machine learning themselves to determine the best size for any given chunk and where they overlap
    - Content-Awareï¼šåŸºäºå†…å®¹æ„å›¾åˆ†å—
      - å¥åˆ†å‰²â€”â€”Sentence splitting
        - Naive splitting: æœ€å¹¼ç¨šçš„æ–¹æ³•æ˜¯ç”¨å¥å·(ã€‚) å’Œ â€œæ¢è¡Œâ€æ¥åˆ†å‰²å¥å­
        - NLTK: è‡ªç„¶è¯­è¨€å·¥å…·åŒ…(NLTK)æ˜¯ä¸€ä¸ªæµè¡Œçš„Pythonåº“ï¼Œç”¨äºå¤„ç†è‡ªç„¶è¯­è¨€æ•°æ®ã€‚å®ƒæä¾›äº†ä¸€ä¸ªå¥å­æ ‡è®°å™¨ï¼Œ
        - spaCy: spaCyæ˜¯å¦ä¸€ä¸ªç”¨äºNLPä»»åŠ¡çš„å¼ºå¤§Pythonåº“ã€‚å®ƒæä¾›äº†ä¸€ä¸ªå¤æ‚çš„å¥å­åˆ†å‰²åŠŸèƒ½ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°†æ–‡æœ¬åˆ†æˆå•ç‹¬çš„å¥å­ï¼Œä»è€Œåœ¨ç”Ÿæˆçš„å—ä¸­æ›´å¥½åœ°ä¿å­˜ä¸Šä¸‹æ–‡ã€‚
      - é€’å½’åˆ†å‰²
        - é€’å½’åˆ†å—ä½¿ç”¨ä¸€ç»„åˆ†éš”ç¬¦ä»¥åˆ†å±‚å’Œè¿­ä»£çš„æ–¹å¼å°†è¾“å…¥æ–‡æœ¬åˆ†æˆæ›´å°çš„å—
      - ä¸“é—¨çš„åˆ†å—
        - Markdownå’ŒLaTeXæ˜¯æ‚¨å¯èƒ½é‡åˆ°çš„ç»“æ„åŒ–å’Œæ ¼å¼åŒ–å†…å®¹çš„ä¸¤ä¸ªä¾‹å­ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨ä¸“é—¨çš„åˆ†å—æ–¹æ³•åœ¨åˆ†å—è¿‡ç¨‹ä¸­ä¿ç•™å†…å®¹çš„åŸå§‹ç»“æ„ã€‚
    - Recursive Character Text Splitting 
      - Breaking text into chunks based on character count ensures each piece is manageable and coherent.
    - Small-to-Big Text Splitting 
      - Starting with larger chunks and progressively breaking them down into smaller ones. Search using small, but retrieve using Big.
    - Semantic Text Splitting 
      - Dividing text based on meaning so that each chunk represents a complete idea or topic, ensuring that the context is preserved.
    - ğ—£ğ—¼ğ—½ğ˜‚ğ—¹ğ—®ğ—¿ ğ—°ğ—µğ˜‚ğ—»ğ—¸ğ—¶ğ—»ğ—´ ğ˜ğ—²ğ—°ğ—µğ—»ğ—¶ğ—¾ğ˜‚ğ—²ğ˜€:
      - â†’ ğ—™ğ—¶ğ˜…ğ—²ğ—±-ğ˜€ğ—¶ğ˜‡ğ—² ğ—°ğ—µğ˜‚ğ—»ğ—¸ğ—¶ğ—»ğ—´: https://weaviate.io/learn/knowledgecards/fixed-size-chunking?utm_source=channels&utm_medium=w_social&utm_campaign=rag&utm_content=knowledge_cards_680482650
      - â†’ ğ—¥ğ—²ğ—°ğ˜‚ğ—¿ğ˜€ğ—¶ğ˜ƒğ—² ğ—°ğ—µğ˜‚ğ—»ğ—¸ğ—¶ğ—»ğ—´: https://weaviate.io/learn/knowledgecards/recursive-chunking?utm_source=channels&utm_medium=w_social&utm_campaign=rag&utm_content=knowledge_cards_680986116
      - â†’ ğ——ğ—¼ğ—°ğ˜‚ğ—ºğ—²ğ—»ğ˜-ğ—¯ğ—®ğ˜€ğ—²ğ—± ğ—°ğ—µğ˜‚ğ—»ğ—¸ğ—¶ğ—»ğ—´: https://weaviate.io/learn/knowledgecards/documentbased-chunking?utm_source=channels&utm_medium=w_social&utm_campaign=rag&utm_content=knowledge_cards_680195274
      - â†’ ğ—¦ğ—²ğ—ºğ—®ğ—»ğ˜ğ—¶ğ—° ğ—°ğ—µğ˜‚ğ—»ğ—¸ğ—¶ğ—»ğ—´: https://weaviate.io/learn/knowledgecards/semantic-chunking?utm_source=channels&utm_medium=w_social&utm_campaign=rag&utm_content=knowledge_cards_680092902
      - â†’ ğ—Ÿğ—Ÿğ— -ğ—¯ğ—®ğ˜€ğ—²ğ—± ğ—°ğ—µğ˜‚ğ—»ğ—¸ğ—¶ğ—»ğ—´: https://weaviate.io/learn/knowledgecards/llmbased-chunking?utm_source=channels&utm_medium=w_social&utm_campaign=rag&utm_content=knowledge_cards_680018669
      - â†’ ğ—Ÿğ—®ğ˜ğ—² ğ—°ğ—µğ˜‚ğ—»ğ—¸ğ—¶ğ—»ğ—´: https://weaviate.io/blog/late-chunking?utm_source=channels&utm_medium=w_social&utm_campaign=rag&utm_content=knowledge_cards
      - There's no one-size-fits-all chunking strategy. Your choice depends on:
        - â€¢ Document structure
        - â€¢ Query patterns
        - â€¢ Context window limits
        - â€¢ Performance requirements
  - ç­–ç•¥é€‰æ‹©
    - é¢„å¤„ç†æ•°æ®ï¼Œåœ¨ç¡®å®šåº”ç”¨ç¨‹åºçš„æœ€ä½³å—å¤§å°ä¹‹å‰ï¼Œæ‚¨éœ€è¦å…ˆé¢„å¤„ç†æ•°æ®ä»¥ç¡®ä¿è´¨é‡
    - é€‰æ‹©ä¸€å®šèŒƒå›´çš„å—å¤§å°ï¼Œæ•°æ®é¢„å¤„ç†å®Œæˆåï¼Œä¸‹ä¸€æ­¥å°±æ˜¯é€‰æ‹©ä¸€å®šèŒƒå›´çš„æ½œåœ¨å—å¤§å°è¿›è¡Œæµ‹è¯•
    - è¯„ä¼°æ¯ç§åˆ†å—å¤§å°çš„æ€§èƒ½ï¼Œä¸ºäº†æµ‹è¯•å„ç§åˆ†å—å¤§å°ï¼Œå¯ä»¥åœ¨å‘é‡æ•°æ®åº“ä¸­ä½¿ç”¨å¤šä¸ªç´¢å¼•æˆ–å…·æœ‰å¤šä¸ªå‘½åç©ºé—´çš„å•ä¸ªç´¢å¼•
    - llamaindexç­‰æ¡†æ¶ä¸ºchunkå¢åŠ æè¿°æ€§metadataï¼Œä»¥åŠç²¾å¿ƒè®¾è®¡ç´¢å¼•ç»“æ„ï¼Œæ¯”å¦‚treeindexç­‰ï¼Œè¿›è€Œè§£å†³å› ä¸ºchunkingå¯¼è‡´çš„è·¨chunkçš„ä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜
    - [Chunking for RAG: best practices](https://unstructured.io/blog/chunking-for-rag-best-practices)
      - åŸºæœ¬åˆ†å—ç­–ç•¥ï¼šè¿™ç§æ–¹æ³•å¯ä»¥åœ¨éµå®ˆæœ€å¤§åˆ†å—å¤§å°é™åˆ¶çš„å‰æä¸‹ï¼Œå°†è¿ç»­å…ƒç´ ç»„åˆèµ·æ¥ï¼Œæœ€å¤§é™åº¦åœ°å¡«å……æ¯ä¸ªåˆ†å—ã€‚å¦‚æœå•ä¸ªå­¤ç«‹çš„å…ƒç´ è¶…è¿‡äº†æœ€å¤§ç¡¬é™åˆ¶ï¼Œå°±ä¼šè¢«åˆ†æˆä¸¤ä¸ªæˆ–æ›´å¤šå—ã€‚
      - æŒ‰æ ‡é¢˜åˆ†å—ç­–ç•¥ï¼šè¯¥ç­–ç•¥åˆ©ç”¨åˆ†åŒºè¿‡ç¨‹ä¸­è¯†åˆ«çš„æ–‡æ¡£å…ƒç´ ç±»å‹æ¥ç†è§£æ–‡æ¡£ç»“æ„ï¼Œå¹¶ä¿ç•™ç« èŠ‚è¾¹ç•Œã€‚è¿™å°±æ„å‘³ç€ï¼Œå•ä¸ªæ•°æ®å—æ°¸è¿œä¸ä¼šåŒ…å«å‡ºç°åœ¨ä¸¤ä¸ªä¸åŒç« èŠ‚ä¸­çš„æ–‡æœ¬ï¼Œä»è€Œç¡®ä¿ä¸»é¢˜ä¿æŒè‡ªè¶³ï¼Œæé«˜æ£€ç´¢ç²¾åº¦ã€‚
      - æŒ‰é¡µé¢åˆ†å—ç­–ç•¥ï¼ˆä»…æ”¯æŒAPIè°ƒç”¨ï¼‰ï¼šè¯¥ç­–ç•¥ä¸“ä¸ºæ¯ä¸€é¡µéƒ½èƒ½ä¼ é€’ç‹¬ç‰¹ä¿¡æ¯çš„æ–‡æ¡£è€Œè®¾è®¡ï¼Œå¯ç¡®ä¿æ¥è‡ªä¸åŒé¡µé¢çš„å†…å®¹ç»ä¸ä¼šæ··æ‚åœ¨åŒä¸€ä¸ªåˆ†å—ä¸­ã€‚å½“æ£€æµ‹åˆ°ä¸€ä¸ªæ–°é¡µé¢æ—¶ï¼Œå³ä½¿ä¸‹ä¸€ä¸ªå…ƒç´ å¯ä»¥æ”¾åœ¨ä¹‹å‰çš„å†…å®¹å—ä¸­ï¼Œä¹Ÿä¼šå®Œæˆç°æœ‰çš„å†…å®¹å—å¹¶å¼€å§‹ä¸€ä¸ªæ–°çš„å†…å®¹å—ã€‚
      - æŒ‰ç›¸ä¼¼æ€§åˆ†å—ç­–ç•¥ï¼ˆä»…æ”¯æŒAPIè°ƒç”¨ï¼‰ï¼šå½“æ–‡æ¡£ç»“æ„æ— æ³•æä¾›æ˜ç¡®çš„ä¸»é¢˜è¾¹ç•Œæ—¶ï¼Œå¯ä»¥ä½¿ç”¨ "é€šè¿‡ç›¸ä¼¼æ€§ "ç­–ç•¥ã€‚è¯¥ç­–ç•¥ä½¿ç”¨ "sentence-transformers/multi-qa-mpnet-base-dot-v1 "åµŒå…¥æ¨¡å‹æ¥è¯†åˆ«åœ¨ä¸»é¢˜ä¸Šç›¸ä¼¼çš„é¡ºåºå…ƒç´ ï¼Œå¹¶å°†å®ƒä»¬ç»„åˆæˆå—ã€‚
  - [æµ‹è¯• LangChain åˆ†å—](https://mp.weixin.qq.com/s/-ZgM3wItZUtY6nU_9FmJnw)
    - æˆ‘æ·»åŠ äº†äº”ä¸ªå®éªŒï¼Œè¿™ä¸ªæ•™ç¨‹æµ‹è¯•çš„åˆ†å—é•¿åº¦ä» 32 åˆ° 64ã€128ã€256ã€512 ä¸ç­‰ï¼Œåˆ†å— overlap ä» 4 åˆ° 8ã€16ã€32ã€64 ä¸ç­‰çš„åˆ†å—ç­–ç•¥
    - Markdownçš„åˆ†é¡µ https://python.langchain.com/docs/how_to/#text-splitters
      - 1. å…ˆæŒ‰ç…§Headersåˆ†ï¼Œæˆ–è€…è¯´æŒ‰ç…§æ–‡ç« çš„â€œç« â€æ¥åˆ†
      - 2. åˆå¹¶ç›¸é‚»è¾ƒå°çš„
      - 3. å‚è€ƒä¸Šé¢çš„ç­–ç•¥ï¼Œå¯¹äºå¤§çš„â€œç« â€ï¼ŒæŒ‰ç…§â€œèŠ‚â€ç»§ç»­æ‹†åˆ†
      - 4. å¯¹äºå¤§çš„â€œèŠ‚â€ï¼Œä¾æ¬¡æŒ‰ç…§â€œæ®µâ€ã€â€œå¥â€ã€â€œè¯â€ç»§ç»­æ‹†åˆ†ï¼Œç›´åˆ°æ»¡è¶³é•¿åº¦è¦æ±‚
  - LlamaParse 
    - with an API call you can store both cleanly parsed text and image chunks 
    - the text can be pre-extracted by OCR/multimodal models but you can also dynamically feed the image directly into the model during query-time
  - [Late Chunking](https://jina.ai/news/late-chunking-in-long-context-embedding-models/?nocache=1)
    - https://colab.research.google.com/drive/15vNZb6AsU7byjYoaEtXuNu567JWNzXOz#scrollTo=e1173893c4f0ea56
    - é•¿æ–‡æœ¬åœ¨ Embedding æ¨¡å‹ä¸­çš„åº”ç”¨å¼•å‘äº†å¹¿æ³›è®¨è®ºå’Œäº‰è®®
      - ä¿¡æ¯å‹ç¼©é—®é¢˜ï¼šå°†æ•°åƒå­—çš„é•¿æ–‡æœ¬ç¼–ç ä¸ºå•ä¸€ Embedding è¡¨ç¤ºä¼šå¯¼è‡´è¯­ä¹‰ä¿¡æ¯çš„"è¿‡åº¦å‹ç¼©"ï¼Œä½¿å¾—æ£€ç´¢ç³»ç»Ÿéš¾ä»¥å‡†ç¡®å®šä½ç‰¹å®šä¿¡æ¯ã€‚
      - æ£€ç´¢ç²’åº¦ä¸è¶³ï¼šè®¸å¤šåº”ç”¨ï¼Œå°¤å…¶æ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿï¼Œéœ€è¦æ£€ç´¢æ–‡æ¡£ä¸­çš„è¾ƒå°ç‰‡æ®µï¼Œè€Œéæ•´ä¸ªé•¿æ–‡æ¡£ã€‚
    - Late Chunkingï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™é•¿æ–‡æœ¬ Embedding æ¨¡å‹ä¼˜åŠ¿çš„åŒæ—¶ï¼Œä¹Ÿèƒ½æ»¡è¶³ç²¾ç»†ç²’åº¦æ£€ç´¢çš„éœ€æ±‚ã€‚
    - ä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜
      - åˆ†å— - Embedding - æ£€ç´¢ - ç”Ÿæˆæµç¨‹åœ¨å¤„ç†é•¿æ–‡æ¡£æ—¶å¯èƒ½ä¼šä¸¢å¤±é•¿è·ç¦»çš„ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»
      - æœ‰ä¸€äº›å¯å‘å¼ç®—æ³•è¯•å›¾ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œå¦‚æ»‘åŠ¨çª—å£é‡æ–°é‡‡æ ·ã€å¤šç§ä¸Šä¸‹æ–‡çª—å£é•¿åº¦åŠå¤šæ¬¡æ–‡æ¡£æ‰«æç­‰ï¼Œç„¶è€Œï¼Œåƒæ‰€æœ‰å¯å‘å¼ç®—æ³•ä¸€æ ·ï¼Œè¿™äº›æ–¹æ³•æ—¶çµæ—¶ä¸çµï¼›å®ƒä»¬å¯èƒ½åœ¨æŸäº›æƒ…å†µä¸‹æœ‰æ•ˆï¼Œä½†æ²¡æœ‰ç†è®ºä¸Šçš„ä¿è¯
    - Late Chunkingè®© Embedding æ›´æ‡‚ä¸Šä¸‹æ–‡
      - å…ˆè¿‡ Embedding æ¨¡å‹å†åˆ†å—ï¼Œæˆ‘ä»¬å…ˆå°† Embedding æ¨¡å‹çš„ transformer å±‚åº”ç”¨åˆ°æ•´ä¸ªæ–‡æœ¬æˆ–å°½å¯èƒ½å¤šçš„è¿ç»­æ–‡æœ¬ï¼Œä¸ºæ¯ä¸ª token ç”Ÿæˆä¸€ä¸ªåŒ…å«ä¸°å¯Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„å‘é‡è¡¨ç¤ºåºåˆ—
      - å†å¯¹è¿™äº› token å‘é‡åºåˆ—è¿›è¡Œå¹³å‡æ± åŒ–ï¼Œè¿›è€Œå¾—åˆ°è€ƒè™‘äº†æ•´ä¸ªæ–‡æœ¬ä¸Šä¸‹æ–‡çš„å— Embeddingã€‚
      - ä¸ºäº†å……åˆ†å‘æŒ¥è¿Ÿåˆ†çš„ä¼˜åŠ¿ï¼Œæˆ‘ä»¬éœ€è¦å€ŸåŠ©æ”¯æŒé•¿ä¸Šä¸‹æ–‡çš„ Embedding æ¨¡å‹ï¼Œå¦‚ jina-embeddings-v2-base-enï¼Œå®ƒèƒ½å¤Ÿå¤„ç†é•¿è¾¾ 8192 ä¸ª token çš„æ–‡æœ¬(ç›¸å½“äº 10 é¡µ A4 çº¸)ï¼ŒåŸºæœ¬æ»¡è¶³äº†å¤§å¤šæ•°é•¿æ–‡æœ¬çš„ä¸Šä¸‹æ–‡éœ€æ±‚ã€‚
    - [Late Chunking: Balancing Precision and Cost in Long Context Retrieval](https://weaviate.io/blog/late-chunking)
    - https://arxiv.org/pdf/2409.04701
    - Chunking long docs has 2 issues: 
      - 1. finding breakpoints determining the breakpointsâ€”i.e., how to segment the document.
      - 2. loss of context within each chunk
      - Late Chunking & AnthropicAI's Contextual Retrieval both tackle the 2nd, experiments show Late Chunking is resilient to messy boundaries, so no need for perfect semantic breaks.
    - Late chunking does not require additional training for embedding models and can be applied to any long-context embedding models that use mean pooling
    - [What Late Chunking Really Is & What Itâ€™s Not](https://jina.ai/news/what-late-chunking-really-is-and-what-its-not-part-ii/)
    - [ä½¿ç”¨å°å‹è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æ¡£ä¸­å¯»æ‰¾æœ€ä¼˜åˆ†éš”ç‚¹](https://jina.ai/news/finding-optimal-breakpoints-in-long-documents-using-small-language-models)
      - ä¼ ç»Ÿçš„é‚£äº›åˆ†å—æ–¹æ³•ï¼Œåƒå›ºå®š token é•¿åº¦ã€å›ºå®šå¥å­æ•°é‡ï¼Œæˆ–è€…é«˜çº§ç‚¹çš„ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œéƒ½å¿½ç•¥äº†è¯­ä¹‰è¾¹ç•Œã€‚ç»“æœå°±æ˜¯ï¼Œç¢°ä¸Šä¸»é¢˜æ¨¡ç³Šçš„å†…å®¹ï¼Œåˆ†å‡ºæ¥çš„å—å°±æ”¯ç¦»ç ´ç¢ï¼Œå³ä½¿åæ¥ç”¨è¿Ÿåˆ†ç”Ÿæˆå¸¦ä¸Šä¸‹æ–‡çš„å‘é‡ä¹Ÿæ•‘ä¸å›æ¥ã€‚
      - æ—¢ç„¶ç”¨äº†è¿Ÿåˆ†ï¼Œå°±ä¸ç”¨å¤ªæ‹…å¿ƒè¯­ä¹‰æˆ–ä¸Šä¸‹æ–‡ä¸¢å¤±çš„é—®é¢˜ã€‚è¾¹ç•Œå¥½åï¼Œè¿Ÿåˆ†éƒ½èƒ½å¤„ç†ï¼Œå› æ­¤æ–‡æœ¬å—çš„å¯è¯»æ€§å°±æˆäº†å…³é”®
      - simple-qwen-0.5ï¼Œæ ¹æ®æ–‡æ¡£çš„ç»“æ„å…ƒç´ è¿›è¡Œåˆ‡åˆ†ï¼Œç®€å•ç›´æ¥ã€‚https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b
      - topic-qwen-0.5ï¼šçµæ„Ÿæ¥è‡ªæ€ç»´é“¾ (Chain-of-Thought) æ¨ç†ï¼Œå®ƒä¼šå…ˆè¯†åˆ«æ–‡æœ¬ä¸­çš„ä¸»é¢˜ï¼Œå†æ ¹æ®ä¸»é¢˜è¿›è¡Œåˆ‡åˆ†ã€‚åˆæ­¥æµ‹è¯•æ˜¾ç¤ºï¼Œå®ƒçš„åˆ‡åˆ†ç»“æœéå¸¸ç¬¦åˆäººç±»çš„ç›´è§‰ã€‚https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b-cot-topic-chunking
      - summary-qwen-0.5ï¼šä¸ä»…èƒ½åˆ‡åˆ†æ–‡æ¡£ï¼Œè¿˜èƒ½ç”Ÿæˆæ¯ä¸ªåˆ†å—çš„æ‘˜è¦ï¼Œåœ¨ RAG åº”ç”¨ä¸­éå¸¸æœ‰ç”¨ã€‚https://huggingface.co/jinaai/text-seg-lm-qwen2-0.5b-summary-chunking
    - [é•¿æ–‡æœ¬æ¨¡å‹å·²å…¨èƒ½ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åˆ†å—å¤„ç†å—ï¼Ÿ](https://jina.ai/news/still-need-chunking-when-long-context-models-can-do-it-all/)
      - é•¿æ–‡æœ¬ Embeddings çš„é—®é¢˜
        - è¡¨ç¤ºç¨€é‡Šï¼šè™½ç„¶æ–‡æœ¬ä¸­çš„æ‰€æœ‰ä¸»é¢˜å¯èƒ½ç›¸å…³ï¼Œä½†ç”¨æˆ·çš„æœç´¢æŸ¥è¯¢å¯èƒ½åªä¸å…¶ä¸­ä¸€ä¸ªç›¸å…³ã€‚ç„¶è€Œï¼Œå•ä¸ª embeddingï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯æ•´ç¯‡åšæ–‡çš„ embeddingï¼‰ä»…æ˜¯å‘é‡ç©ºé—´ä¸­çš„ä¸€ä¸ªç‚¹ã€‚éšç€æ›´å¤šæ–‡æœ¬è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œembedding ä¼šè½¬å‘æ•æ‰æ–‡ç« çš„æ•´ä½“ä¸»é¢˜ï¼Œåœ¨è¡¨ç¤ºç‰¹å®šæ®µè½å†…å®¹æ—¶æ•ˆæœä¸‹é™ã€‚
        - æœ‰é™å®¹é‡ï¼šEmbedding æ¨¡å‹ç”Ÿæˆå›ºå®šå¤§å°çš„å‘é‡ï¼Œä¸è¾“å…¥é•¿åº¦æ— å…³ã€‚éšç€è¾“å…¥å†…å®¹çš„å¢åŠ ï¼Œæ¨¡å‹è¶Šæ¥è¶Šéš¾ä»¥åœ¨å‘é‡ä¸­è¡¨ç¤ºæ‰€æœ‰è¿™äº›ä¿¡æ¯ã€‚
        - ä¿¡æ¯ä¸¢å¤±ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå³ä½¿æ˜¯é•¿æ–‡æœ¬ embedding æ¨¡å‹ä¹Ÿä¼šè¾¾åˆ°å…¶é™åˆ¶ï¼›è®¸å¤šæ¨¡å‹æ”¯æŒæœ€å¤š 8,192 ä¸ª token çš„æ–‡æœ¬ç¼–ç ã€‚æ›´é•¿çš„æ–‡æ¡£åœ¨ embedding ä¹‹å‰éœ€è¦è¢«æˆªæ–­ï¼Œå¯¼è‡´ä¿¡æ¯ä¸¢å¤±
      - æ–‡æœ¬åˆ†æ®µä»¥æå‡æ£€ç´¢æ€§èƒ½
        - â€¢ åˆ†æ®µï¼šåœ¨è¾“å…¥æ–‡æœ¬ä¸­æ£€æµ‹è¾¹ç•Œæ ‡è®°ï¼Œä¾‹å¦‚å¥å­æˆ–å›ºå®šæ•°é‡çš„ tokenã€‚
        - â€¢ æœ´ç´ åˆ†å—ï¼šåœ¨ç¼–ç ä¹‹å‰ï¼Œæ ¹æ®åˆ†æ®µæ ‡è®°å°†æ–‡æœ¬åˆ†æˆå—ã€‚
          - è™½ç„¶æœ´ç´ åˆ†å—è§£å†³äº†é•¿ä¸Šä¸‹æ–‡ embedding æ¨¡å‹çš„ä¸€äº›é™åˆ¶ï¼Œä½†å®ƒä¹Ÿæœ‰å…¶ç¼ºç‚¹ï¼š
            - ä¸¢å¤±å…¨å±€è§†è§’ï¼šåœ¨æ–‡æ¡£æ£€ç´¢ä¸­ï¼Œå¤šä¸ªå°å—çš„ embedding å¯èƒ½æ— æ³•æ•æ‰æ–‡æ¡£çš„æ•´ä½“ä¸»é¢˜ã€‚è¿™å°±åƒåªè§æ ‘æœ¨ä¸è§æ£®æ—ã€‚
            - ç¼ºå¤±ä¸Šä¸‹æ–‡é—®é¢˜ï¼šç”±äºç¼ºå°‘ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ— æ³•å‡†ç¡®ç†è§£å—çš„å†…å®¹ã€‚
            - æ•ˆç‡ï¼šæ›´å¤šçš„å—éœ€è¦æ›´å¤šå­˜å‚¨ç©ºé—´å¹¶å¢åŠ æ£€ç´¢æ—¶é—´ã€‚
        - â€¢ åæœŸåˆ†å—ï¼šå…ˆç¼–ç æ–‡æ¡£ï¼Œç„¶åå†è¿›è¡Œåˆ†æ®µï¼ˆä¿ç•™å—ä¹‹é—´çš„ä¸Šä¸‹æ–‡ï¼‰ã€‚
          - åæœŸåˆ†å—è§£å†³äº†ä¸Šä¸‹æ–‡é—®é¢˜
            - åæœŸåˆ†å—åˆ†ä¸¤ä¸ªä¸»è¦æ­¥éª¤å·¥ä½œï¼š
              - é¦–å…ˆï¼Œåˆ©ç”¨æ¨¡å‹çš„é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›å°†æ•´ä¸ªæ–‡æ¡£ç¼–ç ä¸º token embeddingã€‚è¿™ä¿ç•™äº†æ–‡æ¡£çš„å®Œæ•´ä¸Šä¸‹æ–‡ã€‚
              - ç„¶åï¼Œé€šè¿‡å¯¹ç‰¹å®š token embedding åºåˆ—è¿›è¡Œå¹³å‡æ± åŒ–æ¥åˆ›å»ºå— embeddingï¼Œè¿™äº›åºåˆ—å¯¹åº”äºåˆ†å‰²è¿‡ç¨‹ä¸­è¯†åˆ«çš„è¾¹ç•Œæ ‡è®°ã€‚
      - æœ´ç´ åˆ†å—ï¼šå°†æ–‡æ¡£åˆ†å‰²æˆå°å—ï¼Œç„¶ååˆ†åˆ«å¯¹æ¯ä¸ªå—è¿›è¡Œç¼–ç ã€‚
      - åæœŸåˆ†å—ï¼šä¸€æ¬¡æ€§å¯¹æ•´ä¸ªæ–‡æ¡£è¿›è¡Œç¼–ç ä»¥åˆ›å»º token embeddingï¼Œç„¶ååŸºäºæ®µè½è¾¹ç•Œå¯¹ token embedding è¿›è¡Œæ± åŒ–ä»¥åˆ›å»ºå— embeddingã€‚
      - é•¿æ–‡æœ¬åæœŸåˆ†å—ï¼šå°†å¤§å‹æ–‡æ¡£åˆ†å‰²æˆé€‚åˆæ¨¡å‹ä¸Šä¸‹æ–‡çª—å£çš„é‡å å®å—ï¼Œå¯¹è¿™äº›å—è¿›è¡Œç¼–ç è·å– token embeddingï¼Œç„¶åæ­£å¸¸åº”ç”¨åæœŸåˆ†å—ã€‚
      - ä½•æ—¶åº”è¯¥ä½¿ç”¨é•¿ä¸Šä¸‹æ–‡åµŒå…¥ï¼Ÿ
        - ä¸€èˆ¬æ¥è¯´ï¼Œåœ¨åµŒå…¥æ¨¡å‹çš„è¾“å…¥ä¸­åŒ…å«å°½å¯èƒ½å¤šçš„æ–‡æ¡£æ–‡æœ¬ä¸ä¼šæŸå®³æ£€ç´¢å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œé•¿ä¸Šä¸‹æ–‡åµŒå…¥æ¨¡å‹å¾€å¾€å…³æ³¨æ–‡æ¡£å¼€å¤´ï¼Œå› ä¸ºå®ƒä»¬åŒ…å«æ ‡é¢˜å’Œä»‹ç»ç­‰å¯¹åˆ¤æ–­ç›¸å…³æ€§æ›´é‡è¦çš„å†…å®¹ï¼Œä½†æ¨¡å‹å¯èƒ½ä¼šå¿½ç•¥æ–‡æ¡£ä¸­é—´çš„å†…å®¹ã€‚
        - ä¸»é¢˜å•ä¸€ï¼Œå…³é”®ä¿¡æ¯é›†ä¸­åœ¨å¼€å¤´ï¼šæ¯”å¦‚ç»“æ„åŒ–çš„æ–°é—»æŠ¥é“ï¼Œå…³é”®ä¿¡æ¯å¾€å¾€åœ¨æ ‡é¢˜å’Œå¼€å¤´æ®µè½ä¸­ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œç›´æ¥ä½¿ç”¨å…¨æ–‡å‘é‡åŒ–é€šå¸¸èƒ½å¤Ÿè·å¾—ä¸é”™çš„æ•ˆæœï¼Œå› ä¸ºæ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°ä¸»è¦ä¿¡æ¯ã€‚
        - é€šå¸¸æ¥è¯´ï¼ŒæŠŠå°½å¯èƒ½å¤šçš„æ–‡æœ¬å†…å®¹æ”¾è¿›æ¨¡å‹ä¸ä¼šå½±å“æ£€ç´¢ç»“æœã€‚ä½†æ˜¯ï¼Œé•¿æ–‡æœ¬æ¨¡å‹å¾€å¾€æ›´å…³æ³¨å¼€å¤´éƒ¨åˆ†ï¼ˆæ ‡é¢˜ã€å¼•è¨€ç­‰ï¼‰ï¼Œä¸­é—´å’Œç»“å°¾éƒ¨åˆ†çš„ä¿¡æ¯å¯èƒ½ä¼šè¢«å¿½ç•¥ã€‚æ‰€ä»¥ï¼Œå¦‚æœå…³é”®ä¿¡æ¯åœ¨æ–‡ç« ä¸­é—´æˆ–ç»“å°¾ï¼Œè¿™ç§æ–¹æ³•çš„æ•ˆæœå°±ä¼šå¤§æ‰“æŠ˜æ‰£ã€‚
      - ä½•æ—¶åº”è¯¥ä½¿ç”¨ç®€å•åˆ†å—ï¼Ÿ
        - å½“æ–‡æ¡£æ¶µç›–å¤šä¸ªæ–¹é¢ï¼Œæˆ–ç”¨æˆ·æŸ¥è¯¢é’ˆå¯¹æ–‡æ¡£ä¸­çš„ç‰¹å®šä¿¡æ¯æ—¶ï¼Œåˆ†å—é€šå¸¸å¯ä»¥æé«˜æ£€ç´¢æ€§èƒ½ã€‚
        - æœ€ç»ˆï¼Œåˆ†æ®µå†³ç­–å–å†³äºå„ç§å› ç´ ï¼Œæ¯”å¦‚æ˜¯å¦éœ€è¦å‘ç”¨æˆ·æ˜¾ç¤ºéƒ¨åˆ†æ–‡æœ¬ï¼ˆä¾‹å¦‚ Google åœ¨æœç´¢ç»“æœé¢„è§ˆä¸­å±•ç¤ºç›¸å…³æ®µè½ï¼‰ï¼Œè¿™ä½¿å¾—åˆ†æ®µæˆä¸ºå¿…éœ€ï¼Œæˆ–è€…è®¡ç®—å’Œå†…å­˜çš„é™åˆ¶ï¼Œç”±äºå¢åŠ äº†æ£€ç´¢å¼€é”€å’Œèµ„æºä½¿ç”¨ï¼Œåˆ†æ®µå¯èƒ½è¾ƒä¸åˆ©ã€‚
        - ä¸»é¢˜å¤šæ ·ï¼Œéœ€è¦æ£€ç´¢ç‰¹å®šä¿¡æ¯ï¼šå¦‚æœä½ çš„æ–‡æœ¬åŒ…å«å¤šä¸ªä¸»é¢˜ï¼Œæˆ–è€…ç”¨æˆ·æŸ¥è¯¢çš„ç›®æ ‡æ˜¯æ–‡æœ¬ä¸­çš„æŸä¸ªå…·ä½“äº‹å®ï¼Œé‚£ä¹ˆæœ´ç´ åˆ†å—æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚å®ƒèƒ½å¤Ÿæœ‰æ•ˆé¿å…ä¿¡æ¯ç¨€é‡Šï¼Œæé«˜æ£€ç´¢ç‰¹å®šä¿¡æ¯çš„å‡†ç¡®ç‡ã€‚
        - éœ€è¦å±•ç¤ºå±€éƒ¨æ–‡æœ¬ç‰‡æ®µï¼šç±»ä¼¼äºæœç´¢å¼•æ“ï¼Œéœ€è¦åœ¨ç»“æœä¸­å±•ç¤ºä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µï¼Œå°±å¿…é¡»é‡‡ç”¨åˆ†å—ç­–ç•¥ã€‚
      - ä½•æ—¶åº”è¯¥ä½¿ç”¨ååˆ†å—ï¼Ÿ
        - é€šè¿‡åœ¨åˆ›å»ºåˆ†å—ä¹‹å‰ç¼–ç å®Œæ•´æ–‡æ¡£ï¼Œååˆ†å—è§£å†³äº†ç”±äºç¼ºå°‘ä¸Šä¸‹æ–‡å¯¼è‡´æ–‡æœ¬æ®µè½å¤±å»æ„ä¹‰çš„é—®é¢˜ã€‚è¿™åœ¨è¿è´¯çš„æ–‡æ¡£ä¸­ç‰¹åˆ«æœ‰æ•ˆï¼Œå› ä¸ºæ¯ä¸ªéƒ¨åˆ†éƒ½ä¸æ•´ä½“ç›¸å…³ã€‚
        - ä¸»é¢˜è¿è´¯ï¼Œéœ€è¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼šå¯¹äºä¸»é¢˜è¿è´¯çš„é•¿æ–‡æœ¬ï¼Œä¾‹å¦‚è®ºæ–‡ã€é•¿ç¯‡æŠ¥é“ç­‰ï¼Œè¿Ÿåˆ†æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£æ–‡æœ¬çš„æ•´ä½“è¯­ä¹‰ã€‚å®ƒå°¤å…¶é€‚ç”¨äºéœ€è¦ç†è§£æ–‡æœ¬ä¸­ä¸åŒéƒ¨åˆ†ä¹‹é—´å…³ç³»çš„ä»»åŠ¡ï¼Œä¾‹å¦‚é˜…è¯»ç†è§£å’Œé•¿æ–‡æœ¬è¯­ä¹‰åŒ¹é…ã€‚
        - éœ€è¦å¹³è¡¡å±€éƒ¨ç»†èŠ‚å’Œå…¨å±€è¯­ä¹‰ï¼šè¿Ÿåˆ†æ–¹æ³•åœ¨è¾ƒå°çš„åˆ†å—å¤§å°ä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡å±€éƒ¨ç»†èŠ‚å’Œå…¨å±€è¯­ä¹‰ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹èƒ½å¤Ÿå–å¾—æ¯”å…¶ä»–ä¸¤ç§æ–¹æ³•æ›´å¥½çš„æ•ˆæœã€‚ä½†è¦æ³¨æ„ï¼Œå¦‚æœæ–‡ç« é‡Œæœ‰å¾ˆå¤šæ— å…³ç´§è¦çš„å†…å®¹ï¼Œè¿Ÿåˆ†åè€Œä¼šå› ä¸ºè€ƒè™‘äº†è¿™äº›æ— å…³ä¿¡æ¯è€Œå½±å“æ•ˆæœã€‚
- [Deconstructing RAG](https://blog.langchain.dev/deconstructing-rag/)
  - Query Transformations - a set of approaches focused on modifying the user input in order to improve retrieval
    - Query expansion - decomposes the input into sub-questions, each of which is a more narrow retrieval challenge
      - The multi-query retriever performs sub-question generation, retrieval, and returns the unique union of the retrieved docs.
      -  RAG fusion builds on by ranking of the returned docs from each of the sub-questions
      - Step-back prompting offers a third approach in this vein, generating a step-back question to ground an answer synthesis in higher-level concepts or principles
      - https://haystack.deepset.ai/blog/query-expansion
        - BM25 favors precision while embedding retrieval favors recall
        - use BM25+query expansion to increase recall in cases where you want to rely on keyword search
          """
          You are part of an information system that processes users queries.
          You expand a given query into {{ number }} queries that are similar in meaning.

          Structure:
          Follow the structure shown below in examples to generate expanded queries.
          Examples:
          1. Example Query 1: "climate change effects"
             Example Expanded Queries: ["impact of climate change", "consequences of global warming", "effects of environmental changes"]

          2. Example Query 2: ""machine learning algorithms""
             Example Expanded Queries: ["neural networks", "clustering", "supervised learning", "deep learning"]

          Your Task:
          Query: "{{query}}"
          Example Expanded Queries:
          """
    - Query re-writing
    - Query compression
      - a user question follows a broader chat conversation. In order to properly answer the question, the full conversational context may be required. To address this, we use this prompt to compress chat history into a final question for retrieval
    - ä¸è§„èŒƒçš„æŸ¥è¯¢å’ŒçŸ­æŸ¥è¯¢
      - æ„å›¾åˆ†æï¼šç¡®å®šä¸€ä¸ªæˆ–å¤šä¸ªç”¨æˆ·æ„å›¾ï¼Œç¼©å°å¬å›èŒƒå›´
        - åŸºäºé¢„å®šä¹‰çš„è§„åˆ™æˆ–å…³é”®å­—ï¼Œé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼è¿›è¡ŒåŒ¹é…
        - ä½¿ç”¨ç»å…¸å°æ¨¡å‹åˆ†ç±»ï¼Œä¾‹å¦‚ Naive Bayes åˆ†ç±»å™¨æˆ– BERTã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼ŒBERT çš„ç¤ºä¾‹ä»£ç ç‰‡æ®µå¦‚ä¸‹æ‰€ç¤ºã€‚ç„¶åï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨å®ƒå¯¹æŸ¥è¯¢è¿›è¡Œåˆ†ç±»ã€‚
        - Queryç›¸ä¼¼æ€§æ£€ç´¢ã€‚ä¸ºé¢„å®šä¹‰æ„å›¾ç”Ÿæˆembeddingï¼Œç„¶åä½¿ç”¨ç›¸åŒçš„åµŒå…¥æ¨¡å‹ä¸ºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆembeddingã€‚
        - LLMåˆ†ç±»ã€‚æ„å»ºä¸€ä¸ªæç¤ºï¼Œå¹¶åˆ©ç”¨ LLM åšå‡ºå†³ç­–ã€‚æ­¤å¤–ï¼Œè¿˜å¯ä»¥æä¾›ç”¨æˆ·çš„å†å²è¯­å¢ƒï¼Œä»¥è·å¾—æ›´å‡†ç¡®çš„æ„å›¾
      - å…³é”®è¯æå–ï¼šç¡®å®šæŸ¥è¯¢çš„å…³é”®è¯ï¼Œå¹¶æ ¹æ®å…³é”®è¯è¿›è¡Œæ£€ç´¢ã€‚
        - TF-IDFï¼šé¦–å…ˆï¼Œè¿›è¡Œæ ‡è®°åŒ–å’Œåœæ­¢è¯å»é™¤ã€‚ç„¶åï¼Œè®¡ç®—æ¯ä¸ªæ ‡è®°çš„åæ–‡æ¡£é¢‘ç‡ï¼ˆIDFï¼‰å’Œæ¯ä¸ªæ ‡è®°çš„ TF-IDF åˆ†æ•°ã€‚æœ€åï¼Œæ ¹æ®è®¡ç®—å‡ºçš„ TF-IDF åˆ†æ•°å¯¹è¯è¯­è¿›è¡Œæ’åº
        - è®­ç»ƒBertæ¨¡å‹æˆ–ä½¿ç”¨ç°æœ‰æ¨¡å‹ï¼Œå¦‚ KeyBERTï¼šç›´æ¥æå–å…³é”®è¯ï¼Œå½¢æˆæœ€ç»ˆçš„å…³é”®è¯åˆ—è¡¨
        - ä½¿ç”¨ LLM æå–å…³é”®è¯
      - æ¾„æ¸…å’Œè¯¢é—®ï¼šä¸»åŠ¨å‘ç”¨æˆ·æé—®ï¼Œä»¥è·å–æ›´å¤šä¿¡æ¯
    - [æ„å›¾è¯†åˆ«å·¥ç¨‹åŒ–](https://mp.weixin.qq.com/s/nu-2ji9NOszcZ_6SWd469A)
      - åŸºæ¨¡ + Prompt : CoT æ€ç»´é“¾, Few-Shot å°‘æ ·æœ¬å­¦ä¹ 
      - åŸºæ¨¡ + Prompt + RAG : 
      - ä½¿ç”¨å°å°ºå¯¸æ¨¡å‹è¿›è¡ŒSFT 
      - è‡ªåŠ¨è´¨æ£€å’Œè‡ªåŠ¨å¾®è°ƒå·¥ç¨‹
    - [æ„å›¾è¯†åˆ«æå‡ä¹‹é“](https://mp.weixin.qq.com/s/X9Tg1wbv3_9TTO8PTth95A)
      - å¯¹è¯å¼ AI ä¸­è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰çš„ä¸¤å¤§å…³é”®ç¯èŠ‚ï¼šæ„å›¾è¯†åˆ«ï¼ˆIntent Detectionï¼‰å’Œæ§½ä½æŠ½å–ï¼ˆSlot Fillingï¼‰ã€‚
        - æ„å›¾è¯†åˆ«å†³å®šäº†åç»­ä¸šåŠ¡æµç¨‹èµ°å‘ï¼Œä¸€æ—¦è¯†åˆ«é”™è¯¯ï¼Œæ•´ä¸ªå¯¹è¯æ˜“åç¦»ç”¨æˆ·éœ€æ±‚ã€‚æ§½ä½æŠ½å–åˆ™å°†ç”¨æˆ·è¾“å…¥ä¸­çš„å…³é”®ä¿¡æ¯ç»“æ„åŒ–æå–ï¼Œç”¨äºå…·ä½“ä»»åŠ¡æ‰§è¡Œ
      - æ–¹æ¡ˆAï¼šåˆçº§æç¤ºè¯å·¥ç¨‹
        - æ ¸å¿ƒåšæ³•ï¼šåœ¨åŒä¸€ä¸ªæ¨¡å‹èŠ‚ç‚¹å†…ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ï¼ˆPromptï¼‰ï¼Œå®ç°æ„å›¾è¯†åˆ«å’Œæ§½ä½æŠ½å–ã€‚åŒ…æ‹¬â€œå®šä¹‰æ„å›¾æ§½ä½â€ã€â€œFew-Shot + CoT ç¤ºä¾‹â€ã€â€œé™å®šè¾“å‡ºæ ¼å¼â€ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚
        - ä¼˜ç‚¹ï¼šç®€å•é«˜æ•ˆï¼Œç‰¹åˆ«é€‚ç”¨äºæ„å›¾æ•°é‡è¾ƒå°‘ã€å¯¹ç²¾åº¦å®¹é”™è¾ƒé«˜çš„åœºæ™¯ã€‚
        - ç¼ºç‚¹ï¼šå½“æ„å›¾å¢å¤šæ—¶ï¼Œæç¤ºè¯é•¿åº¦ä¼šè¿…é€Ÿè†¨èƒ€ï¼Œæ¨¡å‹éš¾ä»¥å‡†ç¡®ç†è§£ï¼Œå½±å“è¯†åˆ«å‡†ç¡®æ€§ã€‚
      - æ–¹æ¡ˆBï¼šä¸­çº§æ‹†åˆ†æ¨¡å¼ï¼ˆæ„å›¾ä¸æŠ½æ§½åˆ†ç¦»ï¼‰
        - åšæ³•ï¼šå…ˆç”±ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œæ„å›¾è¯†åˆ«ï¼Œç„¶åç”±ç›¸åº”èŠ‚ç‚¹è¿›è¡Œæ§½ä½æŠ½å–ï¼Œä¸€æ„å›¾å¯¹åº”ä¸€æŠ½æ§½èŠ‚ç‚¹ã€‚
        - ä¼˜ç‚¹ï¼šç³»ç»Ÿæ¶æ„æ›´æ˜“æ‰©å±•å’Œç»´æŠ¤ï¼Œæ¯ä¸ªæŠ½æ§½èŠ‚ç‚¹é’ˆå¯¹æ€§å¼ºï¼ŒPrompt å¯æ›´ä¸“æ³¨äºè¯¥æ„å›¾çš„æŠ½æ§½é€»è¾‘ã€‚
        - ç¼ºç‚¹ï¼šéœ€è¦å¤šæ¬¡è°ƒç”¨ AI æ¥å£ï¼Œå¢åŠ äº†æ•´ä½“ç³»ç»Ÿçš„å“åº”æ—¶å»¶ã€‚
      - æ–¹æ¡ˆCï¼šè¿›é˜¶å‰ç½®æ„å›¾ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰å¬å›
        - èƒŒæ™¯ï¼šåœ¨æ–¹æ¡ˆ A æˆ– B çš„åŸºç¡€ä¸Šï¼Œå®¢æˆ·åé¦ˆè‹¥è¦æé«˜è¯†åˆ«æ³›åŒ–èƒ½åŠ›ï¼ˆå«å£è¯­åŒ–ã€æ–¹è¨€ã€åé—®ç­‰ï¼‰ï¼Œå¿…é¡»è®©æ¨¡å‹èƒ½â€œçœ‹â€åˆ°æ›´å¤šå¤šæ ·åŒ–çš„è¡¨è¾¾æ–¹å¼ã€‚
        - åšæ³•ï¼š
          - â€¢ å…ˆå°†é€šè¿‡ LLM ç”Ÿæˆçš„å¤šæ ·åŒ–æ„å›¾è¯­æ–™ï¼ˆâ€œæ³›åŒ–â€ï¼‰å­˜å…¥çŸ¥è¯†åº“ã€‚
          - â€¢ ç”¨æˆ·è¯¢é—®æ—¶å…ˆåšæ£€ç´¢å¬å›ï¼Œå°†ç›¸ä¼¼è¡¨è¾¾ä¸æ„å›¾å¯¹åº”å…³ç³»ä½œä¸ºæ ·ä¾‹æä¾›ç»™ LLMï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°è¯†åˆ«æ„å›¾ã€‚
        - ä¼˜ç‚¹ï¼šå¯¹å®æ—¶æ¨ç†çš„ä¾èµ–å¤§å¤§é™ä½ï¼Œåªéœ€åœ¨çŸ¥è¯†åº“å¢è¡¥ç›¸åº”çš„è¯­æ–™å³å¯å¿«é€Ÿä¿®å¤é”™è¯¯ï¼Œæ€§ä»·æ¯”è¾ƒé«˜ã€‚
        - ç¼ºç‚¹ï¼šéœ€è¦å…ˆå¯¹æ„å›¾è¯­æ–™è¿›è¡Œå¤šæ ·åŒ–æ•°æ®æ”¶é›†ä¸é¢„å¤„ç†ï¼Œç ”å‘æˆæœ¬é«˜ï¼›å¯¹å¤šè½®ä¼šè¯ä¸­ç»¼åˆåˆ¤æ–­æ„å›¾æ—¶ï¼Œä¾èµ–æ€§ç›¸å¯¹è¾ƒå¼±ã€‚
      - æ–¹æ¡ˆDï¼šé«˜é˜¶åˆå¹¶æ„å›¾æŠ½æ§½èŠ‚ç‚¹ + å‡çº§å‰ç½® RAG å¬å›
        - ä¸ºåº”å¯¹å¤šè½®å¯¹è¯æ„ˆåŠ å¤æ‚ã€ä¸”å¯¹å‡†ç¡®æ€§ä¸å®æ—¶æ€§éƒ½æœ‰æ›´é«˜è¦æ±‚çš„åœºæ™¯ï¼Œæå‡ºäº†å°†æ„å›¾è¯†åˆ«ä¸æ§½ä½æŠ½å–å†æ¬¡åˆå¹¶åˆ°å•èŠ‚ç‚¹ï¼Œä½†åŒæ—¶å€ŸåŠ©å¼ºåŒ–çš„ RAG æœºåˆ¶ï¼š
          - â€¢ é€šè¿‡â€œå¤šè½®å¯¹è¯ + å½“å‰Queryâ€ä¸€èµ·æ£€ç´¢å’Œå¬å›å·²æœ‰çš„å…¸å‹æ¡ˆä¾‹ï¼Œå‡å°‘æç¤ºè¯è†¨èƒ€å’Œæ„å›¾å¹²æ‰°ã€‚
          - â€¢ å¯¹å¤šè½®ä¼šè¯çš„æ„å›¾æ··æ·†ï¼Œå¯é€šè¿‡æ„å›¾åˆ‡æ–­ç­–ç•¥ï¼Œé¿å…å·²å®Œæˆçš„æ„å›¾ä¿¡æ¯å½±å“æ–°æ„å›¾è§£æã€‚
          - â€¢ ä¸€éƒ¨åˆ†ä¸éœ€è¦ LLM å¤„ç†çš„æ„å›¾ç›´æ¥ç”¨ FAQ æ–¹å¼è¿”å›ï¼Œæ˜¾è‘—å‡å°‘æ—¶å»¶ã€‚
        - ä¼˜ç‚¹ï¼šåœ¨æ§åˆ¶æ—¶å»¶çš„åŒæ—¶å¤§å¹…æé«˜å¤šè½®å¤æ‚å¯¹è¯çš„å‡†ç¡®æ€§ï¼›é€šè¿‡çŸ¥è¯†åº“ç®¡ç†æ¡ˆä¾‹ï¼Œé‡åˆ°æ–°é—®é¢˜å¯å¿«é€Ÿæ·»åŠ ç»´æŠ¤æ¡ç›®ï¼Œçœå»å¤§è§„æ¨¡æ¨¡å‹è°ƒä¼˜ã€‚
        - ç¼ºç‚¹ï¼šéœ€è¦æ›´ç³»ç»Ÿçš„çŸ¥è¯†åº“ç®¡ç†å’Œå¤šè½®ä¼šè¯åˆ‡æ–­ç­–ç•¥ï¼Œä¹Ÿéœ€è¦é¢„å…ˆå‡†å¤‡è¾ƒå¤šæ„å›¾ä¸å¤šè½®å¯¹è¯æ¡ˆä¾‹ï¼Œå·¥ä½œé‡ä¸å°
  - [Routing](https://blog.langchain.dev/applying-openai-rag/)
  - Query Construction
    - Text-to-SQL 
      - llamaIndex sample https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/workflow/advanced_text_to_sql.ipynb
      - [QueryGPT ](https://www.uber.com/en-HK/blog/query-gpt/)
        - Naive version
          - To help the LLM understand internal Uber lingo and work with Uber datasets, we also included some custom instructions in the LLM call
          - ```
            It's important to consider the data type of columns in a given dataset because certain functions can only be applied to certain data types. 
            For example, the function AVG() can only be applied to numerical columns. data functions like DATE_TRUNC(), DATE_ADD can only be used with TIMESTAMP columns. 
            ```
        - Better RAG
          - Understanding Userâ€™s Intent
          - Handling Large Schemas
          - Intent Agent
          - Table Agent - Allowing users to select the tables used in the query generation came up as feedback from some users
          - Column Prune Agent - wherein we use an LLM call to prune the irrelevant columns from the schemas we provided to the LLM
          - Evaluation Procedure 
            - For each question, we can view the generated SQL, reason for the error, and related performance metrics
            - We also aggregate accuracy and latency metrics for each evaluation run to track performance over time.
      - [dynamic-few-shot-llamaindex-workflow](https://github.com/rsrohan99/dynamic-few-shot-llamaindex-workflow/tree/master)
    - Text-to-Cypher
    - Text-to-metadata filters
  - Indexing
    - CHunk size
    - [Document embedding strategy](https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb?ref=blog.langchain.dev)
  - Post-Processing
    - [Re-ranking](https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb?ref=blog.langchain.dev)
    - Classification
- [Multi-Vector Retriever for RAG on tables, text, and images](https://blog.langchain.dev/semi-structured-multi-modal-rag/)
- [åŸºäº RAG çš„ LLM å¯ç”Ÿäº§åº”ç”¨ Ray](https://mp.weixin.qq.com/s/rjBa2CQxDK2dvdE53ShyOw)
  - [Embedding Inference at Scale for RAG Applications with Ray Data](https://zilliz.com/blog/embedding-inference-at-scale-for-RAG-app-with-ray-data-and-milvus)
    - BGM-M3 embedding model (generating 3 types of vectors in one round: sparse, dense, and multi-vector)
    - Ray Dataâ€™s scalable data processing makes it easier and faster to process massive amounts of data in parallel across multiple machines (CPUs, GPUs, etc.).
    - Ray Data is especially helpful when the data can be split into parallel processes, such as many simultaneous chunkin and embedding transformations
- [Advanced RAG Techniques](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6)
  - Advanced RAG
    - ![img.png](ml_advance_rag.png)
    - Chunking & vectorisation
      - Search index
      - Vector store index
      - Hierarchical indices
    - Context enrichment
      - Sentence Window Retrieval
      - Auto-merging Retriever (aka Parent Document Retriever)
      - Fusion retrieval or hybrid search
      - Reranking & filtering
    - Query transformations
    - Fusion Retrieval or Hybrid Search: This section likely discusses the combination of different retrieval methods or the integration of various search techniques in RAG systems.
    - Reranking & Filtering: A discussion on methods for rearranging the order of retrieved information and filtering out irrelevant data.
    - Query Transformations: This part might explore how queries are modified or transformed to improve the retrieval process.
    - Chat Engine: A section that could focus on the application of RAG techniques in the development of chat engines.
    - Query Routing: Discusses the routing of queries to the most appropriate source or system component in a RAG setup.
    - Agents in RAG: This could delve into the role of agents (autonomous or semi-autonomous entities) in RAG systems.
    - Response Synthesizer: A section on how responses are generated or synthesized in RAG systems.
  - [advanced RAG series](https://div.beehiiv.com/)
  - [advanced RAG](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930)
    - Pre-retrieval optimization: Sentence window retrieval
      - Sliding window uses an overlap between chunks and is one of the simplest techniques.
      -  Enhancing data granularity applies data cleaning techniques, such as removing irrelevant information, confirming factual accuracy, updating outdated information, etc.
      -  Adding metadata, such as dates, purposes, or chapters, for filtering purposes.
      -  Optimizing index structures involves different strategies to index data, such as adjusting the chunk sizes or using multi-indexing strategies.
    - Retrieval optimization: Hybrid search
      - Fine-tuning embedding models customizes embedding models to domain-specific contexts, especially for domains with evolving or rare terms.
      - Dynamic Embedding adapts to the context in which words are used, unlike static embedding, which uses a single vector for each word
    - Post-retrieval optimization: Re-ranking
      - Prompt compression reduces the overall prompt length by removing irrelevant and highlighting important context.
      - Re-ranking uses machine learning models to recalculate the relevance scores of the retrieved contexts
    - https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/retrieval-augmented-generation/advanced_rag.ipynb
  - [Advance RAG- Improve RAG performance](https://luv-bansal.medium.com/advance-rag-improve-rag-performance-208ffad5bb6a)
    - Pre-Retrieval Optimisation
      - Enhancing data granularity: Improve quality of Data; Adding Metadata; Optimizing index structures
      - Chunking Optimisation: 
        - High-level tasks like summarization requires bigger chunk size and low-level tasks like coding requires smaller chunks
        - Small2big or Parent Document Retrieval, Sentence Window Retrieval
    - Retrieval Optimisation
      - Query Rewriting and MultiQuery Retrievers
      - StepBack-prompt
      - Fine-tune Embedding
      - Hybrid Search Exploration
    - Post-Retrieval Optimisation
      - Re-ranking
      - Prompt Compression
  - [A Cheat Sheet and Some Recipes For Building Advanced RAG](https://www.llamaindex.ai/blog/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b)
    - Advanced techniques for Retrieval must be able to find the most relevant documents to a user query
      - Chunk-Size Optimization
      - Structured External Knowledge
    - Advanced techniques for Generation must be able to make good use of the retrieved documents
      - Information Compression: Not only are LLMs are restricted by context length, but there can be response degradation if the retrieved documents carry too much noise
      - Result Re-Rank: LLMs suffer from the so-called â€œLost in the Middleâ€ phenomena which stipulates that LLMs focus on the extreme ends of the prompts.
    - Advanced techniques for simultaneously addressing Retrieval and Generation success requirements
      - Generator-Enhanced Retrieval: These techniques make use of the LLMâ€™s inherent reasoning abilities to refine the user query before retrieval is performed so as to better indicate what exactly it requires to provide a useful response.
      - Iterative Retrieval-Generator RAG: For some complex cases, multi-step reasoning may be required to provide a useful and relevant answer to the user query.
  - [Advanced Retriever Techniques to Improve Your RAGs](https://towardsdatascience.com/advanced-retriever-techniques-to-improve-your-rags-1fac2b86dd61)
    - Parent Document Retriever
    - Self-Query Retriever
    - Contextual Compression Retriever (Reranking)
  - Auto-Document Retrieval
    - Index chunks with document metadata into a vector DB 
    - Perform chunk-level retrieval to fetch relevant document metadata 
    - Use metadata as few-shot examples for an auto-retriever prompt
    - https://github.com/run-llama/llamacloud-demo/blob/main/examples/advanced_rag/auto_retrieval.ipynb
  - [Advanced RAG techniques](https://www.leewayhertz.com/advanced-rag/#applications-and-use-cases)
    - Indexing
      - Optimize text chunking with chunk optimization
      - Transform texts into vectors with advanced embedding models
      - Enhance semantic matching with embedding fine-tuning
      - Improve retrieval efficiency with multi-representation
      - Organize data with hierarchical indexing
      - Enhance data retrieval with metadata attachment
    - Query transformations
      - Improve query clarity with HyDE (Hypothetical Document Embeddings)
      -  Simplify complex queries with multi-step query
      - Enhance context with step-back prompting
      - Improve retrieval with query rewriting
    - Query routing
      - Direct queries with logical routing 
      -  Guide queries with semantic routing
    - Pre-retrieval and data-indexing techniques
      - Increase information density using LLMs
      - Apply hierarchical index retrieval
      - Improve retrieval symmetry with a hypothetical question index
      -  Deduplicate information in your data index using LLMs
      - Test and optimize your chunking strategy
      - Use sliding window indexing for context preservation
      - Enhance data granularity with cleaning
      - Add metadata for precise filtering
    - Retrieval Techs
      - Optimize search queries using LLMs
      - Fix query-document asymmetry with Hypothetical Document Embeddings (HyDE)
      - Implement query routing or a RAG decider pattern
      -  Perform deep data exploration with recursive retriever
      - Optimize data source selection with router retriever
      - Automate query generation with auto retriever
      - Combine results for comprehensive retrieval with fusion retriever
      - Aggregate data contexts with auto merging retriever
      -  Fine-tune embedding models for domain specificity
      - Implement dynamic embedding for contextual understanding
      - Leverage hybrid search for enhanced retrieval
    - Post-retrieval techniques
      - Prioritize search results with reranking
      - Optimize search results with contextual prompt compression
      - Score and filter retrieved documents with corrective RAG
    -  Generation techniques
      - Tune out noise with Chain-of-Thought prompting
      - Make your system self-reflective with self-RAG
      - Ignore irrelevant context through fine-tuning
      - Use natural language inference to make LLMs robust against irrelevant context
      -  Control data retrieval with FLARE
      - Refine responses with ITER-RETGEN
      - Clarify questions with ToC (Tree of Clarifications)
  - [åŠ¨æ€ç« èŠ‚ RAG ç³»ç»Ÿ](https://github.com/run-llama/llama_parse/blob/main/examples/advanced_rag/dynamic_section_retrieval.ipynb)
    - ä¸€ç§åŸºäºæ–‡æ¡£ç»“æ„çš„æ™ºèƒ½æ£€ç´¢æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€è¯†åˆ«å’Œæå–å®Œæ•´ç« èŠ‚å†…å®¹ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–‡æ¡£åˆ†å—æ£€ç´¢é€ æˆçš„ä¸Šä¸‹æ–‡å‰²è£‚é—®é¢˜ï¼Œå®ç°äº†è¯­ä¹‰å®Œæ•´çš„çŸ¥è¯†å¢å¼ºç”Ÿæˆ
    - é—®é¢˜èƒŒæ™¯:
      - ä¼ ç»Ÿ RAG ç³»ç»Ÿåœ¨å¤„ç†é•¿æ–‡æ¡£æ—¶ä¼šå°†æ–‡æ¡£åˆ†å‰²æˆå°å—è¿›è¡Œæ£€ç´¢
      - è¿™ç§æ–¹å¼å¯èƒ½ä¼šå¯¼è‡´æ£€ç´¢åˆ°çš„å†…å®¹ç¼ºä¹å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œå› ä¸ºä¸€ä¸ªå®Œæ•´çš„ç« èŠ‚å¯èƒ½è¢«åˆ†æ•£åœ¨å¤šä¸ªå—ä¸­
    - è§£å†³æ–¹æ¡ˆ:
      - å…ˆæå–æ–‡æ¡£çš„ç« èŠ‚ç»“æ„(TOC)
      - ä¸ºæ¯ä¸ªæ–‡æ¡£å—æ ‡æ³¨å…¶æ‰€å±çš„ç« èŠ‚ä¿¡æ¯
      - æ£€ç´¢æ—¶ä¸ä»…è¿”å›ç›¸å…³å—ï¼Œè€Œæ˜¯è¿”å›ç›¸å…³å—æ‰€å±çš„å®Œæ•´ç« èŠ‚
  - [agentic retrieval](https://www.llamaindex.ai/blog/rag-is-dead-long-live-agentic-retrieval)
  - [The Hitchhiker's Guide to Vector Search](https://qdrant.tech/blog/hitchhikers-guide/)
    - Query Type
      - Generic query: too broad, may confound the search process	
        - Expansion: you can transform your query into a hypothetical document (HyDE), using a language model to generate a more detailed query text, which you can embed and use in retrieval.
      - Specific query: asks for some specific information that can be easily identified within your documents	
        - No transformation in this case, you can retrieve directly!
      - Complex query: has many questions that generally cannot be answered by just one of the documents within your database	
        - Decomposition: You can divide the query into several sub-queries, each of which is used for a multistep-like retrieval from the database. The results from each step will then form the final answer from the LLM.
    -  RAGcoon https://github.com/AstraBert/RAGcoon. There, a query agent tries various retrieval techniques to get the best information for startup founders.
- [RAG é—®é¢˜](https://mp.weixin.qq.com/s/2dwnwQGsqKWZQX8gEUV0Sw)
  - æœ´ç´ çš„RAGé€šå¸¸å°†æ–‡æ¡£åˆ†æˆå—ï¼ŒåµŒå…¥å®ƒä»¬ï¼Œå¹¶æ£€ç´¢ä¸ç”¨æˆ·é—®é¢˜å…·æœ‰é«˜è¯­ä¹‰ç›¸ä¼¼æ€§çš„å—ã€‚ä½†æ˜¯ï¼Œè¿™ä¼šå¸¦æ¥ä¸€äº›é—®é¢˜
    - æ–‡æ¡£å—å¯èƒ½åŒ…å«é™ä½æ£€ç´¢æ•ˆæœçš„æ— å…³å†…å®¹
      - Multi representation indexingï¼šåˆ›å»ºä¸€ä¸ªé€‚åˆæ£€ç´¢çš„æ–‡æ¡£è¡¨ç¤ºï¼ˆå¦‚æ‘˜è¦ï¼‰ï¼Œå¹¶å°†å…¶ä¸åŸå§‹æ–‡æ¡£ä¸€èµ·å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­
    - ç”¨æˆ·é—®é¢˜å¯èƒ½è¡¨è¾¾ä¸æ¸…ï¼Œéš¾ä»¥è¿›è¡Œæ£€ç´¢
      - Query transformationï¼šåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†å›é¡¾ä¸€äº›è½¬æ¢äººç±»é—®é¢˜çš„æ–¹æ³•ï¼Œä»¥æ”¹å–„æ£€ç´¢
    - å¯èƒ½éœ€è¦ä»ç”¨æˆ·é—®é¢˜ä¸­ç”Ÿæˆç»“æ„åŒ–æŸ¥è¯¢
      - Query constructionï¼šå°†äººç±»é—®é¢˜è½¬æ¢ä¸ºç‰¹å®šçš„æŸ¥è¯¢è¯­æ³•æˆ–è¯­è¨€
  - Solutions
    - [Multi-Vector Retriever for RAG on tables, text, and images](https://blog.langchain.dev/semi-structured-multi-modal-rag/)
    - Rewrite-Retrieve-Read
      - ä½¿ç”¨LLMæ¥é‡å†™ç”¨æˆ·æŸ¥è¯¢ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨åŸå§‹ç”¨æˆ·æŸ¥è¯¢è¿›è¡Œæ£€ç´¢
      - https://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb
      - [å­é—®é¢˜æŸ¥](https://mp.weixin.qq.com/s/mliPeSDp4PfqwsjkeyE_7Q)
        - å­é—®é¢˜ç­–ç•¥é¦–å…ˆå°†ç”¨æˆ·é—®é¢˜é€šè¿‡ LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ç”Ÿæˆå¤šä¸ªå­é—®é¢˜
        - ç„¶åå°†æ¯ä¸ªå­é—®é¢˜ç»è¿‡ RAG æµç¨‹å¾—åˆ°å„è‡ªçš„ç­”æ¡ˆï¼ˆæ£€ç´¢-ç”Ÿæˆï¼‰
        - æœ€åå°†æ‰€æœ‰å­é—®é¢˜çš„ç­”æ¡ˆåˆå¹¶ï¼Œå¾—åˆ°æœ€ç»ˆçš„ç­”æ¡ˆ
        -  llama_index.core.query_engine import SubQuestionQueryEngine
      - HyDE æŸ¥è¯¢è½¬æ¢ ï¼ˆHypothetical Document Embeddingsï¼‰
        - æœ¬è´¨æ˜¯é€šè¿‡ LLM å¯¹ç”¨æˆ·é—®é¢˜ç”Ÿæˆå‡è®¾æ€§æ–‡æ¡£ï¼Œè¿™äº›æ–‡æ¡£åŸºäº LLM æœ¬èº«çš„çŸ¥è¯†ç”Ÿæˆï¼Œå¯èƒ½å­˜åœ¨é”™è¯¯æˆ–è€…ä¸å‡†ç¡®ï¼Œä½†æ˜¯è·Ÿ RAG ä¸­çŸ¥è¯†åº“çš„æ–‡æ¡£ç›¸å…³è”ï¼Œç„¶åé€šè¿‡å‡è®¾æ€§æ–‡æ¡£å»æ£€ç´¢å‘é‡ç›¸è¿‘çš„çœŸå®æ–‡æ¡£ï¼Œé€šè¿‡è¿™ç§æ–¹å¼æ¥æé«˜æ£€ç´¢çš„å‡†ç¡®æ€§
        - from llama_index.core.indices.query.query_transform import HyDEQueryTransform
        -  HyDE å¯èƒ½ä¼šè¯¯å¯¼æŸ¥è¯¢å’Œå¼•èµ·åè§ï¼Œæ‰€ä»¥åœ¨å®é™…åº”ç”¨ä¸­éœ€è¦è°¨æ…ä½¿ç”¨ã€‚
        - [Improving Information Retrieval and RAG with Hypothetical Document Embeddings (HyDE)](https://zilliz.com/learn/improve-rag-and-information-retrieval-with-hyde-hypothetical-document-embeddings)
    - [Step back prompting](https://medium.com/international-school-of-ai-data-science/enhancing-llms-reasoning-with-step-back-prompting-47fad1cf5968)
      - Step-Back Promptingæ˜¯ä¸€ç§ç”¨äºå¢å¼ºè¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†å’Œè§£å†³é—®é¢˜èƒ½åŠ›çš„æŠ€æœ¯ã€‚å®ƒæ¶‰åŠé¼“åŠ±LLMä»ç»™å®šçš„é—®é¢˜æˆ–é—®é¢˜ä¸­åé€€ä¸€æ­¥ï¼Œå¹¶æå‡ºä¸€ä¸ªæ›´æŠ½è±¡ã€æ›´é«˜å±‚æ¬¡çš„é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜åŒ…å«äº†åŸå§‹è¯¢é—®çš„æœ¬è´¨
      - ä½¿ç”¨LLMç”Ÿæˆä¸€ä¸ªâ€œé€€åä¸€æ­¥â€çš„é—®é¢˜ã€‚è¿™å¯ä»¥ä¸æˆ–ä¸ä½¿ç”¨æ£€ç´¢ä¸€èµ·ä½¿ç”¨ã€‚ä½¿ç”¨æ£€ç´¢æ—¶ï¼Œå°†ä½¿ç”¨â€œé€€åä¸€æ­¥â€é—®é¢˜å’ŒåŸå§‹é—®é¢˜è¿›è¡Œæ£€ç´¢ï¼Œç„¶åä½¿ç”¨ä¸¤ä¸ªç»“æœæ¥ç¡®å®šè¯­è¨€æ¨¡å‹çš„å“åº”
      - https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb
    - Follow Up Questions
      - åœ¨å¯¹è¯é“¾ä¸­å¤„ç†åç»­é—®é¢˜æ—¶ï¼Œæœ€åŸºæœ¬å’Œæ ¸å¿ƒçš„åœ°æ–¹æŸ¥è¯¢è½¬æ¢çš„åº”ç”¨æ˜¯éå¸¸é‡è¦çš„ã€‚åœ¨å¤„ç†åç»­é—®é¢˜æ—¶ï¼ŒåŸºæœ¬ä¸Šæœ‰ä¸‰ç§é€‰æ‹©ï¼š
        - åªéœ€åµŒå…¥åç»­é—®é¢˜ã€‚è¿™æ„å‘³ç€å¦‚æœåç»­é—®é¢˜å»ºç«‹åœ¨æˆ–å‚è€ƒäº†ä¹‹å‰çš„å¯¹è¯ï¼Œå®ƒå°†å¤±å»é‚£ä¸ªé—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘å…ˆé—®â€œåœ¨æ„å¤§åˆ©æˆ‘å¯ä»¥åšä»€ä¹ˆâ€ï¼Œç„¶åé—®â€œé‚£é‡Œæœ‰ä»€ä¹ˆç±»å‹çš„é£Ÿç‰©â€ - å¦‚æœæˆ‘åªåµŒå…¥â€œé‚£é‡Œæœ‰ä»€ä¹ˆç±»å‹çš„é£Ÿç‰©â€ï¼Œæˆ‘å°†æ— æ³•çŸ¥é“â€œé‚£é‡Œâ€æŒ‡çš„æ˜¯å“ªé‡Œã€‚
        - å°†æ•´ä¸ªå¯¹è¯ï¼ˆæˆ–æœ€åçš„ k æ¡æ¶ˆæ¯ï¼‰åµŒå…¥ã€‚è¿™æ ·åšçš„é—®é¢˜åœ¨äºï¼Œå¦‚æœåç»­çš„é—®é¢˜ä¸ä¹‹å‰çš„å¯¹è¯å®Œå…¨æ— å…³ï¼Œé‚£ä¹ˆå®ƒå¯èƒ½ä¼šè¿”å›å®Œå…¨æ— å…³çš„ç»“æœï¼Œè¿™åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¯èƒ½ä¼šé€ æˆå¹²æ‰°ã€‚
        - ä½¿ç”¨LLMè¿›è¡ŒæŸ¥è¯¢è½¬æ¢ï¼
    - Multi Query Retrieval
      - LLMè¢«ç”¨æ¥ç”Ÿæˆå¤šä¸ªæœç´¢æŸ¥è¯¢ã€‚ç„¶åï¼Œè¿™äº›æœç´¢æŸ¥è¯¢å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œå¹¶å°†æ£€ç´¢åˆ°çš„ç»“æœä¸€èµ·ä¼ é€’
      - https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever
    - RAG-Fusion
      - ä¸€ç¯‡è¿‘æœŸçš„æ–‡ç« åŸºäºå¤šæŸ¥è¯¢æ£€ç´¢çš„æ¦‚å¿µè¿›è¡Œæ‹“å±•ã€‚ç„¶è€Œï¼Œä»–ä»¬å¹¶æœªå°†æ‰€æœ‰æ–‡æ¡£ä¸€å¹¶å¤„ç†ï¼Œè€Œæ˜¯ä½¿ç”¨äº’æƒ æ’åèåˆæ¥é‡æ–°æ’åºæ–‡æ¡£ã€‚
      - https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb
    - GATE [Generative Active Task Elicitation](https://mp.weixin.qq.com/s/eKmWN1NOUZBipQPwm8H_rw)
      - ç”Ÿæˆå¼ä¸»åŠ¨ä»»åŠ¡æ¿€å‘ï¼Œä¸å½“ä¸‹å¤§æ¨¡å‹è¢«åŠ¨çš„è·å–ç”¨æˆ·è¾“å…¥ç”Ÿæˆé—®é¢˜ä¸åŒï¼Œæå‡ºäº†é€šè¿‡ä¸»åŠ¨ä¸ç”¨æˆ·å¯¹è¯æ¥å¸®åŠ©ç”¨æˆ·ç”Ÿæˆæ›´æœ‰æ•ˆçš„Promptï¼Œä»è€Œæé«˜LLMsçš„å‡†ç¡®æ€§å’Œå¯ç”¨æ€§ã€‚
      - https://github.com/alextamkin/generative-elicitation
      - ç”Ÿæˆå¼ä¸»åŠ¨å­¦ä¹ ï¼ˆGenerative active learningï¼‰ï¼šå¤§æ¨¡å‹ï¼ˆLMï¼‰ç”Ÿæˆç¤ºä¾‹è¾“å…¥ä¾›ç”¨æˆ·æ ‡è®°ï¼ˆlabelï¼‰ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯å‘ç”¨æˆ·æä¾›å…·ä½“çš„åœºæ™¯ï¼Œå…¶ä¸­åŒ…æ‹¬ä»–ä»¬å¯èƒ½æ²¡æœ‰è€ƒè™‘è¿‡çš„ä¸€äº›åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨å†…å®¹æ¨èæ–¹é¢ï¼ŒLMå¯èƒ½ä¼šç”Ÿæˆä¸€ç¯‡æ–‡ç« ï¼Œå¦‚ï¼šæ‚¨å¯¹ä»¥ä¸‹æ–‡ç« æ„Ÿå…´è¶£å—ï¼ŸThe Art of Fusion Cuisine: Mixing Cultures and Flavorsã€‚
      - ç”Ÿæˆâ€œæ˜¯â€æˆ–â€œå¦â€çš„é—®é¢˜ï¼ˆGenerating yes-or-no questionsï¼‰ï¼šæˆ‘ä»¬é™åˆ¶LMç”ŸæˆäºŒè¿›åˆ¶çš„æ˜¯æˆ–å¦é—®é¢˜ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå¼•å¯¼ç”¨æˆ·æä¾›æ›´æŠ½è±¡çš„åå¥½ï¼ŒåŒæ—¶å¯¹ç”¨æˆ·æ¥è¯´ä¹Ÿå¾ˆå®¹æ˜“å›ç­”ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹å¯èƒ½é€šè¿‡è¯¢é—®ç”¨æˆ·çš„åå¥½æ¥è¿›è¡Œæ¢æµ‹ï¼šDo you enjoy reading articles about health and wellness?
      - ç”Ÿæˆå¼€æ”¾æ€§é—®é¢˜ï¼ˆGenerating open-ended questions ï¼‰ï¼šLMç”Ÿæˆéœ€è¦è‡ªç”±å½¢å¼è‡ªç„¶è¯­è¨€å›ç­”çš„ä»»æ„é—®é¢˜ã€‚è¿™ä½¿å¾—LMèƒ½å¤Ÿå¼•å¯¼è·å–æœ€å¹¿æ³›å’Œæœ€æŠ½è±¡çš„çŸ¥è¯†ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´é—®é¢˜è¿‡äºå®½æ³›æˆ–å¯¹ç”¨æˆ·æ¥è¯´å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¾‹å¦‚ï¼ŒLMå¯èƒ½ä¼šç”Ÿæˆè¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼šWhat hobbies or activities do you enjoy in your free time ..., and why do these hobbies or activities captivate you?
  - https://blog.langchain.dev/query-transformations/
- [Self-RAG](https://mp.weixin.qq.com/s/Z1n4E4Z3DVbOctTY4XfXWw)
  - RAGéå¸¸æœ‰æ•ˆï¼Œä½†å®ƒæ˜¯ä¸€ç§å›ºå®šçš„æ–¹æ³•ã€‚æ— è®ºæ˜¯å¦ç›¸å…³ï¼ˆæˆ–æ ¹æœ¬ä¸éœ€è¦æ£€ç´¢ï¼‰ï¼ŒKä¸ªæ®µè½æ€»æ˜¯è¢«æ£€ç´¢å¹¶æ”¾ç½®åœ¨LLMçš„ä¸Šä¸‹æ–‡ä¸­ã€‚Self-RAGé€šè¿‡æ•™å¯¼LLMåæ€RAGè¿‡ç¨‹å¹¶å†³å®šæ”¹è¿›äº†è¿™ç§æ–¹æ³•ã€‚
    - æ˜¯å¦éœ€è¦æ£€ç´¢
    - å¦‚æœæ£€ç´¢åˆ°çš„å†…å®¹ç¡®å®ç›¸å…³
    - æ— è®ºå…¶äº§å‡ºæ˜¯å¦é«˜è´¨é‡å’ŒçœŸå®
- [æ–‡æ¡£ä¼˜åŒ–ä»¥åŠå¬å›ä¼˜åŒ–](https://juejin.cn/live/jpowermeetup24)
  - æ–‡æ¡£ä¼˜åŒ–
    - é’ˆå¯¹æ–‡æ¡£ç‰¹æ€§é€‰æ‹©embedding model
    - é’ˆå¯¹æ€§çš„æ–‡æ¡£åˆ†æ®µæ¨¡å¼
    - æ–‡æ¡£è½¬åŒ–ä¸ºé—®é¢˜ï¼Œä½¿ç”¨é—®é¢˜å¬å› - é—®é¢˜å¬å›é—®é¢˜æ•ˆæœè¾ƒå¥½
  - å¬å›ä¼˜åŒ–
    - ç”¨æˆ·é—®é¢˜æ”¹å†™ï¼Œä½¿ç”¨æ”¹å†™çš„é—®é¢˜å¬å›
    - å¤šè·¯å¬å›ï¼ˆæŠŠé—®é¢˜æ”¹å†™æˆå¤šä¸ªé—®é¢˜ï¼‰ï¼Œç»“åˆæ–‡æ¡£æ£€ç´¢
    - æŠŠé—®é¢˜ç¼–é€ å‡çš„æ–‡æ¡£ï¼Œä½¿ç”¨å‡æ–‡æ¡£å¬å›
- [è¯„ä¼° RAG çš„TruLens](https://mp.weixin.qq.com/s/4sBQeL0m09_V9Sya1voTqg)
  - https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/vector-dbs/milvus/milvus_evals_build_better_rags.ipynb
- [è¯„ä¼° RAG çš„Ragas](https://mp.weixin.qq.com/s/gFr0zYyOeIEtYgcM9olIYQ)
  - https://github.com/milvus-io/bootcamp/tree/master/evaluation
  - https://github.com/weaviate/recipes/blob/main/integrations/ragas/RAGAs-RAG-langchain.ipynb
  - https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a
  - Ragas æä¾›äº†ä¸ƒä¸ªå…³é”®æŒ‡æ ‡ä»ä¸åŒæ–¹é¢æ¥è¯„ä¼° RAG ç³»ç»Ÿ
    - å¿ å®åº¦ï¼šè¯¥æŒ‡æ ‡è¯„ä¼°ç”Ÿæˆçš„æ–‡æœ¬å‡†ç¡®åæ˜  RAG ç³»ç»Ÿæ£€ç´¢çš„æºæ–‡æ¡£ä¸­å­˜åœ¨çš„ä¿¡æ¯çš„ç¨‹åº¦ã€‚å¿ å®å¯¹äºç¡®ä¿å¢å¼ºè¿‡ç¨‹ä¸ä¼šå¼•å…¥ä¸å‡†ç¡®æˆ–æ‰­æ›²ã€ä¿æŒç”Ÿæˆå†…å®¹çš„å®Œæ•´æ€§è‡³å…³é‡è¦ã€‚
    - ç­”æ¡ˆç›¸å…³æ€§ï¼šå®ƒè¡¡é‡ç”Ÿæˆçš„ç­”æ¡ˆä¸æå‡ºçš„æŸ¥è¯¢çš„ç›¸å…³ç¨‹åº¦ã€‚è¯¥æŒ‡æ ‡å¯¹äºç¡®å®š RAG Pipelineåœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆç”¨è‡³å…³é‡è¦ï¼Œå…¶ç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸ä»…å‡†ç¡®è€Œä¸”ç›´æ¥é€‚ç”¨äºä»–ä»¬çš„é—®é¢˜çš„ä¿¡æ¯ã€‚
    - ä¸Šä¸‹æ–‡è°ƒç”¨ï¼šè¿™è¯„ä¼° RAG ç³»ç»Ÿä»å¤–éƒ¨æ•°æ®æºæ£€ç´¢æ‰€æœ‰ç›¸å…³ä¿¡æ¯çš„èƒ½åŠ›ã€‚é«˜ä¸Šä¸‹æ–‡å›å¿†è¡¨æ˜ç³»ç»Ÿå¯ä»¥ç»¼åˆåˆ©ç”¨å¯ç”¨æ•°æ®ï¼Œè¿™æ˜¯ç”Ÿæˆæ¶ˆæ¯çµé€šä¸”å®Œæ•´çš„å“åº”çš„å…³é”®å› ç´ ã€‚
    - ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦ï¼šä¸å¬å›ç›¸åï¼Œä¸Šä¸‹æ–‡ç²¾ç¡®åº¦è¡¡é‡çš„æ˜¯ä¸å½“å‰ä»»åŠ¡ç›¸å…³çš„æ£€ç´¢ä¿¡æ¯çš„æ¯”ä¾‹ã€‚è¯¥æŒ‡æ ‡ç¡®ä¿ RAG ç³»ç»Ÿæœ‰æ•ˆè¿‡æ»¤æ‰æ— å…³æ•°æ®ï¼Œåœ¨å¢å¼ºè¿‡ç¨‹ä¸­æ³¨é‡è´¨é‡è€Œä¸æ˜¯æ•°é‡ã€‚
    - ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼šå®ƒç»“åˆäº†å¬å›ç‡å’Œç²¾ç¡®åº¦ä¸¤ä¸ªæ–¹é¢ï¼Œè¯„ä¼°RAGç³»ç»Ÿæ‰€ä½¿ç”¨çš„ä¸Šä¸‹æ–‡çš„æ•´ä½“ç›¸å…³æ€§ã€‚è¯¥æŒ‡æ ‡å¼ºè°ƒäº†å¹³è¡¡æ•°æ®æ£€ç´¢æ–¹æ³•çš„é‡è¦æ€§ï¼Œå…¶ä¸­ä¿¡æ¯çš„å¹¿åº¦å’Œç‰¹å¼‚æ€§éƒ½å¾—åˆ°äº†ä¼˜åŒ–ã€‚
    - ç­”æ¡ˆè¯­ä¹‰ç›¸ä¼¼æ€§ï¼šè¯¥æŒ‡æ ‡è¡¡é‡ç”Ÿæˆçš„ç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆï¼ˆæˆ–é¢„æœŸç­”æ¡ˆï¼‰ä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼ŒåŒæ—¶è€ƒè™‘åˆ°è¯­è¨€çš„ç»†å¾®å·®åˆ«ã€‚å¯¹äºéªŒè¯ RAG ç³»ç»Ÿæ˜¯å¦æ•è·å“åº”çš„æ½œåœ¨å«ä¹‰è€Œä¸ä»…ä»…æ˜¯è¡¨é¢æ–¹é¢è‡³å…³é‡è¦ã€‚
    - ç­”æ¡ˆæ­£ç¡®æ€§ï¼šé™¤äº†ç›¸å…³æ€§å’Œè¯­ä¹‰ç›¸ä¼¼æ€§ä¹‹å¤–ï¼Œç­”æ¡ˆæ­£ç¡®æ€§è¿˜ç›´æ¥è¯„ä¼°ç”Ÿæˆæ–‡æœ¬ä¸­æä¾›çš„ä¿¡æ¯çš„å‡†ç¡®æ€§ã€‚è¯¥æŒ‡æ ‡å¯¹äºç¡®ä¿ RAG å¢å¼ºLLMä½œä¸ºå¯é çš„ä¿¡æ¯æ¥æºè‡³å…³é‡è¦ã€‚
- [è¯„ä¼° RAG](https://mp.weixin.qq.com/s/OnfSxBJx_lVYV_MtyViUMw)
  - Ragasï¼ˆhttps://docs.ragas.io/en/latest/concepts/metrics/context_recall.htmlï¼‰æ˜¯ä¸“æ³¨äºè¯„ä¼° RAG åº”ç”¨çš„å·¥å…·
  - Trulens-Evalï¼ˆhttps://www.trulens.org/trulens_eval/install/ï¼‰ä¹Ÿæ˜¯ä¸“é—¨ç”¨äºè¯„ä¼° RAG æŒ‡æ ‡çš„å·¥å…·ï¼Œå®ƒå¯¹ LangChain å’Œ Llama-Index éƒ½æœ‰æ¯”è¾ƒå¥½çš„é›†æˆï¼Œå¯ä»¥æ–¹ä¾¿åœ°ç”¨äºè¯„ä¼°è¿™ä¸¤ä¸ªæ¡†æ¶æ­å»ºçš„ RAG åº”ç”¨
  - [Phoenix](https://github.com/Arize-ai/phoenix)ï¼ˆhttps://docs.arize.com/phoenix/ï¼‰æœ‰è®¸å¤šè¯„ä¼° LLM çš„åŠŸèƒ½ï¼Œæ¯”å¦‚è¯„ä¼° Embedding æ•ˆæœã€è¯„ä¼° LLM æœ¬èº«
    - LLM Traces
    - Tracing with LlamaIndex
    - Tracing with LangChain
    - LLM Evals
  - å›å½’ç°å®ï¼Œä»çœŸå®éœ€æ±‚å‡ºå‘
    - ä¸–ç•ŒçŸ¥è¯†&ç§æœ‰çŸ¥è¯†æ··æ·†çš„: ä¹™çƒ¯å’Œä¸™çƒ¯çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ å¤§æ¨¡å‹åº”è¯¥å›ç­”ä¸¤è€…éƒ½å±äºæœ‰æœºåŒ–åˆç‰©ï¼Œè¿˜æ˜¯æ ¹æ®è¿‘æœŸäº§ä¸šèµ„è®¯å›ç­”ï¼Œä¸¤è€…çš„ä»·æ ¼å‡åœ¨ä¸Šæ¶¨ï¼Ÿ
    - å¬å›ç»“æœæ··æ·†
    - å¤šæ¡ä»¶çº¦æŸå¤±æ•ˆ: Q æ˜¨å¤©ã€Šç‹¬å®¶æ–°é—»ã€‹ç»Ÿè®¡çš„åŒ–å­¦åˆ¶å“è¡Œä¸šçš„å…³æ³¨åº¦æ’åç¬¬å‡ 
    - å…¨æ–‡/å¤šæ–‡ç±»æ„å›¾å¤±æ•ˆ
    - å¤æ‚é€»è¾‘æ¨ç†: Q è¿‘æœŸç¢³é…¸é”‚å’Œç¡«é…¸é•åŒæ—¶ä¸‹è·Œçš„æ—¶å€™ï¼Œå“ªä¸ªåœ¨ä¸Šæ¶¨ï¼Ÿ
  - [RAG Evaluation](https://weaviate.io/blog/rag-evaluation)
  - [Calculate the Total Cost of Your RAG-Based Solutions](https://zilliz.com/blog/how-to-calculate-the-total-cost-of-your-rag-based-solutions)
- [How To Observe Your RAG Post-Deployment](https://www.rungalileo.io/blog/mastering-rag-how-to-observe-your-rag-post-deployment)
- [Seven Failure Points When Engineering a Retrieval Augmented Generation System](https://mp.weixin.qq.com/s/iMTgxYELvESUnCFOglhcYg)
  - ![img.png](ml_rag_failure_points.png)
- [A Cheat Sheet and Some Recipes For Building Advanced RAG](https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b)
  - ![img.png](ml_rag_overview.png)
  - åŸºç¡€ RAG
    - RAG åŒ…æ‹¬ä¸€ä¸ªæ£€ç´¢ç»„ä»¶ã€ä¸€ä¸ªå¤–éƒ¨çŸ¥è¯†åº“å’Œä¸€ä¸ªç”Ÿæˆç»„ä»¶ã€‚
    - é«˜çº§æ£€ç´¢æŠ€æœ¯å¿…é¡»èƒ½å¤Ÿæ‰¾åˆ°ä¸ç”¨æˆ·æŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æ¡£
    - å—å¤§å°ä¼˜åŒ–ï¼ˆChunk-Size Optimizationï¼‰ï¼šç”±äº LLM å—ä¸Šä¸‹æ–‡é•¿åº¦çš„é™åˆ¶ï¼Œå› æ­¤åœ¨å»ºç«‹å¤–éƒ¨çŸ¥è¯†åº“æ—¶æœ‰å¿…è¦å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å—ã€‚åˆ†å—è¿‡å¤§æˆ–è¿‡å°éƒ½ä¼šç»™ç”Ÿæˆç»„ä»¶å¸¦æ¥å½±å“ï¼Œå¯¼è‡´å“åº”ä¸å‡†ç¡®ã€‚
    - ç»“æ„åŒ–çš„å¤–éƒ¨çŸ¥è¯†ï¼ˆStructured External Knowledgeï¼‰ï¼šåœ¨å¤æ‚çš„æƒ…å†µä¸‹ï¼Œå¯èƒ½æœ‰å¿…è¦å»ºç«‹æ¯”åŸºæœ¬å‘é‡ç´¢å¼•æ›´å…·ç»“æ„æ€§çš„å¤–éƒ¨çŸ¥è¯†ï¼Œä»¥ä¾¿åœ¨å¤„ç†åˆç†åˆ†ç¦»çš„å¤–éƒ¨çŸ¥è¯†æºæ—¶å…è®¸é€’å½’æ£€ç´¢æˆ–è·¯ç”±æ£€ç´¢ã€‚
    - ä¿¡æ¯å‹ç¼©ï¼ˆInformation Compressionï¼‰ï¼šLLM ä¸ä»…å—åˆ°ä¸Šä¸‹æ–‡é•¿åº¦çš„é™åˆ¶ï¼Œè€Œä¸”å¦‚æœæ£€ç´¢åˆ°çš„æ–‡æ¡£åŒ…å«å¤ªå¤šå™ªéŸ³ï¼ˆå³æ— å…³ä¿¡æ¯ï¼‰ï¼Œå“åº”é€Ÿåº¦ä¹Ÿä¼šä¸‹é™
    - ç»“æœé‡æ’ï¼ˆResult Re-Rankï¼‰ï¼šLLM å­˜åœ¨æ‰€è°“çš„ "è¿·å¤±åœ¨ä¸­é—´ "ç°è±¡ï¼Œå³ LLM åªå…³æ³¨Promptçš„ä¸¤ç«¯ã€‚æœ‰é‰´äºæ­¤ï¼Œåœ¨å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£äº¤ç»™ç”Ÿæˆç»„ä»¶ä¹‹å‰å¯¹å…¶é‡æ–°æ’åºæ˜¯æœ‰å¥½å¤„çš„ã€‚
- [RAG from scratch]
  - ![img.png](ml_rag_scratch.png)
  - Query Translation: Reviewing/rewriting inputs  
  - Routing: Mapping incoming queries to specific data sources
  - Query Construction: Taking advantage of the underlying structure of a database and metadata filters
  - Indexing: Ingest-time strategies to improve later performance
  - Search methods: Considering techniques beyond vector similarity search  
  - Post-processing: Filtering, reranking, etc.  
  - Generation: Self-correcting and sanity checking retrieved documents
- [RAG ç³»ç»Ÿå¼€å‘ä¸­çš„ 12 å¤§ç—›ç‚¹åŠè§£å†³æ–¹æ¡ˆ](https://baoyu.io/translations/rag/12-rag-pain-points-and-proposed-solutions)
  - ![img.png](rag_failpoint_solution.png)
  - ç¼ºå¤±å†…å®¹
    - æ•°æ®æ¸…æ´—çš„é‡è¦æ€§
    - ç²¾å¿ƒè®¾è®¡çš„æç¤ºæœ‰åŠ©äºæé«˜å‡†ç¡®æ€§
  - å…³é”®æ–‡æ¡£è¢«é—æ¼
    - é€šè¿‡è°ƒæ•´ chunk_size å’Œ similarity_top_k å‚æ•°ä¼˜åŒ–æ£€ç´¢æ•ˆæœ -  [LlamaIndex å®ç°è¶…å‚æ•°è‡ªåŠ¨è°ƒæ•´](https://levelup.gitconnected.com/automating-hyperparameter-tuning-with-llamaindex-72fdd68e3b90)
    - æ£€ç´¢ç»“æœçš„ä¼˜åŒ–æ’åº 
      - å…ˆæå–å‰åä¸ªèŠ‚ç‚¹ï¼Œå†ç”¨ CohereRerank è¿›è¡Œä¼˜åŒ–æ’åºï¼Œç²¾é€‰å‡ºæœ€ç›¸å…³çš„ä¸¤ä¸ªèŠ‚ç‚¹ã€‚
      - Boosting RAG: Picking the Best Embedding & Reranker models
      - Improving Retrieval Performance by Fine-tuning Cohere Reranker with LlamaIndex
  - æ–‡æ¡£æ•´åˆé™åˆ¶ â€”â€” è¶…å‡ºä¸Šä¸‹æ–‡
    - è°ƒæ•´æ£€ç´¢ç­–ç•¥ é«˜çº§æ£€ç´¢ä¸æœç´¢ã€è‡ªåŠ¨æ£€ç´¢ã€çŸ¥è¯†å›¾è°±æ£€ç´¢
- [Semantic Chunking for RAG](https://pub.towardsai.net/advanced-rag-05-exploring-semantic-chunking-97c12af20a4d)
  - Embedding-based chunking 
  -  BERT-based chunking techniques (naive, cross-segment, SeqModel)
  -  LLM-based chunking
- [æå‡RAGæ£€ç´¢è´¨é‡](https://mp.weixin.qq.com/s/rjsymQQwgE78fNZ60opE0w)
  - æŸ¥è¯¢æ‰©å±•ï¼ˆQuery expansionï¼‰
    - ä½¿ç”¨ç”Ÿæˆçš„ç­”æ¡ˆè¿›è¡ŒæŸ¥è¯¢æ‰©å±•
    - ç”¨å¤šä¸ªç›¸å…³é—®é¢˜æ‰©å±•æŸ¥è¯¢
      - åˆ©ç”¨ LLM ç”Ÿæˆ N ä¸ªä¸åŸå§‹æŸ¥è¯¢ç›¸å…³çš„é—®é¢˜ï¼Œç„¶åå°†æ‰€æœ‰é—®é¢˜ï¼ˆåŠ ä¸ŠåŸå§‹æŸ¥è¯¢ï¼‰å‘é€ç»™æ£€ç´¢ç³»ç»Ÿ
  - è·¨ç¼–ç å™¨é‡æ’åºï¼ˆCross-encoder re-rankingï¼‰
    - æ ¹æ®è¾“å…¥æŸ¥è¯¢ä¸æ£€ç´¢åˆ°çš„æ–‡æ¡£çš„ç›¸å…³æ€§çš„åˆ†æ•°å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº
    - äº¤å‰ç¼–ç å™¨æ˜¯ä¸€ç§æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå®ƒå°†ä¸¤ä¸ªè¾“å…¥åºåˆ—ä½œä¸ºä¸€ä¸ªè¾“å…¥è¿›è¡Œå¤„ç†ã€‚è¿™æ ·ï¼Œæ¨¡å‹å°±èƒ½ç›´æ¥æ¯”è¾ƒå’Œå¯¹æ¯”è¾“å…¥ï¼Œä»¥æ›´ç»¼åˆã€æ›´ç»†è‡´çš„æ–¹å¼ç†è§£å®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚
  - åµŒå…¥é€‚é…å™¨ï¼ˆEmbedding adaptorsï¼‰ï¼Œå¯ä»¥æ”¯æŒæ£€ç´¢åˆ°æ›´å¤šä¸ç”¨æˆ·æŸ¥è¯¢å¯†åˆ‡åŒ¹é…çš„ç›¸å…³æ–‡æ¡£
    - é€‚é…å™¨æ˜¯ä»¥å°å‹å‰é¦ˆç¥ç»ç½‘ç»œçš„å½¢å¼å®ç°çš„ï¼Œæ’å…¥åˆ°é¢„è®­ç»ƒæ¨¡å‹çš„å±‚ä¹‹é—´ã€‚è®­ç»ƒé€‚é…å™¨çš„æ ¹æœ¬ç›®çš„æ˜¯æ”¹å˜åµŒå…¥æŸ¥è¯¢ï¼Œä»è€Œä¸ºç‰¹å®šä»»åŠ¡äº§ç”Ÿæ›´å¥½çš„æ£€ç´¢ç»“æœã€‚
    - åµŒå…¥é€‚é…å™¨æ˜¯åœ¨åµŒå…¥é˜¶æ®µä¹‹åã€æ£€ç´¢ä¹‹å‰æ’å…¥çš„ä¸€ä¸ªé˜¶æ®µã€‚å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªçŸ©é˜µï¼ˆå¸¦æœ‰ç»è¿‡è®­ç»ƒçš„æƒé‡ï¼‰ï¼Œå®ƒé‡‡ç”¨åŸå§‹åµŒå…¥å¹¶å¯¹å…¶è¿›è¡Œç¼©æ”¾ã€‚
  - [Retrieval-Augmented Generation for Large Language Models: A Survey](https://mp.weixin.qq.com/s/3WAWy4ZV6Ezft_2MJHMgtg)
  - [å¥å­çª—å£æ£€ç´¢](https://mp.weixin.qq.com/s/crYM5_xdZD7Rh3snnLWphg)
    - é¦–å…ˆåœ¨æ–‡æ¡£åˆ‡åˆ†æ—¶ï¼Œå°†æ–‡æ¡£ä»¥å¥å­ä¸ºå•ä½è¿›è¡Œåˆ‡åˆ†ï¼ŒåŒæ—¶è¿›è¡Œ Embedding å¹¶ä¿å­˜æ•°æ®åº“ã€‚
    - ç„¶ååœ¨æ£€ç´¢æ—¶ï¼Œé€šè¿‡é—®é¢˜æ£€ç´¢åˆ°ç›¸å…³çš„å¥å­ï¼Œä½†å¹¶ä¸åªæ˜¯å°†æ£€ç´¢åˆ°çš„å¥å­ä½œä¸ºæ£€ç´¢ç»“æœï¼Œè€Œæ˜¯å°†è¯¥å¥å­å‰é¢å’Œåé¢çš„å¥å­ä¸€èµ·ä½œä¸ºæ£€ç´¢ç»“æœï¼ŒåŒ…å«çš„å¥å­æ•°é‡å¯ä»¥é€šè¿‡å‚æ•°æ¥è¿›è¡Œè®¾ç½®ï¼Œæœ€åå°†æ£€ç´¢ç»“æœå†ä¸€èµ·æäº¤ç»™ LLM æ¥ç”Ÿæˆç­”æ¡ˆã€‚
- [When Simple RAG Fails](https://docs.google.com/presentation/d/12iRlcv-m47cCxEaIMwexrZ1a1xzg4QE9eUwVoafLvvY/edit#slide=id.g2a22202e9fb_0_167)
  - Questions are not relevant to corpus
  - Questions are vague
  - Questions are not about fact retrieval
  - Questions contain multiple sub questions
  - Questions require multi-hop logic
  - Questions include some non-semantic components
  - Conflicting information
  - [Langchain query analysis](https://python.langchain.com/docs/use_cases/query_analysis/)
- [RAG 2.0]
  - å°†æ‰€æœ‰ç»„ä»¶ä½œä¸ºå•ä¸ªé›†æˆç³»ç»Ÿè¿›è¡Œé¢„è®­ç»ƒã€å¾®è°ƒå’Œå¯¹é½ï¼Œé€šè¿‡è¯­è¨€æ¨¡å‹å’Œæ£€ç´¢å™¨è¿›è¡Œåå‘ä¼ æ’­ä»¥æœ€å¤§åŒ–æ€§èƒ½ï¼šå¯¹é½ä¸ºä¸€ä¸ªé›†æˆçš„ç³»ç»Ÿï¼Œé€šè¿‡è¯­è¨€æ¨¡å‹å’Œæ£€ç´¢å™¨è¿›è¡Œåå‘ä¼ æ’­ä»¥æœ€å¤§åŒ–æ€§èƒ½
  - éœ€è¦ç«¯åˆ°ç«¯çš„ä»å¬å›ï¼Œç²—æ’ï¼Œç²¾æ’ï¼Œé‡æ’ç¯èŠ‚ä½œä¸ºæ•´ä½“æ¥ä¼˜åŒ–ï¼Œé¿å…å½¢æˆé”™é…. RAG 2.0æ–¹æ³•å°±æ˜¯å…‹æœè¿™æ ·çš„å±€éƒ¨ä¼˜åŒ–åŠæ³•ï¼Œé€šè¿‡å°†é¢„è®­ç»ƒã€å¾®è°ƒå’Œå¯¹é½æ‰€æœ‰ç»„ä»¶å½¢æˆä¸€ä¸ªç»Ÿä¸€ç³»ç»Ÿï¼Œé€šè¿‡åå‘ä¼ æ’­åŒæ—¶ä¼˜åŒ–è¯­è¨€æ¨¡å‹å’Œæ£€ç´¢å™¨ï¼Œä»¥æœ€å¤§åŒ–ç³»ç»Ÿæ€§èƒ½
  - å¼€æ”¾åŸŸé—®ç­”ï¼šä½¿ç”¨æ ‡å‡†çš„Natural Questionsï¼ˆNQï¼‰å’ŒTriviaQAæ•°æ®é›†æ¥æµ‹è¯•æ¯ä¸ªæ¨¡å‹æ­£ç¡®æ£€ç´¢ç›¸å…³çŸ¥è¯†å¹¶å‡†ç¡®ç”Ÿæˆç­”æ¡ˆçš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†æ¨¡å‹åœ¨HotpotQAï¼ˆHPQAï¼‰æ•°æ®é›†ä¸Šå•æ­¥æ£€ç´¢è®¾ç½®ä¸‹çš„è¡¨ç°ã€‚æ‰€æœ‰æ•°æ®é›†å‡ä½¿ç”¨å®Œå…¨åŒ¹é…ï¼ˆEMï¼‰æŒ‡æ ‡ã€‚
  - å¿ å®åº¦ï¼šHaluEvalQAå’ŒTruthfulQAè¢«ç”¨æ¥è¡¡é‡æ¯ä¸ªæ¨¡å‹ä¿æŒåŸºäºæ£€ç´¢è¯æ®çš„å¿ å®åº¦ä»¥åŠé¿å…äº§ç”Ÿå¹»è§‰çš„èƒ½åŠ›ã€‚
  - æ–°é¢–åº¦ï¼šé€šè¿‡ä½¿ç”¨ç½‘ç»œæœç´¢ç´¢å¼•æ¥è¡¡é‡æ¯ä¸ªRAGç³»ç»Ÿå¯¹å¿«é€Ÿå˜åŒ–çš„ä¸–ç•ŒçŸ¥è¯†çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å±•ç¤ºäº†åœ¨æœ€è¿‘çš„FreshQAåŸºå‡†æµ‹è¯•ä¸­çš„å‡†ç¡®æ€§ã€‚
- [RAG: LLM Prompting Techniques For Reducing Hallucinations](https://www.rungalileo.io/blog/mastering-rag-llm-prompting-techniques-for-reducing-hallucinations)
  - Thread of Thought(ThoT)
    - `Walk me through this context in manageable parts step by step, summarizing and analyzing as we go`
  - Chain of Note(CoN)
    - The steps in CoN involve generating sequential reading notes for retrieved documents, 
    - facilitating a comprehensive evaluation of their relevance, and integrating this information to formulate the final answer.
  - Chain of Verification(CoVe)
    - Baseline Response Generation: In response to a given query, the model generates a baseline response. 
    - Verification Planning: Considering both the query and baseline response, a list of verification questions is generated to facilitate self-analysis and identify potential errors in the original response.
    - Verification Execution: Each verification question is systematically answered, allowing for a comparison with the original response to identify inconsistencies or mistakes.
    - Final Verified Response Generation: Based on any discovered inconsistencies, if present, a revised response is generated, incorporating the results of the verification process.
  - EmotionPrompt
    - `This is very important to my career`
  - ExpertPrompting
- [Is RAG Really Dead](https://docs.google.com/presentation/d/1mJUiPBdtf58NfuSEQ7pVSEQ2Oqmek7F1i4gBwR6JDss/edit#slide=id.g26c0cb8dc66_0_0)
- [Mastering RAG](https://www.rungalileo.io/blog/mastering-rag-how-to-architect-an-enterprise-rag-system)
  - ![img.png](rag_failure_point.png)
    - Cognitive reviewer: Cognitive reviewer is a RAG system designed to assist researchers in analyzing scientific documents. Researchers define a research question or objective and upload a collection of related research papers
    - AI Tutor, another RAG system, enables students to ask questions about a unit and receive answers sourced from learning content
    - Biomedical Q&A, a RAG system was created using the BioASQ dataset, containing questions, document links, and answers
  - Chunk
   
   | Technique                     | Usecase       | Pros                                                                                                             | Cons                                                                                          |
   |-------------------------------|---------------|------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|
   | **Character splitter**        | Text          | Versatile: Handles various separators<br>Flexible: Adapts to different languages<br>Cost-Effective: Does not require an ML model                                           | Performance: May have increased computational load<br>Complexity: Requires parameter tuning<br>Sentence Interruption: May cut sentences midway          |
   | **Recursive character splitter** | Text, code    | Versatile: Handles various separators<br>Flexible: Adapts to different languages<br>Cost-Effective: Does not require an ML model                                           | Performance: Recursive nature may increase computational load<br>Complexity: Requires parameter tuning<br>Sentence Interruption: May cut sentences midway |
   | **Sentence splitter**         | Text          | Considers Sentence Boundaries: Avoids cutting sentences prematurely<br>Customizable: Parameters for stride and overlap<br>Cost-Effective: Works with light sentence segmenter | Lack of Versatility: Limited to sentence-based chunks<br>Overlap Issues: May lead to redundancy                                                      |
   | **Semantic splitter**         | Text, Chat    | Contextual Grouping: Organizes text based on semantic similarity<br>Overcomes Challenges: Handles chunk size and overlap                                                 | Complexity: Requires similarity model and tuning<br>Parameter Dependency: Relies on setting appropriate parameters<br>Resource Intensive: Demands computational resources         |
   | **Propositions**              | Text, Chat    | Atomic Expression: Introduces novel retrieval unit (propositions)<br>Distinct Factoids: Each proposition is self-contained<br>Contextualization: Provides necessary context | Complexity: Requires LLM model<br>Parameter Dependency: Relies on setting appropriate prompt<br>Resource Intensive: Demands computational resources                              |
   
  - Prompt
    
    | Name                 | How it works?                                                    | Ease of implementation | Increase of input token | Increase of output token |
    |----------------------|------------------------------------------------------------------|------------------------|-------------------------|--------------------------|
    | **Thread of Thought (ToT)** | Break down and analyzes extensive contexts for selecting relevant information | Easy                   | Yes                     | Yes                      |
    | **Chain of Note (CoN)**     | Generate sequential reading notes for retrieved documents > evaluate their relevance to the given question > integrate information to formulate the final answer | Easy | Yes | Yes |
    | **Chain of Verification (CoV)** | Draft a response > plan verification questions > answer those questions independently > generate final verified response | Hard | Yes | Yes |
    | **EmotionPrompt**          | Add an emotional prompt to the original prompt                  | Easy                   | Yes                     | No                       |
    | **ExpertPrompting**        | Add synthesized expert background generated with another few shot prompt | Easy | Yes | No |
  - Techniques for improving retrieval
    - [Hypothetical document embeddings (HyDE)](https://docs.haystack.deepset.ai/docs/hypothetical-document-embeddings-hyde)
      - The HyDE method is highly useful when:
        - The performance of the retrieval step in your Pipeline is not good enough (for example, low Recall metric).
        - Your retrieval step has a query as input and returns documents from a larger document base.
        - Particularly worth a try if your data (documents or queries) come from a special domain that is very different from the typical datasets that Retrievers are trained on.
    - Query routing
      - Query routing proves advantageous when dealing with multiple indexes, directing queries to the most relevant index for efficient retrieval
    - [Reranker](https://mp.weixin.qq.com/s/LVoJ5uG0AiaRD6bAqJYRGQ)
      - When retrieval from the encoder falls short of delivering optimal quality, a reranker is used to enhance the document ranking
      - [What is a Reranker](https://zilliz.com/learn/optimize-rag-with-rerankers-the-role-and-tradeoffs) ä¸»è¦åœ¨æ‹¿åˆ°å‘é‡æŸ¥è¯¢ï¼ˆANNï¼‰çš„ç»“æœåä½¿ç”¨ Rerankerï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ç¡®å®šæ–‡æ¡£å’ŒæŸ¥è¯¢ä¹‹é—´çš„è¯­ä¹‰ç›¸å…³æ€§ï¼Œæ›´ç²¾ç»†åœ°å¯¹ç»“æœé‡æ’ï¼Œæœ€ç»ˆæé«˜æœç´¢è´¨é‡ã€‚
        - Reranker ç±»å‹ä¸»è¦æœ‰ä¸¤ç§â€”â€”åŸºäºç»Ÿè®¡å’ŒåŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ Reranker
          - Score-based rerankers, åŸºäºç»Ÿè®¡çš„ Reranker ä¼šæ±‡æ€»å¤šä¸ªæ¥æºçš„å€™é€‰ç»“æœåˆ—è¡¨ï¼Œä½¿ç”¨å¤šè·¯å¬å›çš„åŠ æƒå¾—åˆ†æˆ–å€’æ•°æ’åèåˆï¼ˆRRFï¼‰ç®—æ³•æ¥ä¸ºæ‰€æœ‰ç»“æœé‡æ–°ç®—åˆ†
          - Neural Network-based rerankers, åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ Rerankerï¼Œé€šå¸¸è¢«ç§°ä¸º Cross-encoder Reranker,è¿™ç±» Reranker å¯ä»¥ä¸ºé—®é¢˜å’Œæ–‡æ¡£ä¹‹é—´çš„è¯­ä¹‰çš„ç›¸ä¼¼åº¦è¿›è¡Œæ‰“åˆ†
      - Reranker
        - LLMRanker - In LLMRerank the query and nodes are passed to a Large language model which returns the relevance for the nodes.
        - Cohere - uses semantic relevance to rerank the nodes
        - SentenceTransformerRerank - Uses the cross-encoders from the sentence-transformer package to re-order nodes 
        - KeywordNodePostprocessor - is Used to ensure certain keywords are either excluded or included in a node.
      - ä½¿ç”¨ Reranker çš„æˆæœ¬
        - Reranker ä¼šæ˜¾è‘—å¢åŠ æœç´¢å»¶è¿Ÿ
        - Reranker ä¼šå¤§å¹…åº¦æé«˜è®¡ç®—æˆæœ¬
      - å“ªç§æƒ…å†µé€‚åˆåœ¨ RAG åº”ç”¨ä¸­ä½¿ç”¨ Reranker
        - è¿½æ±‚å›ç­”é«˜ç²¾åº¦å’Œé«˜ç›¸å…³æ€§çš„åœºæ™¯ä¸­ç‰¹åˆ«é€‚åˆä½¿ç”¨ Rerankerï¼Œä¾‹å¦‚ä¸“ä¸šçŸ¥è¯†åº“æˆ–è€…å®¢æœç³»ç»Ÿç­‰åº”ç”¨ã€‚
        - åœ¨ç½‘é¡µæœç´¢ã€ç”µå•†æœç´¢è¿™ç±»åœºæ™¯ä¸­ï¼Œå“åº”é€Ÿåº¦å’Œæˆæœ¬è‡³å…³é‡è¦ï¼Œå› æ­¤ä¸å¤ªé€‚åˆä½¿ç”¨ä»£ä»·é«˜æ˜‚çš„ Cross-Encoder Rerankerã€‚æ­¤ç±»åº”ç”¨åœºæ™¯æ›´é€‚åˆé€‰ç”¨å‘é‡æ£€ç´¢æ­é…æ›´è½»é‡çš„ Score-based Rerankerï¼Œä»è€Œç¡®ä¿å“åº”é€Ÿåº¦ï¼Œåœ¨æå‡æœç´¢è´¨é‡çš„åŒæ—¶é™ä½å¼€é”€
      - [How to Select A Reranking Model](https://www.rungalileo.io/blog/mastering-rag-how-to-select-a-reranking-model)
        - ![img.png](rag_reranker.png)
    - auto-merging retrieval
      - a bunch of nearby context chunks are retrieved, merge them into one bigger â€œchunkâ€ so the LLM has a holistic view of the larger document.
      - https://generativeai.pub/advanced-rag-retrieval-strategies-auto-merging-retrieval-dc3f869654c4
- [Enhance the Performance of Your RAG Pipeline](https://zilliz.com/learn/how-to-enhance-the-performance-of-your-rag-pipeline)
  - Query Enhancement: Modifying and manipulating the query process of the RAG input to better express or process the query intent.
    - Creating Hypothetical Questions
    - HyDE (Hypothetical Document Embeddings)
    - Creating Sub-Queries
    - Creating Stepback Prompts: involves abstracting complicated user queries into "stepback questions" using an LLM
  - Indexing Enhancement: Optimizing the creation of chunking indexes using techniques such as multi-chunking, step-wise indexing, or multi-way indexing.
    - Merging Document Chunks Automatically
    - Constructing Hierarchical Indices - two-level index: one for document summaries and another for document chunks
    - Hybrid Retrieval and Reranking
  - Retriever Enhancement: Applying optimization techniques and strategies during the retrieval process.
    - Sentence Window Retrieval - decouples the document chunk used for embedding retrieval from the chunk provided to the LLM.
    - Meta-data Filtering - 
  - Generator Enhancement: Adjusting and optimizing prompts when assembling prompts for the LLM to provide better responses.
    - Compressing the LLM prompt
    - Adjusting the chunk order in the prompt - `Lost in th middle`
  - RAG Pipeline Enhancement: Dynamically switching processes within the entire RAG pipeline, including using agents or tools to optimize key steps in the RAG pipeline.
    - Self-reflection
    - Query Routing with an Agent
- ç¨ å¯†ã€ç¨€ç–å’ŒäºŒè¿›åˆ¶ embedding å‘é‡ï¼Œå®ƒä»¬å„è‡ªçš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿
- [ColBert](https://mp.weixin.qq.com/s/rvTkr2ttyxqo6TvyCxMx_A)
  - ç¨ å¯†å‘é‡ç”Ÿæˆå’Œæ£€ç´¢çš„ BERTï¼Œä»¥åŠç”¨äºç¨€ç–å‘é‡ç”Ÿæˆå’Œæ£€ç´¢çš„ SPLADE å’ŒBGE-M3ã€‚
  - ColBERTâ€”â€”ä¸“ä¸ºé«˜æ•ˆç›¸ä¼¼æ€§æœç´¢è€Œè®¾è®¡çš„åˆ›æ–°å‹ embedding å’Œæ’åºï¼ˆrankingï¼‰
    - Bert
      - BERT ä»å¥å­çš„å·¦ä¾§åˆ°å³ä¾§æˆ–ç›¸åæ–¹å‘è¿›è¡Œç§»åŠ¨ï¼Œé€šè¿‡åŒæ—¶åˆ†ææ•´ä¸ªå•è¯åºåˆ—ç»“åˆå•è¯ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œç”Ÿæˆç¨ å¯†å‘é‡
      - BERT é€šè¿‡ embedding çŸ©é˜µå°†tokenå˜ä¸ºå‘é‡ï¼Œå¹¶ä¸”é€šè¿‡å¤šå±‚ç¼–ç å™¨å°†å…¶è¿›è¡Œæ·±å±‚æ¬¡çš„ç¼–ç ã€‚
      - è¿™äº›å±‚æ ¹æ®åºåˆ—ä¸­æ‰€æœ‰å…¶ä»–tokenæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¹æ¯ä¸ªtokençš„è¡¨ç¤ºè¿›è¡ŒåŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç»†åŒ–ã€‚
      - æœ€åï¼Œä½¿ç”¨æ± åŒ–æ“ä½œå°†æ‰€æœ‰ token å‘é‡è½¬åŒ–æˆå•ä¸€çš„ç¨ å¯†å‘é‡
    - ColBERT ä¿ç•™äº† token çº§åˆ«çš„ embeddingï¼Œé€šè¿‡å…¶åˆ›æ–°çš„åæœŸäº¤äº’æœºåˆ¶å®ç°äº†æ›´ç²¾ç¡®å’Œç»†ç²’åº¦çš„ç›¸ä¼¼æ€§è®¡ç®—
    - ColBERTv2â€”â€”é€šè¿‡ PQ å’ŒåŸºäºè´¨å¿ƒçš„ç¼–ç æ¥å‡è½»å­˜å‚¨æ¶ˆè€—çš„ä¼˜åŒ–ç‰ˆColBERTã€‚è¿™äº›æ”¹è¿›æœ‰æ•ˆæé«˜äº†å­˜å‚¨æ•ˆç‡ï¼Œå¹¶ä¿æŒäº†æ¨¡å‹çš„æ£€ç´¢æ•ˆæœã€‚
- [ç”Ÿæˆå¼AIåº”ç”¨æ¶æ„å’Œæˆç†Ÿåº¦æ¨¡å‹](https://mp.weixin.qq.com/s/z7cdcJVcMRB-PvwMVnxRJg)
  - https://dr-arsanjani.medium.com/the-genai-reference-architecture-605929ab6b5a
- A Survey of Techniques for Maximizing LLM Performance
  - https://www.youtube.com/watch?v=ahnGLM-RC1Y
  - notes
    - https://ihower.tw/notes/%E6%8A%80%E8%A1%93%E7%AD%86%E8%A8%98-AI/2023/A+Survey+of+Techniques+for+Maximizing+LLM+Performance+(OpenAI+DevDay)
  - å…ˆå¾ Prompt engineering é–‹å§‹åšï¼Œå¾—åˆ° evaluation
    - å¦‚æœæ˜¯ context å•é¡Œï¼Œåš RAG
    - å¦‚æœæ˜¯ model act problemï¼Œéœ€è¦æ›´ä¸€è‡´çš„éµå®ˆæŒ‡ç¤ºï¼Œåš Fine-tuning
    - æˆ–æ˜¯å…©è€…éƒ½éœ€è¦
  - RAG
    - HyDE: ç”¢ç”Ÿ fake answers ä¾†åšç›¸ä¼¼æ€§æœå°‹
    -  å¾®èª¿ Embeddings: å¾æº–ç¢ºç‡ä¾†èªªæœ‰å¹«åŠ©ï¼Œä½†å¤ªè²´å¤ªæ…¢äº†ï¼Œæ‰€ä»¥æ”¾æ£„ (non-functional ç†ç”±)
    -  å¯¦é©—ä¸åŒå¤§å°çš„ chunksã€embedding ä¸åŒ bits çš„å…§å®¹
    -  å˜—è©¦äº† 20 æ¬¡è¿­ä»£æ‰å¢å¼·åˆ° 65%
    -  re-ranking: cross encoder æˆ– relues-based stuff
    -  classification step: å…ˆè®“æ¨¡å‹åˆ†é¡æ˜¯å“ªä¸€ç¨® domainï¼Œå†å¢åŠ é¡å¤–ä¸åŒçš„ metadata åˆ° promptï¼Œä¾†å¹«åŠ©æ‰¾åˆ°æœ€ç›¸é—œçš„å…§å®¹ çœ‹çœ‹æ˜¯å“ªäº›é¡å‹çš„å•é¡Œç­”éŒ¯
    -  query expansion: ç”¢ç”Ÿå¤šç¨® query å¹³è¡ŒæŸ¥ï¼Œå†åˆä½µçµæœ
- [What We Learned from a Year of Building with LLMs](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)
  - tactical,
    - Prompting
      - Focus on getting the most out of fundamental prompting techniques
      - n-shot prompts + in-context learning, chain-of-thought, and providing relevant resources
      - tips
        - If n is too low, the model may over-anchor on those specific examples, hurting its ability to generalize. As a rule of thumb, aim for n â‰¥ 5. Donâ€™t be afraid to go as high as a few dozen.
        - Examples should be representative of the expected input distribution. If youâ€™re building a movie summarizer, include samples from different genres in roughly the proportion you expect to see in practice.
        - You donâ€™t necessarily need to provide the full input-output pairs. In many cases, examples of desired outputs are sufficient.
        - If you are using an LLM that supports tool use, your n-shot examples should also use the tools you want the agent to use.
      - COT it helpful to make the CoT more specific, where adding specificity via an extra sentence or two often reduces hallucination rates significantly
        - summarize a meeting transcript
        ```
        First, list the key decisions, follow-up items, and associated owners in a sketchpad.
        Then, check that the details in the sketchpad are factually consistent with the transcript.
        Finally, synthesize the key points into a concise summary.
        ```
    - Structure your inputs and outputs
      - Claude prefers xml while GPT favors Markdown and JSON
    - Have small prompts that do one thing, and only one thing
    - Long-context models wonâ€™t make RAG obsolete
      - First, even with a context window of 10M tokens, weâ€™d still need a way to select information to feed into the model.
      - Second, beyond the narrow needle-in-a-haystack eval, weâ€™ve yet to see convincing data that models can effectively reason over such a large context
      - Finally, thereâ€™s cost
    - Getting more diverse outputs beyond temperature
      - The simplest way is to adjust elements within the prompt.
        - if the prompt template includes a list of items, such as historical purchases, shuffling the order of these items each time theyâ€™re inserted into the prompt can make a significant difference.
      - keeping a short list of recent outputs can help prevent redundancy.
        - In our recommended products example, by instructing the LLM to avoid suggesting items from this recent list, or by rejecting and resampling outputs that are similar to recent suggestions, we can further diversify the responses
        -  incorporating phrases like â€œpick an item that the user would love using regularlyâ€ or â€œselect a product that the user would likely recommend to friendsâ€ can shift the focus and thereby influence the variety of recommended products.
  - operational
  - and strategic
- [Beyond RAG: Building Advanced Context-Augmented LLM Applications](https://docs.google.com/presentation/d/1IWjo8bhoatWccCfGLYw_QhUI4zfF-MujN3ORIDCBIbc/edit#slide=id.g2bac367b3d6_0_0)
  - [Agent Course](https://huggingface.co/learn/agents-course/unit0/introduction)
  - [12-factor-agents](https://github.com/humanlayer/12-factor-agents)
  - RAG Pains
    - Summarization Questions: â€œGive me a summary of the entire <company> 10K annual reportâ€
    - Comparison Questions: â€œCompare the open-source contributions of candidate A and candidate Bâ€
    - Structured Analytics + Semantic Search: â€œTell me about the risk factors of the highest-performing rideshare company in the USâ€
    - General Multi-part Questions: â€œTell me about the pro-X arguments in article A, and tell me about the pro-Y arguments in article B, make a table based on our internal style guide, then generate your own conclusion based on these facts.â€
  - Agent ingredients
    - Letâ€™s put them together for a full agent system
    - Query planning
    - Memory
    - Tool Use
  - Letâ€™s add additional components
    - Reflection
    - Controllability
    - Observability
  - [RAG agent](https://talks.nerdai.io/vector-ess-oss-06-13-2024)
    - https://github.com/milvus-io/bootcamp/blob/master/bootcamp/RAG/advanced_rag/langgraph-rag-agent-local.ipynb
  - [What is an agent](https://blog.langchain.dev/what-is-an-agent/)
    - æ˜¯ä¸€å¥—ç³»ç»Ÿ
    - è¿™å¥—ç³»ç»Ÿå†³ç­–çš„æ˜¯åº”ç”¨ç¨‹åºçš„æ§åˆ¶æµ
    - è¦å€ŸåŠ©å¤§è¯­è¨€æ¨¡å‹æ¥è§„åˆ’å†³ç­–
  - [Build an agent with llamaindex](https://docs.llamaindex.ai/en/stable/understanding/agent/tools/)
    - 1. Building a basic agent, with and without local models
    - 2. Adding RAG + data processing to an agent
    - 3. Adding memory to an agent
    - 4. Equipping with our tools from LlamaHub
  - [Agentè¿›åŒ–çš„ä¸‰ä¸ªç­‰çº§](https://x.com/yoheinakajima/status/1839398354364838366?s=46)
    - L1ï¼šåŸºäºè¯·æ±‚
      - ç”¨æˆ·å¯ä»¥è¦æ±‚äººå·¥æ™ºèƒ½ç”Ÿæˆå‡½æ•°ï¼Œå½“ä»–ä»¬æŸ¥è¯¢ç³»ç»Ÿæ—¶ï¼Œæ–°å‡½æ•°å°±ä¼šä½œä¸ºä¸€ä¸ªé€‰é¡¹ä¾›äººå·¥æ™ºèƒ½ä½¿ç”¨ã€‚
    - L2ï¼šåŸºäºéœ€æ±‚
      - å½“ç”¨æˆ·æäº¤æŸ¥è¯¢æ—¶ï¼Œäººå·¥æ™ºèƒ½é¦–å…ˆä¼šåˆ¤æ–­ç°æœ‰å‡½æ•°æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æœæ— æ•ˆï¼Œåˆ™ä¼šç”Ÿæˆä¸€ä¸ªæ–°çš„å¯é‡ç”¨å‡½æ•°ï¼Œæ ¹æ®ç”¨æˆ·çš„åŸå§‹è¾“å…¥ç”Ÿæˆå‚æ•°ï¼Œå¹¶æ‰§è¡Œæ–°å‡½æ•°æ¥å¤„ç†æŸ¥è¯¢ã€‚
    - L3ï¼šé¢„è§æ€§
      - æ ¹æ®å¯¹ç”¨æˆ·çš„ç†è§£ç”ŸæˆåˆæˆæŸ¥è¯¢çš„ç³»ç»Ÿï¼Œæ¯ä¸ªæŸ¥è¯¢éƒ½ä¼šè¾“å…¥ç³»ç»Ÿ 2 ï¼ˆåŸºäºéœ€æ±‚çš„ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿä¼šæ ¹æ®éœ€è¦ç”Ÿæˆæ‰€éœ€çš„åŠŸèƒ½ï¼‰ã€‚æœ€ç»ˆå½¢æˆä¸€ä¸ªå¯è‡ªä¸»ç”ŸæˆåŠŸèƒ½çš„ç³»ç»Ÿ
      - ä»–è¿˜ç»™å‡ºäº†L3 AgentåŸå‹å±•ç¤ºï¼š
        - ç”¨æˆ·æè¿°ä½œä¸ºè¾“å…¥
        - ç”ŸæˆæŸ¥è¯¢
        - å¤„ç†æŸ¥è¯¢
        - ç”Ÿæˆå¹¶å­˜å‚¨é’ˆå¯¹è¯¥æŸ¥è¯¢çš„å¤šä¸ªå¯é‡ç”¨å‡½æ•°
  - [Orchestrating Agents: Routines and Handoffs](https://github.com/openai/openai-cookbook/blob/main/examples/Orchestrating_agents.ipynb)
  - Handoff æ¨¡å¼
  - [o1æ­£åœ¨é‡å¡‘Agent](https://mp.weixin.qq.com/s/R33WBLPzpkdj_P3UbNG4Dg)
    - [Using reasoning for routine generation](https://cookbook.openai.com/examples/o1/using_reasoning_for_routine_generation)
      - Actionå¯ä»¥è¢«åˆ†ä¸ºå››ç±»ï¼š
        - Function Callï¼ˆé»‘è‰²ï¼‰ï¼šç”Ÿæˆå¹¶è°ƒç”¨ç›¸å…³APIï¼Œä¾‹å¦‚éªŒè¯ç”¨æˆ·æˆ–å–æ¶ˆè®¢é˜…ï¼›
        - Knowledge Retrieverï¼ˆæ·±è“ï¼‰ï¼šè°ƒé˜…ç›¸å…³æ”¿ç­–å’ŒçŸ¥è¯†ï¼›
        - å‘ç”¨æˆ·ç´¢å–ä¿¡æ¯ï¼ˆé»„è‰²ï¼‰ï¼›
        - æŒ‡å¯¼å¦‚ä½•é€šçŸ¥å®¢æˆ·ï¼ˆæµ…è“ï¼‰ã€‚
    - ä¼´éšç€â€œæ…¢æ€è€ƒâ€å¤§æ¨¡å‹çš„æ¼”è¿›ï¼ŒOne-Shot Agentçš„ç‰¹å¾éå¸¸é€‚åˆäºè·¨å¹³å°å¹¶åä½œäººç±»è§£ç­”æµç¨‹å¤æ‚çš„å†³ç­–é—®é¢˜
    - å½“å‰è¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼ˆgpt-4oï¼‰One-Shotçš„å‡†ç¡®ç‡æœ‰ä¸ƒæˆï¼Œå¦‚æœæˆ‘ä»¬åˆ©ç”¨Verifierå°†One-Shotæ¶æ„è½¬åŒ–ä¸ºReActï¼Œå‡­å€Ÿæç¤ºè¯Routine Gençš„å‡†ç¡®ç‡æœ‰æœ›è¾¾åˆ°90%+ï¼›
    - å‡†ç¡®ç‡è¶…è¿‡60%çš„æ¨¡å‹å¯¹çŸ¥è¯†å›¾è°±æœ‰è¾ƒå¥½çš„ç†è§£ï¼Œè€Œå¦‚æœè¯¥æŒ‡æ ‡ä½äº50%ï¼Œåˆ™ä¸å»ºè®®ä½¿ç”¨æ­¤ç±»æ¨¡å‹è¿›è¡ŒRoutine Genï¼›
    - å›½äº§ä¸»åŠ›æ¨¡å‹èƒ½åŠ›è·gpt-4oä¸è¿œï¼ˆä¾‹å¦‚ glm-4-plusçš„å‡†ç¡®ç‡ä¸ºï½65%ï¼‰ï¼Œå¸‚åœºä¸Šæœ‰æœ›å‡ºç°èƒ½å¤ŸPKå¾®è½¯å’ŒSalesforceçš„çº¯å›½äº§çš„"ç¼–æ’å‹"Agentï¼›
    - å„ä¸ªæ¨¡å‹æ‰€çŠ¯é”™è¯¯è¾ƒä¸ºè¿‘ä¼¼ï¼Œæœ‰è¿›ä¸€æ­¥é€šè¿‡ä¼˜åŒ–æç¤ºè¯å·¥ç¨‹æå‡å‡†ç¡®ç‡çš„ç©ºé—´
  - [Memory for agents](https://blog.langchain.dev/memory-for-agents/)
    - CoALA paper
    - Procedural Memory
      - This term refers to long-term memory for how to perform tasks, similar to a brainâ€™s core instruction set. - remembering how to ride a bike.
    - Semantic Memory
      - This is someoneâ€™s long-term store of knowledge.
      - Semantic memory in humans: itâ€™s composed of pieces of information such as facts learned in school, what concepts mean and how they are related
    - Episodic Memory
      - This refers to recalling specific past events.
      - Episodic memory in humans: when a person recalls a particular event (or â€œepisodeâ€) experienced in the past.
  - å¿«æ€è€ƒä¸æ…¢æ€è€ƒ Agent çš„ç»“åˆ
    - åœ¨è¿™ä¸ªåŒç³»ç»Ÿæ¶æ„ä¸­ï¼ŒAgentè¢«åˆ†ä¸ºä¸¤ä¸ªè§’è‰²ï¼šå¿«é€Ÿç›´è§‚çš„å¯¹è¯ä»£ç†å’Œè¾ƒæ…¢æ·±æ€ç†Ÿè™‘çš„æ¨ç†ä»£ç†ã€‚
    - ç³»ç»Ÿ1èƒ½å¤Ÿå¿«é€Ÿåšå‡ºåˆ¤æ–­å’Œååº”ï¼Œæ¯”å¦‚æ„ŸçŸ¥é€Ÿåº¦è¾ƒå¿«çš„æ±½è½¦æˆ–è¯†åˆ«åŒäº‹çš„æƒ…ç»ªã€‚è€Œç³»ç»Ÿ2åˆ™å¤„ç†å¤æ‚é—®é¢˜ï¼Œå¦‚è§„åˆ’å‡æœŸå’Œè¿›è¡Œå¤æ‚è®¡ç®—
    - ç³»ç»Ÿ1æŒç»­ä¸ºç³»ç»Ÿ2æä¾›ç›´è§‰å’Œå»ºè®®ï¼Œåè€…å¯ä»¥é€‰æ‹©é‡‡çº³è¿™äº›å»ºè®®ã€‚
  - [RAG Context Refinement Agent](https://www.llamaindex.ai/blog/rag-context-refinement-agent)
    - the agent to revisit the source documentation itself, to refine the context portion of the LLM prompt until it contains sufficient information to answer the user's question
  - [Building effective agents](https://www.anthropic.com/research/building-effective-agents)
    - Building block: The augmented LLM
    - Workflow: Prompt chaining / Routine / Parallelization /  Orchestrator-workers / Evaluator-optimizer / Agent
    - https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents
    - https://www.youtube.com/watch?v=D7_ipDqhtwk
  - [Full RAG](https://zilliz.com/blog/full-rag-modern-architecture-for-hyperpersonalization)
    -  Batch + Streaming data + Real-time Context
  - [è«‡ LLM-based AI Agents](https://ihower.tw/presentation/ihower-agents-202412.pdf)
  - [Agent white paper](https://www.kaggle.com/whitepaper-agents)
  - https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf
  - [Donâ€™t Build Multi-Agents](https://cognition.ai/blog/dont-build-multi-agents#principles-of-context-engineering)
    - å¤šä»£ç†æ¶æ„åœ¨LLMä»£ç†ä¸­å¯èƒ½ä¸ç¨³å®šï¼Œå»ºè®®ä½¿ç”¨å•çº¿ç¨‹çº¿æ€§ä»£ç†
    - Context ä¸Šä¸‹æ–‡å·¥ç¨‹è¢«è®¤ä¸ºæ˜¯æ„å»ºå¯é é•¿æœŸä»£ç†çš„å…³é”®ã€‚
    - å¤šæ™ºèƒ½ä½“æ¶æ„çš„â€œè„†å¼±æ€§â€ä¸â€œå¯é æ€§â€é—®é¢˜
      - å…³é”®çš„å¤±è´¥ç‚¹åœ¨äºå­æ™ºèƒ½ä½“å¯èƒ½è¯¯è§£ä»»åŠ¡å¹¶äº§ç”Ÿä¸ä¸€è‡´çš„ç»“æœï¼Œå¯¼è‡´æœ€ç»ˆçš„æ™ºèƒ½ä½“éš¾ä»¥æ•´åˆè¿™äº›è¯¯è§£
      - æ™ºèƒ½ä½“éœ€è¦é•¿æœŸè¿è¡Œå¹¶ä¿æŒè¿è´¯å¯¹è¯æ—¶ï¼Œå¯é æ€§è‡³å…³é‡è¦ï¼Œè€Œä¸Šä¸‹æ–‡å·¥ç¨‹æ˜¯æ ¸å¿ƒã€‚å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¼šå¯¼è‡´â€œå†³ç­–è¿‡äºåˆ†æ•£ï¼Œä¸Šä¸‹æ–‡æ— æ³•å……åˆ†å…±äº«â€ï¼Œä»è€Œäº§ç”Ÿâ€œè„†å¼±çš„ç³»ç»Ÿâ€
    - å­æ™ºèƒ½ä½“å³ä½¿å…±äº«åŸå§‹ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œä¹Ÿå¯èƒ½å› ä¸ºæ— æ³•çœ‹åˆ°å…¶ä»–å­æ™ºèƒ½ä½“æ­£åœ¨åšä»€ä¹ˆè€Œå¯¼è‡´å·¥ä½œä¸ä¸€è‡´ï¼Œå› ä¸ºå®ƒä»¬çš„è¡ŒåŠ¨åŸºäºç›¸äº’å†²çªçš„æœªé¢„è®¾å‡è®¾ã€‚
      - åŸåˆ™1æ˜¯â€œå…±äº«å®Œæ•´ä¸Šä¸‹æ–‡å’Œå®Œæ•´çš„æ™ºèƒ½ä½“è¿½è¸ªï¼Œè€Œä¸ä»…ä»…æ˜¯å•ç‹¬çš„æ¶ˆæ¯â€ï¼Œ
      - åŸåˆ™2æ˜¯â€œè¡ŒåŠ¨å¸¦æœ‰éšå«å†³ç­–ï¼Œå†²çªçš„å†³ç­–ä¼šå¯¼è‡´ç³Ÿç³•çš„ç»“æœâ€ã€‚
  - [How we built our multi-agent research system](https://www.anthropic.com/engineering/built-multi-agent-research-system)
    - Claude æå‡å¤æ‚ç ”ç©¶ä»»åŠ¡èƒ½åŠ›ï¼Œåº•å±‚å…¶å®æ˜¯ä¸‰ä¸ªå…³é”®è¯ï¼šå¸¦å®½ã€ç»“æ„ã€æœºåˆ¶ã€‚
      - ä» token åˆ°å¸¦å®½ï¼šæ‰©å®¹é—®é¢˜å…¶å®æ˜¯ç³»ç»Ÿé—®é¢˜
        - å•ä¸ª agent å¾ˆå¿«å°±ä¼šé‡åˆ° token é™åˆ¶ï¼Œè¿™ä¸æ˜¯æ¨¡å‹èƒ½åŠ›ä¸è¡Œï¼Œè€Œæ˜¯å®¹é‡ä¸å¤Ÿã€‚
        - æˆ‘ä»¬è‡ªå·±è°ƒé•¿é“¾æ¡ã€å¤šè·³è°ƒç”¨çš„æ—¶å€™ä¹Ÿå¾ˆæ˜æ˜¾ã€‚Anthropic é€‰æ‹©çš„è§£æ³•ä¸æ˜¯æ‰©æ¨¡å‹ï¼Œè€Œæ˜¯æ‹†ä»»åŠ¡ã€å¼€å¹¶å‘ã€åˆ† agentï¼Œæ¯ä¸ª agent è‡ªå¸¦ä¸Šä¸‹æ–‡çª—å£ï¼Œä»ç³»ç»Ÿç»“æ„å±‚é¢æ‰©å®¹ã€‚
      - æç¤ºè¯æ˜¯ç³»ç»ŸæŒ‡ä»¤ï¼Œå¾ˆé‡è¦ã€å¾ˆé‡è¦ã€å¾ˆé‡è¦ï¼
        - ä¸» agent çš„æç¤ºè¯ï¼Œæ˜¯è´Ÿè´£åˆ†é…ä»»åŠ¡ã€æŒ‡æ˜ç›®æ ‡ã€äº¤ä»£æ ¼å¼ã€é€‰å·¥å…·çš„ã€‚
        - æç¤ºè¯ä¸åªæ˜¯æ²Ÿé€šè¯­è¨€ï¼Œæ›´æ˜¯è°ƒåº¦é€»è¾‘ã€ä»»åŠ¡åè®®ã€æ ¼å¼è§„èŒƒçš„é›†ä¸­æ‰¿è½½ä½“ã€‚
        - å¤šä¸ª agent å¹¶è¡Œè¿è¡Œæ—¶ï¼Œå¦‚æœæ²¡æœ‰ä¸€ä¸ªæ¸…æ™°ã€æ ¼å¼åŒ–ã€ç»“æ„ç¨³å›ºçš„ prompt æ¨¡æ¿ï¼Œæ¯ä¸ªå­ agent æ‹‰å›æ¥çš„ä¿¡æ¯ä¼šç‰¹åˆ«æ•£ã€é”™æ¼ç‡é«˜ã€å¾ˆéš¾åˆå¹¶ã€‚è¿™æ—¶å€™ï¼Œä¸» agent çš„æç¤ºè¯å°±ç­‰äºä¸€ä¸ªè°ƒåº¦ä¸­æ¢çš„â€œç¼–ç¨‹è¯­è¨€â€
        - ä¸» agent çš„æç¤ºè¯ç­–ç•¥åº”è¯¥å’Œæµç¨‹å›¾ä¸€æ ·ä¸¥è°¨ï¼šæ¯ä¸€æ­¥è¦é¢„è®¾ç»“æœã€é¢„è®¾å¤±è´¥ã€é¢„è®¾ä¸Šä¸‹æ¸¸
      - ç³»ç»Ÿçº§æœºåˆ¶ï¼Œå†³å®šäº†èƒ½ä¸èƒ½æ’‘è¿›ç”Ÿäº§ç¯å¢ƒ
        - checkpointã€å¼‚æ­¥é‡è¯•æœºåˆ¶ã€å…¨é“¾è·¯ tracingã€å½©è™¹éƒ¨ç½²ã€‚
        - agent ç³»ç»Ÿæœ¬è´¨ä¸Šè¦å¾€æœåŠ¡åŒ–æ–¹å‘èµ°ï¼Œå°±å¿…é¡»é¢„è®¾å¤±è´¥æ˜¯å¸¸æ€ï¼Œé‡è¯•æ˜¯èƒ½åŠ›ã€‚
      - è¯„ä¼°æœºåˆ¶æ˜¯ä¸å¯ç¼ºçš„é—­ç¯ï¼Œä¸ç„¶åšä¸å‡ºåé¦ˆå¯¼å‘çš„ç³»ç»Ÿè¿›åŒ–
        - è®©å¦ä¸€ä¸ª LLM å»è¯„å®¡ agent çš„ç»“æœï¼Œä»å‡†ç¡®æ€§ã€å¼•ç”¨åˆç†æ€§ã€è¦†ç›–åº¦ç­‰å¤šä¸ªç»´åº¦æ‰“åˆ†. åœ¨ç³»ç»Ÿé‡Œå†…åµŒäº† QA æµç¨‹ï¼Œè€Œä¸”ä¸æ˜¯äº‹åäººè¯„ï¼Œè€Œæ˜¯å¯ä»¥æ’å…¥è°ƒè¯•é“¾è·¯çš„ LLM è¯„æµ‹å™¨
      - å¹¶å‘æ˜¯å·¥å…·ï¼Œä¸æ˜¯ç­–ç•¥ï¼Œé€‚ç”¨åœºæ™¯è¾¹ç•Œè¦æƒ³æ¸…æ¥š
        - è¿™å¥—ç³»ç»Ÿæœ€é€‚åˆçš„åœºæ™¯æ˜¯ï¼šé—®é¢˜å¤æ‚åº¦é«˜ã€ä¿¡æ¯å¹¿åº¦è¦æ±‚å¼ºã€éå®æ—¶äº§å‡ºå‹ä»»åŠ¡ã€‚ä¾‹å¦‚æ”¿ç­–ç ”åˆ¤ã€äº§å“è°ƒç ”ã€æ–‡çŒ®ç»¼è¿°ã€ç«å“åˆ†æè¿™äº›ï¼Œåœ¨ç§åŸŸæœåŠ¡é‡Œä¹Ÿå¯ä»¥ç±»æ¯”æˆâ€œå¤šç»´æ ‡ç­¾ç”¨æˆ·æ„å›¾ç ”åˆ¤â€è¿™ç§å¤æ‚å·¥ä½œ
        - ä½†å¦‚æœæ”¾åœ¨éœ€è¦ç´§å¯†é…åˆã€é¢‘ç¹è¿­ä»£ã€ä½å»¶è¿Ÿè¦æ±‚çš„ä»»åŠ¡ä¸Šï¼Œä¾‹å¦‚ä»£ç ç”Ÿæˆã€å¯¹è¯ä»»åŠ¡ã€å®æ—¶æ¥å£æ„å»ºï¼Œå¤š agent çš„åè°ƒæˆæœ¬åè€Œå¯èƒ½æ”¾å¤§ç³»ç»Ÿå¤æ‚åº¦ã€‚
        - æ„å»º agent ç³»ç»Ÿï¼Œä¸èƒ½åªæ˜¯å¯¹è¯å¼çš„ prompt ç¼–æ’ï¼Œè€Œè¦åƒæ­æœåŠ¡ä¸€æ ·ï¼Œä»ä»»åŠ¡å®šä¹‰åˆ°è¯„ä¼°åé¦ˆï¼Œä»å¹¶å‘æœºåˆ¶åˆ°å¼‚å¸¸å…œåº•ï¼Œå½¢æˆä¸€æ•´å¥—å¯ä»¥æŒç»­è¿è¡Œçš„ç³»ç»Ÿé€»è¾‘ã€‚
    - æœ‰äº›é¢†åŸŸéœ€è¦æ‰€æœ‰æ™ºèƒ½ä½“å…±äº«ç›¸åŒä¸Šä¸‹æ–‡ï¼Œæˆ–è€…æ¶‰åŠæ™ºèƒ½ä½“ä¹‹é—´è®¸å¤šä¾èµ–å…³ç³»ï¼Œç›®å‰ä¸é€‚åˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
      - å¦‚ä½•å…‹æœè¿™äº›é™åˆ¶çš„ï¼š
        - åè°ƒæ¨¡å¼: Anthropicçš„ç³»ç»Ÿé‡‡ç”¨â€œåè°ƒè€…-å·¥ä½œè€…â€æ¨¡å¼ï¼Œç”±ä¸€ä¸ªä¸»æ™ºèƒ½ä½“åè°ƒæ•´ä¸ªè¿‡ç¨‹ï¼Œå¹¶å§”æ´¾ä»»åŠ¡ç»™å¹¶è¡Œçš„ä¸“ä¸šå­æ™ºèƒ½ä½“ã€‚
          - ä¸»æ™ºèƒ½ä½“åˆ†ææŸ¥è¯¢ï¼Œåˆ¶å®šç­–ç•¥ï¼Œå¹¶ç”Ÿæˆå­æ™ºèƒ½ä½“åŒæ—¶æ¢ç´¢ä¸åŒçš„æ–¹é¢ã€‚å­æ™ºèƒ½ä½“å°†ç»“æœè¿”å›ç»™ä¸»æ™ºèƒ½ä½“è¿›è¡Œç»¼åˆã€‚
        - æ˜ç¡®å§”æ‰˜: ä»–ä»¬å¼ºè°ƒâ€œæ•™å¯¼åè°ƒè€…å¦‚ä½•å§”æ‰˜â€ï¼Œå³ä¸»æ™ºèƒ½ä½“éœ€è¦ä¸ºå­æ™ºèƒ½ä½“æä¾›è¯¦ç»†çš„ä»»åŠ¡æè¿°ï¼ŒåŒ…æ‹¬ç›®æ ‡ã€è¾“å‡ºæ ¼å¼ã€ä½¿ç”¨çš„å·¥å…·å’Œæ¥æºæŒ‡å—ï¼Œä»¥åŠæ˜ç¡®çš„ä»»åŠ¡è¾¹ç•Œï¼Œä»¥é¿å…å·¥ä½œé‡å¤ã€é—æ¼æˆ–ä»»åŠ¡è¯¯è§£ã€‚
          - ä¾‹å¦‚ï¼Œå¦‚æœæ²¡æœ‰è¯¦ç»†æè¿°ï¼Œå­æ™ºèƒ½ä½“å¯èƒ½ä¼šé‡å¤æ‰§è¡Œç›¸åŒçš„æœç´¢ï¼Œæˆ–è€…å¯¹ä»»åŠ¡è¿›è¡Œä¸åŒçš„è§£é‡Šã€‚
        - ä¸Šä¸‹æ–‡ç®¡ç†: å¯¹äºé•¿æœŸè¿è¡Œçš„ä»»åŠ¡å’Œä¸Šä¸‹æ–‡çª—å£æº¢å‡ºé—®é¢˜ï¼Œ
          - Anthropicçš„è§£å†³æ–¹æ¡ˆæ˜¯ä¸»æ™ºèƒ½ä½“å°†è®¡åˆ’ä¿å­˜åˆ°â€œå†…å­˜â€ä¸­ï¼Œä»¥æŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡çª—å£è¿‡å¤§æ—¶è¢«æˆªæ–­ã€‚
          - ä»–ä»¬è¿˜å®ç°äº†æ™ºèƒ½ä½“åœ¨å®Œæˆå·¥ä½œé˜¶æ®µåæ€»ç»“å…³é”®ä¿¡æ¯å¹¶å­˜å‚¨åˆ°å¤–éƒ¨è®°å¿†ä¸­ï¼Œå¹¶åœ¨ä¸Šä¸‹æ–‡æ¥è¿‘é™åˆ¶æ—¶ç”Ÿæˆæ–°çš„å­æ™ºèƒ½ä½“ï¼Œé€šè¿‡ä»”ç»†äº¤æ¥ä¿æŒè¿ç»­æ€§ã€‚
       - æœ€å°åŒ–â€œç”µè¯æ¸¸æˆâ€: ä»–ä»¬é€šè¿‡è®©å­æ™ºèƒ½ä½“å°†è¾“å‡ºç›´æ¥ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿæ¥â€œæœ€å°åŒ–â€˜ç”µè¯æ¸¸æˆâ€™ï¼ˆgame of telephoneï¼‰â€ï¼Œ
         - è€Œä¸æ˜¯æ‰€æœ‰ä¿¡æ¯éƒ½é€šè¿‡ä¸»åè°ƒå™¨ä¼ é€’ã€‚è¿™æœ‰åŠ©äºæé«˜ä¿çœŸåº¦å’Œæ€§èƒ½ï¼Œå¹¶å‡å°‘é€šè¿‡å¯¹è¯å†å²å¤åˆ¶å¤§é‡è¾“å‡ºæ‰€éœ€çš„tokenå¼€é”€ï¼Œä»è€Œé¿å…ä¿¡æ¯ä¸¢å¤±ã€‚
    - é€šè¿‡è®©å¤šä¸ªå­ä»£ç†ï¼ˆå­æ¨¡å‹ï¼‰å¹¶è¡Œå·¥ä½œï¼Œå¯ä»¥åŒæ—¶æ¢ç´¢ä¸åŒæ–¹å‘ã€åœ¨è¶…å‡ºå•ä¸€ä¸Šä¸‹æ–‡çª—å£é™åˆ¶çš„å¤§è§„æ¨¡æ•°æ®ä¸­è¿›è¡Œæœç´¢ä¸æç‚¼
    - å¤šä»£ç†ç³»ç»Ÿçš„æ€»ä½“æ¶æ„ - Anthropic é‡‡ç”¨â€œä¸»ä»£ç†ï¼ˆLeadResearcherï¼‰+ å­ä»£ç†ï¼ˆSubagentsï¼‰â€çš„æ¨¡å¼ï¼š
      - ä¸»ä»£ç†åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œåˆ¶å®šç ”ç©¶ç­–ç•¥å¹¶åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼›
      - å­ä»£ç†å„è‡ªä½¿ç”¨æœç´¢ã€é›†æˆç­‰å·¥å…·å¯¹å­ä»»åŠ¡è¿›è¡Œå¹¶è¡Œæ¢ç´¢ï¼Œç„¶åå°†ç»“æœæŠ¥å‘Šç»™ä¸»ä»£ç†ï¼›
      - ä¸»ä»£ç†ç»§ç»­ç»¼åˆã€åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´å¤šç ”ç©¶ï¼Œæˆ–è€…è¿›å…¥ç»“æœæ•´ç†é˜¶æ®µã€‚
      - Prompt: https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts
        - citations_agent.mdï¼šè§„åˆ™å†™å¾—è¶³å¤Ÿå…·ä½“ï¼Œä»å¼•ç”¨ä½ç½®ã€æ ¼å¼å¯†åº¦ï¼Œåˆ°å»å†—ä½™ç­–ç•¥éƒ½ä¸€ç›®äº†ç„¶ï¼›
          - è¿˜æ˜ç¡®äº†æŠ€æœ¯éªŒè¯é€»è¾‘ï¼Œæ¨¡å‹åªè¦åŠ¨äº†åŸæ–‡å°±ç›´æ¥ä¸æ”¶ï¼Œè¿™ç§åˆšæ€§çº¦æŸéå¸¸é€‚åˆæ”¾åˆ°æœ€ç»ˆå‡ºæŠ¥å‘Šçš„é“¾è·¯é‡Œã€‚
        - research_lead_agent.mdï¼šå…·å¤‡å®Œæ•´çš„å››å±‚ Research Process æ‹†è§£æµç¨‹ï¼Œè¿˜èƒ½åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼ˆdepth-first / breadth-first / straightforwardï¼‰ï¼Œå¯¹åº”ä¸åŒä»»åŠ¡è‡ªåŠ¨è®¾è®¡ç»“æ„åŒ–åˆ†å·¥ï¼›
          - å¹¶å‘ agent çš„ä½¿ç”¨ä¹Ÿæœ‰ä¸Šé™æŒ‡å¼•ï¼Œèƒ½æœ‰æ•ˆé˜²æ­¢â€œä¹±æ‹† agentâ€å¸¦æ¥çš„èµ„æºæµªè´¹ã€‚
        - research_subagent.mdï¼šæµç¨‹ä¸Šå¼•å…¥ OODAï¼ˆObserveâ€“Orientâ€“Decideâ€“Actï¼‰å¾ªç¯ï¼Œè¿˜é…æœ‰ Tool budget çº¦æŸï¼Œå­ agent ä¸ä»…èƒ½è·‘ã€è¿˜èƒ½é™æµï¼›
          - åŠ ä¸Šæ˜ç¡®çš„ source quality checklistï¼Œæ˜¾è‘—æå‡ä¿¡æ¯è´¨é‡ï¼Œé¿å…æ‹‰åˆ°ä¸€å †è¥é”€ç¨¿æˆ–æ— æ•ˆé“¾æ¥ã€‚
    - å¤šä»£ç†ç³»ç»Ÿçš„è¯„ä¼°é¢ä¸´æ›´é«˜éš¾åº¦ï¼Œå› å…¶ä¸ä¸€å®šä¼šæŒ‰ç…§é¢„è®¾è·¯å¾„è¡ŒåŠ¨ã€‚Anthropic å»ºè®®ï¼š
      - å…ˆç”¨å°è§„æ¨¡æµ‹è¯•é›†è¿›è¡Œå¿«é€Ÿè¿­ä»£ï¼›
      - ä½¿ç”¨ LLM ä½œä¸ºè¯„å®¡æ¥æ‰“åˆ†æˆ–æ£€æŸ¥è¾“å‡ºï¼Œä»å‡†ç¡®æ€§ã€å¼•ç”¨ç­‰å¤šè§’åº¦è¯„ä¼°ï¼›
      - äººå·¥è¯„ä¼°åˆ™èƒ½å‘ç°è‡ªåŠ¨æ‰“åˆ†é—æ¼çš„å„ç§ç»†èŠ‚é—®é¢˜ï¼ˆå¦‚æ¥æºè´¨é‡ä¸ä½³ï¼‰å¹¶å¸®åŠ©ä¿®æ­£ä»£ç†è¡Œä¸ºã€‚
  - [How and when to build multi-agent systems](https://blog.langchain.dev/how-and-when-to-build-multi-agent-systems/)
    - Context engineering is crucial
    - Multi-agent systems that primarily â€œreadâ€ are easier than those that â€œwriteâ€
  - [èˆªç©ºå…¬å¸æ™ºèƒ½å®¢æœç³»ç»Ÿ](https://github.com/openai/openai-cs-agents-demo)
    - æœ‰å¦‚ä¸‹ Agent ç»„æˆï¼Œå®ç°å®Œå–„çš„èˆªç©ºå®¢æœç³»ç»Ÿï¼š
       - æ™ºèƒ½åˆ†æµ Agentï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶è·¯ç”±ä¸åŒç±»å‹å®¢æˆ·è¯·æ±‚
       - ä¸“ä¸šåº§ä½é¢„è®¢ Agentï¼Œå¤„ç†åº§ä½æ›´æ”¹å’Œäº’åŠ¨åº§ä½å›¾
       - èˆªç­çŠ¶æ€ Agentï¼Œæä¾›å®æ—¶èˆªç­ä¿¡æ¯æŸ¥è¯¢
       - FAQ Agentï¼Œå›ç­”å¸¸è§é—®é¢˜å’Œæœºå‹ä¿¡æ¯
       - å–æ¶ˆæœåŠ¡ Agentï¼Œå¤„ç†é€€ç¥¨å’Œæ”¹ç­¾ä¸šåŠ¡
  - [åœ°å›¾å…¨å¼€çš„éº¦è‚¯é”¡Agent](https://mp.weixin.qq.com/s/NP0pUhji_P5z2svxfio1_A)
- [çŸ¥è¯†å¬å›è°ƒä¼˜](https://aws.amazon.com/cn/blogs/china/practice-of-knowledge-question-answering-application-based-on-llm-knowledge-base-construction-part-3/)
  - å€’æ’å¬å› & å‘é‡å¬å›
    - å€’æ’å¬å›
      - ä¼˜åŠ¿ï¼šå‘å±•æˆç†Ÿï¼Œæ˜“è¾¾åˆ°éå¸¸å¥½çš„ baseline æ€§èƒ½
        - æ£€ç´¢é€Ÿåº¦æ›´å¿«
        - å¯è§£é‡Šèƒ½åŠ›å¼º
        - ç²¾ç¡®åŒ¹é…èƒ½åŠ›å¼º
        - æ”¯æŒè‡ªå®šä¹‰åœç”¨è¯è¡¨ï¼ŒåŒä¹‰è¯è¡¨
      - åŠ£åŠ¿ï¼šæ²¡æœ‰è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¹â€ä¸€è¯å¤šä¹‰â€ç°è±¡è§£å†³çš„ä¸å¥½
        - å…³é”®å­—ä¸åŒ¹é…ï¼Œç”¨æˆ·åœ¨æœç´¢æ—¶å¹¶æ— æ³•çŸ¥é“ Document ä¸­å‡†ç¡®çš„ termsï¼Œéœ€è¦é€šè¿‡ term expansionï¼ˆåŒä¹‰è¯ï¼‰ï¼Œquery æ”¹å†™æ¥è§£å†³
        - è¯­ä¹‰åç§»é—®é¢˜, è™½ç„¶å…³é”®è¯å­—é¢ä¸ŠåŒ¹é…ï¼Œä½†æ˜¯å‘½ä¸­é¡ºåºå’Œç”¨æˆ·è¾“å…¥ä¸ä¸€æ ·ï¼Œè¯­ä¹‰ä¸Šå®Œå…¨ä¸ç›¸å…³
      - åœ¨å‚ç›´é¢†åŸŸçš„ FAQ çŸ¥è¯†è¯­æ–™çš„å€’æ’æ£€ç´¢å®è·µä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¸Šè¿°çš„åˆ†ææ–¹æ³•ï¼Œå‘ç°äº†ä¸¤ç±»å¸¸è§çš„å¾—åˆ†åå·®
        - ç§æœ‰é¢†åŸŸæ–‡æ¡£çš„ IDF å¤±çœŸé—®é¢˜
          - ç”±äº BM25 æ‰“åˆ†çš„ IDF æ˜¯åŸºäº Index å†…çš„æ‰€æœ‰çš„æ–‡æ¡£ç»Ÿè®¡å¾—åˆ°çš„ï¼Œåœ¨ä¸€äº›é¢†åŸŸå†…åœºæ™¯ï¼Œæ‰€æœ‰çš„æ–‡æ¡£çš„æ€»é‡å¹¶ä¸å¤§ï¼Œæœ‰äº›ä¸“æœ‰è¯æ±‡åœ¨å…¨éƒ¨æ–‡æ¡£ä¸­çš„å‡ºç°é¢‘ç‡å’Œä¸€äº›å¸¸è§çš„åœç”¨è¯æ˜¯å·®ä¸å¤šçš„
          - æœ‰æ•ˆè§£å†³æ–¹æ¡ˆï¼š å¯¼å…¥ä¸€äº›å…¶ä»–æ¥æºçš„æ–‡æœ¬è¯­æ–™ï¼Œ å½•å…¥åœç”¨è¯ï¼Œåœç”¨è¯ä¸å‚ä¸ BM25 çš„å¾—åˆ†è®¡ç®—
        - æ— å…³é”®è¯åŒ¹é…
          - æ˜¯å€’æ’å¬å›ç¼ºä¹è¯­ä¹‰ä¿¡æ¯çš„å…¸å‹ç°è±¡ï¼Œç°å®ä¸­å¤šè¯ä¸€æ„æ˜¯éå¸¸æ™®éçš„
          - æœ‰æ•ˆè§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨åŒä¹‰è¯è¡¨ï¼Œå¯¹ query è¿›è¡Œæ”¹å†™ï¼Œä½¿ç”¨å‘é‡å¬å›
    - å‘é‡å¬å›
      - ä¼˜åŠ¿ï¼šè€ƒè™‘è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œæ›´åŠ æ™ºèƒ½
        - è¯­ä¹‰ç›¸è¿‘å³å¯å¬å›ï¼Œæ— éœ€ term å‘½ä¸­
        - æ— éœ€è€ƒè™‘å¤æ‚çš„ä¼ ç»Ÿå€’æ’çš„è°ƒä¼˜æ‰‹æ®µ
        - å…·å¤‡æ”¯æŒè·¨æ¨¡æ€å¬å›çš„æ½œåŠ›
      - åŠ£åŠ¿ï¼šéœ€è¦æ¨¡å‹è®­ç»ƒï¼Œå¯¹å‚ç›´é¢†åŸŸè½åœ°æ”¯æŒæœ‰é™
        - é¢„è®­ç»ƒæ¨¡å‹å¯¹äºå…¬å¼€æ•°æ®é›†çš„ benchmark å‚è€ƒæ€§ä¸è¶³ã€‚å¯¹å‚ç›´é¢†åŸŸæ³›åŒ–æ€§ä¸è¶³ï¼Œå¯èƒ½å‡ºç°ä»¥ä¸‹æƒ…å†µï¼š
        - ä¸ç†è§£ä¸“æœ‰è¯æ±‡
        - å®¹æ˜“å‡ºç°è¯­ä¹‰ç›¸ä¼¼ä½†ä¸»é¢˜ä¸ç›¸ä¼¼çš„æƒ…å†µ
        - å¯¹ç²¾å‡†åŒ¹é…æ”¯æŒä¸è¶³ï¼Œéš¾ä»¥ç”¨ä¸“ä¸šè¯æ±‡ç²¾å‡†å¬å›
        - å¯¹â€å¤šè¯ä¸€ä¹‰â€æƒ…å†µçš„æ”¯æŒä¸å¦‚å€’æ’å¬å›ä¸­çš„åŒä¹‰è¯è¡¨ç®€å•ç›´æ¥
        - å¯è§£é‡Šèƒ½åŠ›å¼±
        - éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æº
  - [å¬å›è°ƒä¼˜](https://aws.amazon.com/cn/blogs/china/practice-of-knowledge-question-answering-application-based-on-llm-knowledge-base-construction-part-4/)
    - å¯¹ç§°å¬å›ï¼Œä¸€èˆ¬æ˜¯æŒ‡é€šè¿‡ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§æ¥å¬å›ï¼Œæ¯”å¦‚è¾“å…¥çš„ query åŒ¹é…ç›¸ä¼¼çš„å¦ä¸€ä¸ª question(query->question)ï¼Œä¹Ÿå¯ä»¥æ˜¯è¾“å…¥çš„é™ˆè¿°å¥åŒ¹é…ç›¸ä¼¼çš„å¦ä¸€ä¸ªé™ˆè¿°å¥
    - éå¯¹ç§°å¬å›ä¸€èˆ¬æ˜¯æ£€ç´¢æ•°æ®ï¼Œ ä¸€èˆ¬æ˜¯ä¸€ä¸ªç›¸å¯¹çŸ­çš„é—®å¥å’Œä¸€ä¸ªç›¸å¯¹é•¿çš„ç­”æ¡ˆï¼ˆä¸€èˆ¬ä¸ºä¸€ä¸ªæ–‡æœ¬æ®µè½ï¼‰ 
    - æ¨èåŒæ—¶è€ƒè™‘ QQ å’Œ QD å¬å›ï¼Œå¯¹äº FAQ çš„çŸ¥è¯†å½¢æ€ï¼Œå¯¹ Question ç”Ÿæˆå‘é‡ä½œä¸ºç´¢å¼•ï¼ŒåŒæ—¶æŠŠ Answer ä½œä¸º Doc ç”Ÿæˆå‘é‡ä½œä¸ºç´¢å¼•ï¼Œåœ¨å¬å›æ—¶åŒæ—¶èµ° QQ å’Œ QD å¬å›ã€‚å¯¹äºæ–‡æœ¬æ–‡æ¡£çš„çŸ¥è¯†å½¢æ€ï¼Œé™¤äº†å¯¹ Doc ç”Ÿæˆå‘é‡ä»¥å¤–ï¼Œè¿˜å¯ä»¥é€šè¿‡çŸ¥è¯†å¢å¼ºçš„æ–¹å¼ç”Ÿæˆå¤šç»„ Question
- [Building Advanced RAG Over Complex Documents](https://docs.google.com/presentation/d/1yiuHEQEAhWEvVskbD9jwmfjopznVeZGwwWUzBIZ_P9U/edit#slide=id.g271ba741083_0_1608)
  - Parsing:
    - Bad parsers are a key cause of garbage in == garbage out.
    - Badly formatted text/tables confuse even the best LLMs
  - [Text Splitting/Chunking:](https://mlpills.substack.com/p/issue-69-split-different-text-examples)
    - Character Split
      - A straightforward method that splits text based on character count. 
      - It's ideal when you need consistent chunk sizes without necessarily preserving the document's structure.
    - Recursive Character Text Splitter
      - Splits text while respecting document structure. It starts with larger boundaries like paragraphs, then moves to finer ones like sentences if needed. 
      - Useful for maintaining context and coherence.
    - Token Text Splitter:
      - Divides text based on token count rather than character count. 
      - This is particularly useful when working with models that have token limits, ensuring each chunk fits within those limits.
    - Document specific chunker (Code, Markdown, PDF)
    - Semantic chunking (embeddings only)
      - Uses embeddings to measure semantic similarity between sentences. 
      - It aims to keep semantically related content together, resulting in more meaningful and coherent chunks.
    - AI21 Semantic Text Splitter:
      - Leverages AI21's language models to identify distinct topics within the text and create chunks accordingly. 
      - This method produces topically coherent chunks, enhancing retrieval and context understanding
    - Reasoned chunking (agent like)
  - Indexing:
    - Raw text oftentimes confuse the embedding model.
    - Donâ€™t just embed the raw text, embed references.
    - Having multiple embeddings point to the same chunk is a good practice!
  - Self reflection
    - Use feedback to improve agent execution and reduce errors
      - Human feedback
      - LLM feedback
  - https://python.langchain.com/v0.2/docs/concepts/#retrieval
- [The Future of Knowledge Assistants](https://docs.google.com/presentation/d/1uDMj6iaMnJqcfSUVt5EnrPAzefSghzapSxQBcN2wR80)
  - Advanced data and retrieval modules: Have an advanced set of capabilities for parsing, chunking, and retrieval even before you try out fancier orchestration techniques.
  - Advanced single-agent query flows: Treat all data interfaces as tools, use agentic reasoning to build personalized QA systems.
  - General multi-agent task solvers: Build a multi-agent system as event-driven microservices in order to better collectively solve a task, whether through an agentic orchestrator or through an explicitly defined orchestrator.
- Optimizing RAG Through an Evaluation-Based Methodology
  - Summary
    - Irrelevance and Hallucinations: When the documents retrieved are irrelevant, evidenced by low scores in both Chunk Relevance and Context Relevance, the model is prone to generating inaccurate or fabricated information.
    - Optimizing Document Retrieval: By retrieving a greater number of documents and reducing the chunk size, we observed improved outcomes in the modelâ€™s performance.
    - Adaptive Retrieval Needs: Certain queries may benefit from accessing more documents. Implementing a dynamic retrieval strategy that adjusts based on the query could enhance accuracy.
    - Influence of Model and Prompt Variations: Alterations in language models or the prompts used can significantly impact the quality of the generated responses, suggesting that fine-tuning these elements could optimize performance.
  - Experiment
    - Adjusting the chunk parameter 
    - Increasing the number of documents retrieved (retrieval window)
    - Changing the embedding model
    - Changing the LLM
  - Chunk size: 512 Chunk overlap: 64  Number of docs retrieved (Retrieval Window): 5
- Graph RAG
  - [Overview](https://mp.weixin.qq.com/s/GWRMF7gR9O9zp57_u1ooMQ)
    - RAG 
      - ç´¢å¼•å±‚é¢çš„æŠ€æœ¯åŒ…æ‹¬ Chunk and Embedding / BM25ã€ç”Ÿæˆ QA å¯¹ã€åˆ†å±‚å—æ‘˜è¦ç­‰ï¼Œ
      - æŸ¥è¯¢å±‚é¢çš„æŠ€æœ¯åŒ…æ‹¬ Vector / Hybrid Searchã€Rewrite Queryã€é€’å½’æœç´¢ / å¤åˆæœç´¢ã€Agenticã€é‡æ’ç­‰ã€‚
    - RAG é¢å¯¹å¦‚ä¸‹ä¸€äº›æŒ‘æˆ˜
      - ç»†ç²’åº¦æ£€ç´¢ï¼šç¢ç‰‡åŒ–çŸ¥è¯†çš„å¬å›
        - å¤§æµ·æé’ˆï¼ˆNeedle in Haystackï¼‰ï¼š
          - åˆ†å‰²å†…å®¹å¯èƒ½ä¼šä½¿æ£€ç´¢ç»†ç²’åº¦ã€åˆ†æ•£çš„çŸ¥è¯†å˜å¾—å…·æœ‰æŒ‘æˆ˜
          - åˆ†åŒºå¯èƒ½ä¼šåœ¨å¤šä¸ªç‰‡æ®µä¸­ç¨€é‡Šå…³é”®ä¿¡æ¯ï¼Œä½¿å…¶æ›´éš¾æ•è·å®Œæ•´çš„ä¸Šä¸‹æ–‡ã€‚
      - å…¨å±€ä¸Šä¸‹æ–‡ï¼šä¸¢å¤±é“¾æ¥
        - ç©¿é’ˆå¼•çº¿ï¼ˆConnecting the Dotsï¼‰ï¼Œè¿™ä¸ªæŒ‘æˆ˜çš„å…³é”®ç‚¹åœ¨äºï¼š
          - çº¿æ€§åˆ†å‰²å¤§å—çŸ¥è¯†å¯èƒ½ä¼šå¯¼è‡´ä¸¢å¤±å…¨å±€ä¸Šä¸‹æ–‡ / è¿æ¥ï¼› é¢å‘è¿æ¥çš„æ£€ç´¢åœ¨ä¸Šä¸‹æ–‡åˆ†æ•£åœ¨å¤šæ¥æºï¼ˆä¸å…·æœ‰å±€éƒ¨æ€§ï¼‰æ—¶å¯èƒ½æœ‰æŒ‘æˆ˜ã€‚
      - è¯­ä¹‰ç›¸ä¼¼åº¦ï¼šç›¸å…³æ€§é”™é…
        - åŸºç¡€æ¨¡å‹é€šå¸¸ä¾èµ–äºå¸¸è¯†æˆ–å­—é¢æ„ä¹‰ï¼Œå¯¼è‡´ç›¸å…³æ€§ï¼ˆç›¸å…³æ€§å¹»è§‰ï¼‰çš„é”™è¯¯æ­£ä¾‹ï¼›
        - é«˜ç›¸ä¼¼åº¦ï¼ˆä¾‹å¦‚ï¼Œ95%ï¼‰å¹¶ä¸ä¿è¯ç›¸å…³æ€§ï¼›ä¸Šä¸‹æ–‡æ— å…³çš„ç‰‡æ®µå¯èƒ½çœ‹èµ·æ¥éå¸¸ç›¸ä¼¼ï¼ˆä¾‹å¦‚ï¼Œè™šæ„çš„é£Ÿè°±æˆ–ä¸å­˜åœ¨çš„æƒ…èŠ‚ï¼‰
      - åˆ†å±‚æ‘˜è¦ï¼šå®è§‚é—®é¢˜æŒ‘æˆ˜
        - éš¾ä»¥ä»å¤šä¸ªæ¥æºçš„åˆ†æ•£ä¿¡æ¯ä¸­å›ç­”å¹¿æ³›ã€å…¨å±€çš„é—®é¢˜ï¼›
        - éœ€è¦ä»æ•´ä¸ªæ•°æ®é›†ä¸­æ€»ä½“è·å¾—æ´å¯Ÿï¼Œè€Œä¸æ˜¯æŸå‡ ä¸ªå­¤ç«‹çš„ç‰‡æ®µ
    - retrieveæ–¹æ³•ï¼šå­å›¾æœç´¢ï¼Œè·¯å¾„æœç´¢
    - chain of explorationï¼Œå¯¹äºé—®é¢˜åˆ†ç±» å…¨å±€é—®é¢˜orå±€éƒ¨é—®é¢˜
    - é«˜æ•ˆæ„å»ºgraphï¼Ÿ
      - promptæ–¹å¼ï¼Œæ‹†åˆ†æ–‡æ¡£ï¼Œè§£æ ä¸»è°“å®¾ï¼Œæ„å»ºgraph
      - ä»£ç å¯¹äºgraphï¼Œè¿›è¡Œè¿‡æ»¤æ£€æŸ¥
  - ä½¿ç”¨å›¾ç¤¾åŒºæ‘˜è¦è§£å†³æ€»ç»“æ€§æŸ¥è¯¢ä»»åŠ¡çš„é—®é¢˜ï¼Œå°†çŸ¥è¯†å›¾è°±æŠ€æœ¯åº”ç”¨åˆ°RAGã€‚
  - Graph RAGçš„æ ¸å¿ƒé“¾è·¯åˆ†å¦‚ä¸‹ä¸‰ä¸ªé˜¶æ®µï¼š
    - ç´¢å¼•ï¼ˆä¸‰å…ƒç»„æŠ½å–ï¼‰ï¼šé€šè¿‡LLMæœåŠ¡å®ç°æ–‡æ¡£çš„ä¸‰å…ƒç»„æå–ï¼Œå†™å…¥å›¾æ•°æ®åº“ã€‚
    - æ£€ç´¢ï¼ˆå­å›¾å¬å›ï¼‰ï¼šé€šè¿‡LLMæœåŠ¡å®ç°æŸ¥è¯¢çš„å…³é”®è¯æå–å’Œæ³›åŒ–ï¼ˆå¤§å°å†™ã€åˆ«ç§°ã€åŒä¹‰è¯ç­‰ï¼‰ï¼Œå¹¶åŸºäºå…³é”®è¯å®ç°å­å›¾éå†ï¼ˆDFS/BFSï¼‰ï¼Œæœç´¢Nè·³ä»¥å†…çš„å±€éƒ¨å­å›¾ã€‚
    - ç”Ÿæˆï¼ˆå­å›¾ä¸Šä¸‹æ–‡ï¼‰ï¼šå°†å±€éƒ¨å­å›¾æ•°æ®æ ¼å¼åŒ–ä¸ºæ–‡æœ¬ï¼Œä½œä¸ºä¸Šä¸‹æ–‡å’Œé—®é¢˜ä¸€èµ·æäº¤ç»™å¤§æ¨¡å‹å¤„ç†ã€‚
  - ä¸»è¦ä¸¤ä¸ªéƒ¨åˆ†ï¼šIndexing å’Œ Query
    - ç´¢å¼• (Indexing) ä½¿ç”¨ LLM ä»æ–‡æœ¬æ–‡æ¡£ä¸­è‡ªåŠ¨æå–ä¸°å¯Œçš„çŸ¥è¯†å›¾è°±ã€‚
      - Source Documents â†’ Text Chunks
      - Text Chunks â†’ Element Instances
        - ä»åˆ‡å—çš„æ–‡æœ¬ä¸­æå–ä¸‰å…ƒç»„ã€‚LLM+Promptã€‚å¹¶ä¸”æŠŠä¸‰å…ƒç»„å’Œæ–‡æœ¬åˆ‡å—å…³è”èµ·æ¥
      - Element Instances â†’ Element Summaries
        - ç”¨Community detectionç®—æ³•å¯¹æ–‡æ¡£ç”Ÿæˆçš„å¤§å›¾è¿›è¡Œå¤šå±‚æ¬¡åˆ‡åˆ†ã€‚è¾“å‡ºæœ‰å±‚æ¬¡ç»“æ„çš„å­å›¾
      - Element Summaries â†’ Graph Communities
        - å¯¹æ¯å±‚æ¯ä¸ªå­å›¾ç”Ÿæˆsummaryï¼Œè€Œè¿™äº›summariesåˆ™å¯ä»¥åœ¨å›ç­”é—®é¢˜çš„æ—¶å€™ï¼Œä½œä¸ºContextè¢«ä½¿ç”¨ä½œä¸ºå›ç­”é—®é¢˜çš„ä¾æ®ã€‚ç”ŸæˆSummaryçš„ä»»åŠ¡è‡ªç„¶ä¹Ÿæ˜¯ç”±LLMå®Œæˆ
    - æŸ¥è¯¢ (Query) é€šè¿‡æ£€æµ‹å›¾ä¸­èŠ‚ç‚¹çš„"ç¤¾åŒº"æ¥æŠ¥å‘Šæ•°æ®çš„è¯­ä¹‰ç»“æ„,å½¢æˆå¤šå±‚æ¬¡çš„ä¸»é¢˜æ¦‚è¿°
      - Graph Communities â†’ Community Summaries
      -  Community Summaries â†’ Community Answers â†’ Global Answer
  - https://github.com/microsoft/graphrag
    - Do a vector or keyword search to find an initial set of nodes.
    - Traverse the graph to bring back information about related nodes.
    - Optionally, re-rank documents using a graph-based ranking algorithm such as PageRank.
  - ä¼˜åŠ¿
    - èƒ½å¤Ÿæ›´å¥½åœ°å›ç­” "å…¨å±€é—®é¢˜" (æ¶‰åŠæ•´ä¸ªæ•°æ®é›†çš„é—®é¢˜)ï¼Œè€Œä¼ ç»Ÿ RAG æ–¹æ³•åœ¨è¿™æ–¹é¢è¡¨ç°ä¸ä½³ã€‚
    - ä½¿ç”¨ç¤¾åŒºæ‘˜è¦å’Œæ˜ å°„-å½’çº¦æ–¹æ³•æ¥ä¿ç•™å…¨å±€æ•°æ®ä¸Šä¸‹æ–‡ä¸­çš„æ‰€æœ‰ç›¸å…³å†…å®¹ã€‚
    - Graph RAG çš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºä½¿ç”¨äº†èƒ½å¤Ÿè‡ªé€‚åº”åœ°å¯¹å…¨å±€é—®é¢˜è¿›è¡Œæ€»ç»“çš„å›¾ç»“æ„ã€‚
  - RAG æ–¹æ³•å’Œç³»ç»Ÿ
    - Naive RAG æ–¹æ³•é€šè¿‡æ–‡æ¡£è½¬æ–‡æœ¬ã€åˆ‡åˆ†æ–‡æœ¬å—å’ŒåµŒå…¥å‘é‡ç©ºé—´å®ç°ï¼Œå…¶ä¸­ç›¸ä¼¼è¯­ä¹‰å¯¹åº”ç›¸ä¼¼ä½ç½®ï¼Œç„¶åæŸ¥è¯¢ä¹Ÿè¢«åµŒå…¥åŒä¸€ç©ºé—´ï¼Œæœ€è¿‘çš„ k ä¸ªæ–‡æœ¬å—ä½œä¸ºä¸Šä¸‹æ–‡ã€‚
    - Advanced RAG ç³»ç»Ÿè®¾è®¡äº†é¢„æ£€ç´¢ã€æ£€ç´¢å’Œåæ£€ç´¢ç­–ç•¥æ¥å¼¥è¡¥æœ´ç´  RAG çš„ä¸è¶³ï¼Œè€Œæ¨¡å—åŒ– RAG ç³»ç»Ÿåˆ™é‡‡ç”¨è¿­ä»£å’ŒåŠ¨æ€å¾ªç¯æ£€ç´¢ç”Ÿæˆæ¨¡å¼ã€‚
    - Graph RAG ç»“åˆäº†å¤šä¸ªç³»ç»Ÿçš„æ¦‚å¿µï¼Œå¦‚ç¤¾åŒºæ¦‚è¦ä½œä¸ºè‡ªæˆ‘è®°å¿†ç”¨äºå¢å¼ºæ£€ç´¢ï¼Œä»¥åŠç¤¾åŒºç­”æ¡ˆçš„å¹¶è¡Œç”Ÿæˆç±»ä¼¼äºè¿­ä»£æˆ–è”é‚¦æ£€ç´¢-ç”Ÿæˆç­–ç•¥ã€‚å…¶ä»–ç³»ç»Ÿä¹Ÿé›†æˆäº†è¿™äº›æ¦‚å¿µè¿›è¡Œå¤šæ–‡æ¡£æ‘˜è¦å’Œå¤šè·³é—®ç­”
  - [From Knowledge Graphs to GraphRAG: Advanced Intelligent Data Retrieval](https://div.beehiiv.com/p/knowledge-graphs-graphrag-advanced-intelligent-data-retrieval)
  - [Graph Data Models for RAG Applications](https://neo4j.com/developer-blog/graph-data-models-rag-applications/?utm_campaign=DeveloperBlog&utm_content=&utm_medium=&utm_source=LinkedIn&utm_justglobal=NA)
  - Sample
    - https://colab.research.google.com/github/tomasonjo/blogs/blob/master/llm/llama_relik.ipynb
    - https://towardsdatascience.com/graph-rag-into-production-step-by-step-3fe71fb4a98e
    - https://zilliz.com/blog/graphrag-explained-enhance-rag-with-knowledge-graphs
    - https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/GraphRAG_v2.ipynb
    - GraphRAG + Milvus https://mp.weixin.qq.com/s/9P0yel8EsEsPNeeCTZ5GTA
  - [KG-based RAG](https://mp.weixin.qq.com/s/jaFzZ2WIbgy9mKo1-gKt2Q)
    - è·³æ•°æœ‰é™æ€§å‡è®¾åŸºäºä¸¤ç‚¹å¾ˆé‡è¦çš„è§‚å¯Ÿï¼š1. query å¤æ‚åº¦æœ‰é™æ€§ï¼Œ 2.â€œæ·å¾„â€çš„å±€éƒ¨ dense ç»“æ„ã€‚
    - å°† entities, relationships ä¿¡æ¯åˆ†åˆ«è¿›è¡Œå‘é‡åŒ–ï¼Œå¹¶å­˜å‚¨åœ¨å‘é‡å­˜å‚¨é‡Œï¼Œè¿™æ ·å­˜å‚¨äº†ä¸€ä¸ªé€»è¾‘ä¸Šçš„çŸ¥è¯†å›¾è°±
    - å½“è¿›è¡Œ query æŸ¥è¯¢æ—¶ï¼Œä¼šå…ˆæŠŠç›¸å…³çš„ entities å’Œ relationships æ£€ç´¢å‡ºæ¥ã€‚é€šè¿‡è¿™äº› entities å’Œ relationshipsï¼Œæˆ‘ä»¬åœ¨å›¾ç»“æ„ä¸Šè¿›è¡Œæœ‰é™çš„æ‹“å±•
    - å°†è¿™äº› relationships ä¸ query é—®é¢˜ç»„è£…è¿› prompt å†…ï¼Œä½¿ç”¨ LLM çš„èƒ½åŠ›å¯¹è¿™äº› relationships è¿›è¡Œ rerankingã€‚
    - æœ€åå¾—åˆ° topK ä¸ªé‡è¦çš„ relationshipsï¼Œåœ¨ä»–ä»¬çš„ metadata ä¿¡æ¯å†…è·å¾—ä¸ä»–ä»¬ç›¸å…³çš„ passagesï¼Œä½œä¸ºæœ€ç»ˆçš„ retrieved passagesã€‚
    - https://milvus.io/docs/graph_rag_with_milvus.md
  - [GraphRAG Agent](https://zilliz.com/blog/build-graphrag-agent-with-neo4j-and-milvus)
    - agent follows three key concepts: routing, fallback mechanisms, and self-correction
      - Routing â€“ A dedicated routing mechanism decides whether to use the vector database, the knowledge graph, or a combination of both based on the query.
      - Fallback â€“ In situations where the initial retrieval is insufficient, the agent falls back to a web search using Tavily.
      - Self-correction â€“ The agent evaluates its own answers and attempts to correct hallucinations or inaccuracies.
    - https://neo4j.com/developer-blog/graphrag-agent-neo4j-milvus/
- æå‡RAGæ•ˆæœçš„æ–¹æ³•
  - RAPTOR https://arxiv.org/pdf/2401.18059
    - é€šè¿‡é€’å½’åµŒå…¥ã€èšç±»å’Œæ€»ç»“æ–‡æœ¬å—ï¼Œæ„å»ºä¸€ä¸ªè‡ªåº•å‘ä¸Šçš„æ ‘å½¢ç»“æ„ï¼Œåœ¨æ¨ç†æ—¶ä»è¿™æ£µæ ‘ä¸­æ£€ç´¢ä¿¡æ¯ï¼Œä»è€Œåœ¨ä¸åŒæŠ½è±¡å±‚æ¬¡ä¸Šæ•´åˆæ¥è‡ªé•¿æ–‡æ¡£çš„ä¿¡æ¯ã€‚
  - Self-RAG https://arxiv.org/pdf/2310.11511
    - é€šè¿‡è®©è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è¿›è¡Œè‡ªæˆ‘åæ€ï¼Œæ¥æé«˜ç”Ÿæˆè´¨é‡å’Œäº‹å®æ­£ç¡®æ€§ï¼ŒåŒæ—¶ä¸æŸå¤±è¯­è¨€æ¨¡å‹çš„å¤šæ ·æ€§
  - Dense X Retrivel https://arxiv.org/pdf/2312.06648
- [Safeguarding Your RAG Pipelines](https://towardsdatascience.com/safeguarding-your-rag-pipelines-a-step-by-step-guide-to-implementing-llama-guard-with-llamaindex-6f80a2e07756)
- [RAG for a Codebase with 10k Repos](https://www.codium.ai/blog/rag-for-large-scale-code-repos/)
- Agentic RAG
  - 3 core components
    - ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†: This allows agents to learn from past experiences and improve over time. It's what makes your agent smarter with each interaction rather than starting from scratch every time.
    - ğ—§ğ—¼ğ—¼ğ—¹ğ˜€: These are the hands of your agent - external resources that help it complete tasks beyond just generating text. In RAG, these might include search tools, data processors, or API connectors.
    - ğ—¥ğ—²ğ—®ğ˜€ğ—¼ğ—»ğ—¶ğ—»ğ—´: LLMs serve as the brain, enabling the agent to plan, make decisions, and break complex tasks into manageable sub-tasks. The agent follows a ReAct framework (Reason + Act) where it:
      â€¢ Thinks about what action to take
      â€¢ Executes that action
      â€¢ Observes the results
      â€¢ Repeats until completion
  - Routing (Adaptive RAG) - Allows the agent to intelligently route user queries to the most suitable retrieval method based on the question itself. 
  - Fallback (Corrective RAG) - Ensures the agent has a backup plan if its initial retrieval methods fail to provide relevant results. 
  - Self-correction (Self-RAG) - Enables the agent to identify and fix its own errors or misleading outputs.
  - [Building an Advanced Knowledge Assistant](https://www.figma.com/slides/wkRKi1AxgAkIaX8CnR2IbE/LlamaIndex-(AI-Conference%2C-Sep.-10-2024%2C-v1)?node-id=66-320&node-type=slide)
    - Thereâ€™s many questions/tasks that naive RAG canâ€™t give an answer to
      - Hallucinations
      -  Limited time savings
      -  Limited decision-making enhancement
    - Knowledge Assistant
      - High-quality data and retrieval - hierarchical indexing and retrieval
        - generally good pipeline:
          - Parse documents into elements: text chunks, tables, images, and more.
          - For each element, extract one or more text representations that can be indexed.
            - Text Chunks: Extract smaller sentences, summaries
            - Tables: Extract summaries, table cells
            - Images: Extract caption
      - Agentic reasoning over complex inputs
      - Agentic decision-making and output generation
      - Towards a scalable, full-stack application
  - [Agents](https://weaviate.io/blog/what-is-agentic-rag#what-are-agents-in-ai-systems)
    - LLM (with a role and a task)
    - Memory (short-term and long-term)
    - Planning (e.g., reflection, self-critics, query routing, etc.)
    - Tools (e.g., calculator, web search, etc.)
  - [Build agentic RAG on Google Cloud databases with LlamaIndex](https://cloud.google.com/blog/products/databases/llamaindex-integrates-with-alloydb-and-cloud-sql-for-postgresql?e=48754805)
  - [How to think about agent frameworks](https://blog.langchain.dev/how-to-think-about-agent-frameworks/)
    - TL; DR; 
      - The hard part of building reliable agentic systems is making sure the LLM has the appropriate context at each step. This includes both controlling the exact content that goes into the LLM, as well as running the appropriate steps to generate relevant content.
      - Agentic systems consist of both workflows and agents (and everything in between).
      - Most agentic frameworks are neither declarative or imperative orchestration frameworks, but rather just a set of agent abstractions.
      - Agent abstractions can make it easy to get started, but they can often obfuscate and make it hard to make sure the LLM has the appropriate context at each step.
      - Agentic systems of all shapes and sizes (agents or workflows) all benefit from the same set of helpful features, which can be provided by a framework, or built from scratch.
    - agentic systemsâ€ we see in production are a combination of â€œworkflowsâ€ and â€œagents
- ![img.png](rag_ft.png)
- [Musings on building a Generative AI product](https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product)
  - the basic framework up and running:
    - Routing: decides if the query is in scope or not, and which AI agent to forward it to. Examples of agents are: job assessment, company understanding, takeaways for posts, etc.
    - Retrieval: recall-oriented step where the AI agent decides which services to call and how (e.g. LinkedIn People Search, Bing API, etc.).
    - Generation: precision-oriented step that sieves through the noisy data retrieved, filters it and produces the final response.
  - Small models for routing/retrieval, bigger models for generation
  - Embedding-Based Retrieval (EBR) powered by an in-memory database as our 'poor man's fine-tuning' to inject response examples directly into our prompts
  - æ€ä¹ˆç¨³å®šçš„è®© LLM è¿”å›ç»“æ„åŒ–çš„æ•°æ®ï¼Ÿ
    - ä½¿ç”¨ YAML æ ¼å¼è€Œä¸æ˜¯ JSONï¼Œç›¸å¯¹æ¥è¯´å®¹é”™ç‡æ›´é«˜
    - ç”¨æ—¥å¿—è®°å½•å¸¸è§çš„ YAML é”™è¯¯ï¼Œä¼˜åŒ–è‡ªå·±çš„ YAML è§£æå™¨ï¼Œå¯ä»¥è§£æ LLM è¿”å›çš„ä¸è§„èŒƒçš„ YAML
    - å¦‚æœè¿˜æ˜¯æ— æ³•è§£æåˆ™å°†é”™è¯¯ä¿¡æ¯äº¤ç»™ LLM ä¿®å¤ï¼Œå¹¶ä¸”ä¸æ–­ä¼˜åŒ–æç¤ºè¯ï¼Œæå‡ LLM ä¿®å¤çš„æˆåŠŸç‡
- RAG ç»éªŒè°ˆ
  - åˆ†å—å¤§å°ï¼šå»ºè®®ä¸è¦åˆ†å—å¤ªå¤§ï¼ˆ<500ï¼‰ï¼Œè¶…è¿‡é˜ˆå€¼åŠ overlap
  - å¯¹æ–‡å—å†…å®¹è¿›è¡Œé¢„å¤„ç†ï¼ŒæŠ½å–æ®µè½çº§åˆ«çš„å†…å®¹ï¼Œè¶…è¿‡æ®µè½çš„å†…å®¹ï¼Œè¦æ±‚å†…å®¹ç»“æ„æ¸…æ™°
  - Rerankè¿˜æ˜¯å¾ˆæœ‰å¿…è¦
  - topkçš„ç­–ç•¥é€‰æœ€ä¼˜å€¼ï¼Œå¤ªå°ä¸€å®šç¼ºçœï¼Œå¬å›ç‡éšä¾¿é«˜äº†
  - å¢åŠ embeddingæ¨¡å‹åœ¨rerankæ¨¡å‹ä¸­èåˆçš„æ•ˆæœï¼Œä¸çŸ¥é“ç›´æ¥ä½¿ç”¨æ•ˆæœå¦‚ä½•ï¼Œembedding+rerankæ¨¡å‹ä¸­åŒ…å«å¾—æ›´å¥½
  - å¥ç²’æ”¹å†™ä¼šæœ‰å¸®åŠ©ï¼Œæ”¹å†™çš„ç­–ç•¥å’Œæ–¹å‘è¦æ ¹æ®å…·ä½“ä¸šåŠ¡æ¥
  - è¦åœ¨æ£€ç´¢/æ£€ç´¢ç»“æœä¸Šä¸‹åŠŸå¤«
  - æ£€ç´¢ç­–ç•¥çš„æ”¹è¿›ï¼šæ··åˆæ£€ç´¢ã€ç´¢æ¡å¼•ã€æ£€ç´¢æ£€éªŒã€åˆ†å±‚æ£€ç´¢
  - æ¸…æ´—æ•°æ®ï¼Œåœ¨å¤„ç†æ•°æ®ä¸­æ¸…æ´—æ•°æ®ï¼Œä¸æ˜¯æ£€ç´¢èŒƒå›´è¿‡æ»¤
  - RAGè¾ƒé•¿çš„å†…å®¹ï¼Œæ£€ç´¢åˆ°äº†ä¸€å®šå†…å®¹çš„å†…å®¹ï¼Œæ£€ç´¢åˆ°äº†ä¸€å®šå†…å®¹ï¼ˆç»“åˆæœ‰çŸ¥è¯†æ£€ç´¢ï¼‰
  - å¢åŠ promptç­–ç•¥ï¼Œå¢åŠ promptåœ¨æ£€ç´¢ç­–ç•¥ä¸­çš„åº”ç”¨
  - Summaryä¸ä¸€å®šåœ¨chunkéœ€è¦summaryï¼Œæœ‰çš„ä¸è¦
  - ç”¨æˆ·çš„ query æœ€å¥½éƒ½å»åšé‡å†™ï¼Œå¤šè½®å¯¹è¯åœºæ™¯ä¸‹å°¤ä¸ºé‡è¦ã€‚æ ¸å¿ƒè¿˜æ˜¯è¦åšåˆ°æŒ‡ä»£æ¶ˆè§£ï¼Œè¿›è€Œæå‡å¬å›ç‡
  - åˆ‡ Chunk å…¶å®è¿˜æ˜¯æŒºè®²ç©¶çš„ï¼Œåˆ‡ç¢ä¸€ç‚¹è™½ç„¶å¯ä»¥ç²¾å‡†å®šä½åˆ°æ¯ä¸ªæ®µè½çš„åæ ‡ï¼Œä½†æ‹¿ç¢çš„å—å»å¬å›ä¼šå¯¼è‡´ç¼ºå°‘ä¿¡æ¯,  ç¢å— åŸºç¡€ä¸Šå†èšåˆä¸€å±‚å˜æˆå¤§ chunk ï¼Œè¿™ä¸ªæ•ˆæœå°±ä¼šå¥½å¾ˆå¤š
  - éœ€è¦æœ‰ä¸€ä¸ªå®Œå–„çš„è¯„æµ‹ä½“ç³»ï¼Œç¡®ä¿æ¯æ¬¡ä¼˜åŒ–éƒ½æ˜¯ä¸€ä¸ªå¸•ç´¯æ‰˜ä¼˜åŒ–
- RAG åº”ç”¨ç”Ÿäº§ç¯å¢ƒä¸­æœ‰æ•ˆéƒ¨ç½²å‘é‡æ•°æ®åº“çš„å…³é”®æŠ€å·§
  - è®¾è®¡ä¸€ä¸ªæœ‰æ•ˆçš„ Schemaï¼šä»”ç»†è€ƒè™‘æ•°æ®ç»“æ„åŠå…¶æŸ¥è¯¢æ–¹å¼ï¼Œåˆ›å»ºä¸€ä¸ªå¯ä¼˜åŒ–æ€§èƒ½å’Œæä¾›å¯æ‰©å±•æ€§çš„ Schemaã€‚
    - ä¸»é”®ï¼šåœ¨ Milvus ä¸­ï¼Œä¸»é”®é€šå¸¸ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œåœ¨ RAG ç”¨ä¾‹ä¸­å¯èƒ½ä¼šå°† chunk ID ä½œä¸ºä¸»é”®ã€‚ä¸»é”®ä¼šè¢«é¢‘ç¹è®¿é—®ï¼Œå¯ä»¥å¼€å¯è‡ªåŠ¨ç”Ÿæˆï¼ˆAuto IDï¼‰
    - Partition keyï¼šåœ¨ Milvus ä¸­åˆ›å»º Collection æ—¶ï¼Œå¯ä»¥æŒ‡å®š Partition keyã€‚è¿™ä¸ªé”®å…è®¸ Milvus æ ¹æ®é”®å€¼å°†æ•°æ® Entity å­˜å‚¨åœ¨ä¸åŒçš„ Partition ä¸­ï¼Œæœ‰æ•ˆå°†æ•°æ®ç»„ç»‡æˆå¯ç®¡ç†çš„ Segment

      | å­—æ®µåç§°         | å­—æ®µæ•°æ®ç±»å‹ | æè¿°                                                                 | ç¤ºä¾‹å€¼            |
      |------------------|--------------|----------------------------------------------------------------------|-------------------|
      | chunkID          | Int64        | ä¸»é”®ã€‚ä¸»é”®å€¼å…¨å±€å”¯ä¸€ã€‚                                               | 123456789         |
      | userID           | Int64        | Partition keyã€‚æ ¹æ®ç”¨æˆ· ID (userID) è¿›è¡Œæ•°æ®åˆ†åŒºã€‚ç¡®ä¿åŒä¸€ç”¨æˆ· ID çš„æ•°æ®å‡åˆ†åŒºåœ¨ä¸€èµ·ã€‚ | 987654321         |
      | docID            | Int64        | æ–‡æ¡£çš„ç‰¹æœ‰æ ‡è¯†ç¬¦ã€‚ç”¨äºå°†åŒä¸€ç¯‡æ–‡æ¡£çš„ä¸åŒ Chunk è”ç³»èµ·æ¥ã€‚             | 555666777         |
      | chunkData        | varchar      | æ–‡æ¡£ä¸­çš„ä¸€éƒ¨åˆ†æ•°æ®ã€‚ä¿å­˜æå–åçš„æ–‡æ¡£å†…å®¹ã€‚                           | "This is a part of the document." |
      | dynamicParams    | JSON         | å­˜å‚¨æ–‡æ¡£çš„åŠ¨æ€å‚æ•°ã€‚å¯ä»¥æ˜¯æ–‡æ¡£çš„å…ƒæ•°æ®ã€‚                             | {"name": "Example Document", "source": "www.example.com"} |
      | sparseVector     | ç‰¹æ®Šæ ¼å¼     | è¡¨ç¤ºç¨€ç–å‘é‡çš„æ•°æ®ã€‚ä»…åœ¨æŸäº›ç‰¹å®šåœºæ™¯ä¸‹ä½¿ç”¨ã€‚                          | [0.0, 0.1, 0.0, 0.3] |
      | denseVector      | ç‰¹æ®Šæ ¼å¼     | è¡¨ç¤ºç¨ å¯†å‘é‡çš„æ•°æ®ã€‚                                                 | [0.1, 0.2, 0.3, 0.4] |
  - è€ƒè™‘å¯æ‰©å±•æ€§ï¼šè€ƒè™‘æœªæ¥çš„æ•°æ®è§„æ¨¡å¢é•¿ï¼Œå¹¶å……åˆ†è®¾è®¡æ¶æ„ä»¥é€‚åº”ä¸æ–­å¢é•¿çš„æ•°æ®é‡å’Œç”¨æˆ·æµé‡ã€‚
    - Partition è¿›è¡Œå¤šç§Ÿç®¡ç†ä¹Ÿæœ‰åŠ©äºæé«˜å¯æ‰©å±•æ€§å’Œæ€§èƒ½ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°ç»„ç»‡äº†æ•°æ®ï¼Œå¹¶é€šè¿‡é™åˆ¶é€‚å½“ç”¨æˆ·çš„æ•°æ®å¯è§æ€§æ¥å¢å¼ºæ•°æ®å®‰å…¨å’Œéšç§
  - é€‰æ‹©æœ€ä½³ç´¢å¼•å¹¶ä¼˜åŒ–æ€§èƒ½ï¼šæ ¹æ®ç”¨ä¾‹é€‰æ‹©æœ€åˆé€‚çš„ç´¢å¼•æ–¹æ³•ï¼Œå¹¶æŒç»­ç›‘æ§å’Œè°ƒæ•´æ€§èƒ½ã€‚
    - GPU ç´¢å¼•æ˜¯é«˜æ€§èƒ½ç¯å¢ƒçš„é¦–é€‰é€‰é¡¹ï¼Œæ”¯æŒå¿«é€Ÿçš„æ•°æ®å¤„ç†å’Œæ£€ç´¢ã€‚
    - å†…å­˜ç´¢å¼•æ˜¯ä¸€ä¸ªä¸­é—´é€‰é¡¹ï¼Œå¹³è¡¡äº†æ€§èƒ½å’Œå®¹é‡ï¼Œæä¾›äº†è‰¯å¥½çš„ QPSï¼Œå¹¶èƒ½å¤Ÿæ‰©å±•åˆ° TB çº§å­˜å‚¨ï¼Œå¹³å‡å»¶æ—¶çº¦ä¸º 10 æ¯«ç§’ã€‚
    - ç£ç›˜ç´¢å¼•å¯ä»¥ç®¡ç†æ•°å TB çš„æ•°æ®ï¼Œå»¶æ—¶çº¦ä¸º 100 æ¯«ç§’ï¼Œé€‚ç”¨äºè¾ƒå¤§ä¸”å¯¹æ—¶é—´æ•æ„Ÿåº¦è¾ƒä½çš„æ•°æ®é›†ã€‚Milvus æ˜¯å”¯ä¸€æ”¯æŒç£ç›˜ç´¢å¼•çš„å¼€æºå‘é‡æ•°æ®åº“ã€‚
    - Swap ç´¢å¼•ä¿ƒè¿›äº† S3 æˆ–å…¶ä»–å¯¹è±¡å­˜å‚¨è§£å†³æ–¹æ¡ˆä¸å†…å­˜ä¹‹é—´çš„æ•°æ®äº¤æ¢
- [Building A Generative AI Platform](https://huyenchip.com/2024/07/25/genai-platform.html)
- [é•¿æ–‡æœ¬ä¸RAG](https://mp.weixin.qq.com/s/AT0tNqhqdq5VvxEUajX-2g)
  - å‡†ç¡®ç‡ï¼šé€šå¸¸æƒ…å†µä¸‹é•¿æ–‡æœ¬ä¼˜äºRAG 
  - é•¿æ–‡æœ¬ï¼šå—é™çš„å› ç´ æ¯”è¾ƒå¤šã€‚
    - æ¯”å¦‚å¹¶å‘æ€§èƒ½ä¼šéšç€ä¸Šä¸‹æ–‡é•¿åº¦çš„å¢åŠ åæ¯”ä¸‹é™ï¼Œé¢„å¡«å……çš„å»¶è¿Ÿä¹Ÿæ˜¯ä¼šéšä¸Šä¸‹æ–‡é•¿åº¦çš„å¢é•¿å¹³æ–¹çº§åˆ«çš„å¢é•¿ï¼›
    - è§£ç å»¶è¿Ÿå’Œä¸Šä¸‹æ–‡åˆ‡æ¢çš„å¼€é”€ä¹Ÿæ˜¯ä¼šçº¿æ€§çš„å¢åŠ ï¼›
    - æœ€æˆç“¶é¢ˆçš„æ˜¯é¢„å¡«å……å»¶è¿Ÿï¼Œå› ä¸ºå®ƒæ˜¯ä¼šå¹³æ–¹çº§åˆ«çš„å¢é•¿ï¼Œè¿™ä¹Ÿæ˜¯æ„æˆç›®å‰é•¿ä¸Šä¸‹æ–‡æ¨ç†çš„ä¸»è¦éš¾åº¦ã€‚
  - é•¿æ–‡æœ¬å¦‚ä½•ä¼˜åŒ–First Tokenå»¶è¿Ÿé—®é¢˜
    - å·¥ç¨‹å±‚é¢ï¼šæ¯”å¦‚è¯´Flash attentionã€‚
    - ç¡¬ä»¶å±‚é¢ï¼šæ¯”å¦‚è¯´è‹±ä¼Ÿè¾¾æœ‰ä¸€äº›æ–°çš„æŠ€æœ¯ã€‚
    - ç®—æ³•çš„å±‚é¢ï¼šç”¨çš„æ¯”è¾ƒå¤šçš„æ˜¯KV cache
  - Context windowè¶Šå¤§é™¤äº†æˆæœ¬ä¼šå¢é•¿ä¹‹å¤–ï¼Œé¦– token å»¶è¿Ÿä¼šæ˜¾è‘—çš„å¢åŠ ã€‚æ¯”å¦‚128Kçš„æ¨¡å‹ï¼Œå¦‚æœå…¨ç”¨æ»¡ï¼Œéœ€è¦å¤§æ¦‚å‡ åç§’é’Ÿçš„æ—¶é—´æ‰èƒ½è¿”å›é¦–token
  - RAGè‚¯å®šæ˜¯ç›¸å¯¹å¤šä¸€äº›å‡†ç¡®åº¦çš„æŸè€—ã€‚å› ä¸ºæœ€åè¿˜æ˜¯è¦æŠŠè¿‡RAGçš„ä¿¡æ¯ç»™åˆ°å¤§æ¨¡å‹ï¼ˆRAGæœ¬èº«çš„å‡†ç¡®åº¦æŸè€—+å¤§æ¨¡å‹çš„å‡†ç¡®åº¦æŸè€— vs åªæœ‰å¤§æ¨¡å‹çš„å‡†ç¡®åº¦æŸè€—ï¼‰ã€‚
- Embedding model
  - [MSMARCO Models](https://www.sbert.net/docs/pretrained-models/msmarco-v5.html?highlight=dot%20product)
    - MS MARCO is a large scale information retrieval corpus that was created based on real user search queries using Bing search engine
  - [Train and evaluate embedding model](https://zilliz.com/learn/evaluating-your-embedding-model)
  - [https://weaviate.io/blog/how-to-choose-an-embedding-model](https://weaviate.io/blog/how-to-choose-an-embedding-model)
  - [Jina Embeddings V3](https://mp.weixin.qq.com/s/n3qH2jCpbCV23A_hg-ce-Q)
    - https://mp.weixin.qq.com/s/EQsgkQX8PtWTN69axJ7uOQ
    - jina-embeddings-v3 åŸºäº XLM-RoBERTa æ¨¡å‹æ¶æ„ï¼Œæˆ‘ä»¬ä¸»è¦é’ˆå¯¹å¤šè¯­è¨€é•¿æ–‡æœ¬çš„å¤„ç†ï¼Œä»¥åŠå¤šä»»åŠ¡åœºæ™¯è¿›è¡Œäº†ä¼˜åŒ–
    - æ²¿ç”¨äº† XLM-RoBERTa åˆ†è¯å™¨, 5.7 äº¿å‚æ•°çš„é¡¶çº§æ–‡æœ¬å‘é‡æ¨¡å‹
      - ä½¿ç”¨ RoPE å»åš position embeddings ä»¥ä¿è¯é•¿æ–‡æœ¬å¬å›æ€§èƒ½ï¼ŒFlashAttention2 å»æ”¹è¿›æ³¨æ„åŠ›æœºåˆ¶çš„è®­ç»ƒå’Œæ¨ç†æ€§èƒ½ã€‚
      - æˆ‘ä»¬é‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒæ–¹å¼ï¼šä»å¤´å¼€å§‹å¯¹æ•´ä¸ªæ¨¡å‹é¢„è®­ç»ƒï¼ŒäºŒæ®µ pairwise è®­ç»ƒï¼Œä¸‰æ®µ hard-negative triplet è®­ç»ƒã€‚
      - å†…ç½®å¤šç§ LoRA é€‚é…å™¨ï¼Œå¯ä»¥æ ¹æ®ä½ çš„éœ€æ±‚ï¼Œé’ˆå¯¹ æ£€ç´¢ã€èšç±»ã€åˆ†ç±»å’ŒåŒ¹é… çš„ä¸åŒåœºæ™¯è¿›è¡Œå®šåˆ¶ï¼Œè·å¾—æ›´ç²¾å‡†çš„å‘é‡åŒ–æ•ˆæœ
      - LoRA adapter å…¶å®è¢«æ’å…¥åˆ° 24 å±‚ Transformer çš„æ¯ä¸€å±‚ä¸­äº†ã€‚åœ¨é€‰æ‹©ä¸€é¡¹ä»»åŠ¡æ—¶ï¼Œé‚£ä¸ªä»»åŠ¡å¯¹åº”çš„ LoRA adapter å°±ä¼šè¢«æ¿€æ´»ï¼Œä»è€Œå‚ä¸åˆ°æ¯ä¸€å±‚çš„è®¡ç®—ä¸­æ¥
    - å¤šè¯­è¨€æ”¯æŒ: æ”¯æŒ 89 ç§è¯­è¨€ï¼Œå…¨é¢è¶…è¶Š multilingual-e5-large-instruct
    - é•¿æ–‡æœ¬å¤„ç†: æ”¯æŒ 8192 token çš„è¾“å…¥é•¿åº¦ï¼Œåœ¨ LongEmbed åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²
    - ä»»åŠ¡å®šåˆ¶æ›´ç²¾å‡†: å†…ç½®å¤šç§ LoRA é€‚é…å™¨ï¼Œé’ˆå¯¹æ£€ç´¢ã€èšç±»ã€åˆ†ç±»å’ŒåŒ¹é…ç­‰ä»»åŠ¡ï¼Œç”Ÿæˆå®šåˆ¶åŒ–å‘é‡ï¼Œæ•ˆæœæ›´ç²¾å‡†ã€‚
    - è¾“å‡ºç»´åº¦å¯å®šåˆ¶: é»˜è®¤è¾“å‡ºç»´åº¦ä¸º 1024ï¼Œä½†ä½ å®Œå…¨å¯ä»¥æ ¹æ®éœ€è¦æŠŠå®ƒç¼©å‡åˆ° 32ï¼Œæ€§èƒ½å‡ ä¹ä¸å—å½±å“ï¼Œè¿™éƒ½å½’åŠŸäºä¿„ç½—æ–¯å¥—å¨ƒè¡¨ç¤ºå­¦ä¹ æŠ€æœ¯çš„åŠ æŒ
    - é’ˆå¯¹å¼‚æ„æœç´¢ã€åŒæ„åŒ¹é…ã€åˆ†ç±»ã€èšç±»å››ç±»ä»»åŠ¡åšäº†ç‰¹åˆ«çš„ Adapter è®¾è®¡å’Œè®­ç»ƒï¼ŒåŸºæœ¬ä¸Š Embedding çš„ä½¿ç”¨åœºæ™¯éƒ½å¯ä»¥è¢«åˆ’åˆ†åˆ°è¿™å››ç±»ä»»åŠ¡ä¸Šã€‚
    - [v2 åˆ° v3 çš„è¿ç§»](https://mp.weixin.qq.com/s/wdoWD_i8G095-GdU5ZSn5Q)
  - [jina embeddings v4](https://jina.ai/news/quantization-aware-training-of-jina-embeddings-v4/)
    - é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ
      - é‡åŒ–æ˜¯è§£å†³äººå·¥æ™ºèƒ½æ‰©å±•é—®é¢˜çš„ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•ã€‚ è¿™ä¸ªåå­—å¬èµ·æ¥å¾ˆå¤æ‚ï¼Œä½†å®ƒåªæ˜¯å¯¹æ•°å­—è¿›è¡Œå››èˆäº”å…¥ï¼Œä»¥å‡å°‘å®ƒä»¬å ç”¨çš„ç©ºé—´ã€‚ 
      - è¿™æ„å‘³ç€æ›´å°çš„ å‘é‡æ¨¡å‹ (Embeddings)ï¼Œå ç”¨æ›´å°‘çš„å†…å­˜å’Œå­˜å‚¨ç©ºé—´ï¼Œå¹¶ä¸”ç”±äºæ¯”è¾ƒå‘é‡æ‰€éœ€çš„æ—¶é—´æ›´å°‘ï¼Œå› æ­¤ä¿¡æ¯æ£€ç´¢é€Ÿåº¦æ›´å¿«
    - æ¨¡å‹é‡åŒ–é€šå¸¸æ„å‘³ç€ä»¥ä¸‹å››ä»¶äº‹ä¹‹ä¸€ï¼š
      - è®­ç»ƒåé‡åŒ–ï¼ˆPTQï¼‰
        - æ¥å—ç»è¿‡è®­ç»ƒçš„ å‘é‡æ¨¡å‹ (Embeddings) æ¨¡å‹ï¼Œå¹¶ä¸”ä¸ä»¥ä»»ä½•æ–¹å¼ä¿®æ”¹å®ƒã€‚ è¿™åªæ˜¯ä¸¢å¼ƒæ¨¡å‹äº§ç”Ÿçš„æµ®ç‚¹å€¼çš„æœ€ä½æœ‰æ•ˆæ•°å­—çš„é—®é¢˜ã€‚ æˆ‘ä»¬åªæ˜¯å¯¹æ•°å­—è¿›è¡Œå››èˆäº”å…¥ï¼Œæœ‰æ—¶è¿˜ä¼šå°†å®ƒä»¬ç¼©æ”¾åˆ°ä¸€ä¸ªèŒƒå›´ã€‚
      - é‡åŒ– å‘é‡æ¨¡å‹ (Embeddings) è¾“å‡ºè®­ç»ƒï¼ˆOutput QATï¼‰
        - å¾®è°ƒ å‘é‡æ¨¡å‹ (Embeddings) æ¨¡å‹ä»¥äº§ç”Ÿæœ€ä½³çš„é™ä½ç²¾åº¦å‘é‡ã€‚ è¿™æ„å‘³ç€ä¿®æ”¹æ¨¡å‹ï¼Œä½†å®ƒä¸ä¼šæ”¹å˜æ¨¡å‹æƒé‡çš„ç²¾åº¦ï¼Œå› æ­¤ä¸ä¼šå‡å°å…¶å¤§å°ã€‚ åªæ˜¯è¾“å‡ºå‘é‡çš„å¤§å°å‡å°äº†
      - å®Œå…¨é‡åŒ–æ¨¡å‹è®­ç»ƒï¼ˆFull QATï¼‰
        - ä»ä¸€ä¸ªå®Œå…¨è®­ç»ƒå¥½çš„ã€å…¨ç²¾åº¦çš„æ¨¡å‹å¼€å§‹ï¼Œé™ä½æ¨¡å‹æƒé‡çš„ç²¾åº¦ï¼Œç„¶åå¾®è°ƒè¿™ä¸ªä¿®æ”¹åçš„æ¨¡å‹çš„æ€§èƒ½ã€‚
      - ä»ç°æœ‰éé‡åŒ–æ¨¡å‹ä¸­æç‚¼å‡ºä¸€ä¸ªæ–°çš„é‡åŒ–æ¨¡å‹
        - Distillation æ˜¯è®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹ä»¥åŒ¹é…ç°æœ‰æ¨¡å‹æ€§èƒ½çš„è¿‡ç¨‹ã€‚ è¿™æ„å‘³ç€åˆ›å»ºä¸€ä¸ªä»å¤´å¼€å§‹è®¾è®¡ä¸ºé‡åŒ–çš„æ–°æ¨¡å‹ï¼Œç„¶åä½¿ç”¨ç°æœ‰æ¨¡å‹ç”Ÿæˆæ‰€éœ€çš„å°½å¯èƒ½å¤šçš„è®­ç»ƒæ•°æ®æ¥è®­ç»ƒå®ƒï¼Œç›´åˆ°å®ƒçš„æ€§èƒ½å°½å¯èƒ½æ¥è¿‘ç°æœ‰æ¨¡å‹
    - å®éªŒ
      - åŸºçº¿æ¨¡å‹æ˜¯å¸¦æœ‰æ£€ç´¢é€‚é…å™¨çš„ jina-embeddings-v4ï¼Œå®ƒäº§ç”Ÿ 2048 ç»´çš„ 32 ä½ç²¾åº¦æµ®ç‚¹ (FP32) å‘é‡ã€‚ å› æ­¤ï¼Œæ¯ä¸ª å‘é‡æ¨¡å‹ (Embedding) çš„å¤§å°ä¸º 8196 å­—èŠ‚ï¼Œå³ 8kBã€‚
      - PTQâ€”â€”æˆ‘ä»¬é‡åŒ–äº†è¾“å‡ºå‘é‡ä¸ºäºŒè¿›åˆ¶å‘é‡ï¼Œè€Œæ²¡æœ‰æ›´æ”¹æ¨¡å‹ã€‚
      - Output QATâ€”â€”æˆ‘ä»¬é‡åŒ–äº†è¾“å‡ºå‘é‡ï¼Œå¹¶å¯¹æ£€ç´¢é€‚é…å™¨è¿›è¡Œäº†å¾®è°ƒï¼Œä»¥æé«˜å…¶åœ¨é‡åŒ–æ¡ä»¶ä¸‹çš„æ€§èƒ½ã€‚
      - è¯•éªŒäº†å››ä¸ªä¸åŒçš„é‡åŒ–çº§åˆ«ã€‚
        - 8 ä½æ•´æ•°â€”â€”FP32 å€¼è¢«ç¼©å‡ä¸º -128 åˆ° 127 èŒƒå›´å†…çš„æ•´æ•°ï¼Œä»è€Œå°† å‘é‡æ¨¡å‹ (Embeddings) ç¼©å° 4 å€è‡³ 2048 å­—èŠ‚ã€‚
        - 4 ä½æ•´æ•°â€”â€”ä¸ 4 ä½æ•´æ•°ç›¸åŒï¼Œä½†æˆ‘ä»¬æ˜ å°„åˆ° -8 åˆ° 7 çš„èŒƒå›´ï¼Œå°†å‘é‡å¤§å°ç¼©å° 8 å€ï¼Œè‡³ 1024 å­—èŠ‚ã€‚
        - ä¸‰å…ƒé‡åŒ–â€”â€”æ‰€æœ‰å€¼éƒ½æ˜ å°„åˆ°ä¸‰ä¸ªå€¼ä¹‹ä¸€ï¼š-1ã€0ã€1ã€‚ä»¥æœ€ä½³æ–¹å¼å­˜å‚¨æ—¶ï¼Œè¿™ä¼šå°†æ¯ä¸ªç»´åº¦å‡å°‘åˆ° 1.6 ä½ï¼Œä»è€Œå°† å‘é‡æ¨¡å‹ (Embedding) çš„å¤§å°å¤§è‡´å‡å°‘ 40 å€è‡³å¤§çº¦ 230 å­—èŠ‚ã€‚
        - äºŒè¿›åˆ¶é‡åŒ–â€”â€”æˆ‘ä»¬ä½¿ç”¨ torch.sign æ•°æ®ç±»å‹å°† FP32 æ ‡é‡å€¼è½¬æ¢ä¸ºä¸€ä½ï¼Œè¯¥æ•°æ®ç±»å‹ä»…æä¾›ä¸¤ä¸ªå€¼ï¼Œå ç”¨ä¸€ä½æ¥å­˜å‚¨ã€‚ è¿™ä¼šå°† 2048 ç»´ å‘é‡æ¨¡å‹ (Embedding) ä» 8192 å­—èŠ‚å‡å°‘åˆ° 128 å­—èŠ‚ï¼Œå‡å°‘äº† 64 å€ã€‚
      - æµ‹è¯•è¡¨æ˜ï¼Œæ»šåŠ¨å¹³å‡ç¼©æ”¾æ–¹æ³•ä¼˜äºç®€å•çš„ min/max æ–¹æ³•
      - è™½ç„¶ç®€å•çš„è®­ç»ƒåé‡åŒ– (PTQ) åœ¨å†…å­˜å’Œå­˜å‚¨æ–¹é¢æä¾›äº†ç«‹ç«¿è§å½±çš„å¥½å¤„ï¼Œä½†æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒ (QAT) æ˜¾ç€å‡è½»äº†ä¸å¯é¿å…çš„ç²¾åº¦æŸå¤±ã€‚ å¾®è°ƒå§‹ç»ˆäº§ç”Ÿæ›´å¥½çš„åˆ†æ•°
  - [Matryoshka Embeddings](https://milvus.io/blog/matryoshka-embeddings-detail-at-multiple-scales)
    - Matryoshka Representation Learning is a technique used in training embedding models. It allows you to trade off a small amount of accuracy in exchange for much smaller embedding sizes
      - Thus, you can store more information at a lower cost and search for it faster.
      - https://weaviate.io/blog/openais-matryoshka-embeddings-in-weaviate
    - Matryoshka embeddings learn this multi-scale structure during the initial training process.
    - The result is remarkable: not only does the full embedding capture input semantics, but each nested subset prefix (first half, first quarter, etc.) provides a coherent, if less detailed, representation.
    - Need a quick approximate search? Use the smallest â€œdoll.â€ Need maximum accuracy? Use the full embedding.
    - funnel search approach
      - First, we perform an initial similarity search using only the first 1/32 of the embedding dimensions, generating a broad pool of candidate items
      - We then rerank these candidates based on their similarity to the query using the first 1/16 of the dimensions, pruning a portion of the list.
  - ğ¦ğ®ğ¥ğ­ğ¢-ğ¯ğğœğ­ğ¨ğ« ğ¦ğ¨ğğğ¥ğ¬
    - ğ¬ğ¢ğ§ğ ğ¥ğ ğ¯ğğœğ­ğ¨ğ« (dense) embeddings compress entire documents into one representation
    - ğ¦ğ®ğ¥ğ­ğ¢-ğ¯ğğœğ­ğ¨ğ« ğ¦ğ¨ğğğ¥ğ¬ models with late interaction are revolutionizing information retrieval by maintaining token-level semantics.
    - Why multi-vector models outperform traditional approaches:
      -  They preserve granular meaning rather than averaging it
      - Enable precise token-to-token matching between queries and documents
      - Perfect balance between speed and accuracy
    - ğ‚ğ¨ğ¥ğğ„ğ‘ğ“: Text-specialized, ideal for high-precision RAG
    -  ğ‚ğ¨ğ¥ğğšğ¥ğ¢: Multimodal processing with PaliGemma Vision LLM
    - ğ‚ğ¨ğ¥ğğ°ğğ§: Apache 2.0 licensed alternative using Qwen2
- 15 Advanced RAG Techniques from Pre-Retrieval to Generation
  - å¢åŠ ä¿¡æ¯å¯†åº¦ï¼ˆIncrease Information Density Using LLMsï¼‰
    - åˆ©ç”¨ LLMsï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰å¤„ç†ã€æ¸…ç†å’Œæ ‡è®°æ•°æ®ï¼Œä»¥æé«˜ä¿¡æ¯å¯†åº¦ï¼Œä»è€Œå‡å°‘ç”Ÿæˆæ¨¡å‹æ‰€éœ€çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œé™ä½æˆæœ¬å¹¶æé«˜å“åº”å‡†ç¡®æ€§
  - åº”ç”¨åˆ†å±‚ç´¢å¼•æ£€ç´¢ï¼ˆApply Hierarchical Index Retrieval
    - åˆ©ç”¨æ–‡æ¡£æ‘˜è¦åˆ›å»ºå¤šå±‚ç´¢å¼•ï¼Œä¼˜å…ˆæ£€ç´¢ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„æ‘˜è¦éƒ¨åˆ†ï¼Œå†æ·±å…¥åˆ°è¯¦ç»†æ–‡æ¡£ï¼Œæé«˜æ£€ç´¢æ•ˆç‡ã€‚
  - æ”¹å–„æ£€ç´¢å¯¹ç§°æ€§ï¼ˆImprove Retrieval Symmetry with Hypothetical Question Indexï¼‰
    - ç”Ÿæˆæ¯ä¸ªæ–‡æ¡£çš„å‡è®¾é—®ç­”å¯¹ï¼Œå¹¶å°†è¿™äº›é—®ç­”å¯¹ä½œä¸ºæ£€ç´¢çš„åµŒå…¥å¯¹è±¡ï¼Œä»è€Œæé«˜æŸ¥è¯¢ä¸æ–‡æ¡£ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œå‡å°‘æ£€ç´¢æ—¶çš„ä¸Šä¸‹æ–‡ä¸¢å¤±
  - ä½¿ç”¨ LLMs å»é‡ä¿¡æ¯ï¼ˆDeduplicate Information in Your Data Index Using LLMsï¼‰
  - æµ‹è¯•å’Œä¼˜åŒ–åˆ†å—ç­–ç•¥ï¼ˆTest and Optimize Your Chunking Strategyï¼‰
    - æ ¹æ®å…·ä½“æƒ…å†µæµ‹è¯•ä¸åŒçš„åˆ†å—ç­–ç•¥ï¼Œé€šè¿‡è°ƒæ•´æ•°æ®å—å¤§å°å’Œé‡å ç‡ç­‰å‚æ•°ï¼Œæ‰¾åˆ°æœ€ä½³çš„åµŒå…¥æ–¹å¼ï¼Œä»¥æé«˜æ£€ç´¢æ•ˆæœã€‚
  - ä¼˜åŒ–æœç´¢æŸ¥è¯¢ï¼ˆOptimize Search Queries Using LLMsï¼‰
    - ç‰¹åˆ«æ˜¯é’ˆå¯¹å¯¹è¯ç³»ç»Ÿï¼Œä½¿ç”¨ LLMs æ ¹æ®ç³»ç»Ÿçš„æœç´¢éœ€æ±‚ä¼˜åŒ–ç”¨æˆ·çš„æŸ¥è¯¢è¯­å¥ï¼Œç¡®ä¿æœç´¢ç³»ç»Ÿèƒ½å¤Ÿæ›´å‡†ç¡®ã€é«˜æ•ˆåœ°æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚
  - ä½¿ç”¨å‡è®¾æ–‡æ¡£åµŒå…¥ä¿®æ­£æŸ¥è¯¢ä¸æ–‡æ¡£çš„éå¯¹ç§°æ€§ï¼ˆFix Query-Document Asymmetry with Hypothetical Document Embeddings (HyDE)ï¼‰
    - åœ¨æ£€ç´¢å‰ï¼Œç”Ÿæˆä¸€ä¸ªä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„å‡è®¾æ–‡æ¡£ï¼Œå¹¶ä½¿ç”¨è¿™ä¸ªæ–‡æ¡£çš„åµŒå…¥æ¥æ›¿ä»£ç”¨æˆ·çš„æŸ¥è¯¢è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œä»¥æé«˜æ£€ç´¢çš„å‡†ç¡®æ€§
  - å®æ–½æŸ¥è¯¢è·¯ç”±æˆ– RAG å†³ç­–æ¨¡å¼ï¼ˆImplement Query Routing or a RAG Decider Patternï¼‰
  - é‡æ–°æ’åä»¥ä¼˜åŒ–æœç´¢ç»“æœï¼ˆPrioritize Search Results with Rerankingï¼‰
  - ä½¿ç”¨ä¸Šä¸‹æ–‡å‹ç¼©ä¼˜åŒ–æœç´¢ç»“æœï¼ˆOptimize Search Results with Contextual Prompt Compressionï¼‰
    - é€šè¿‡ LLMs å¯¹æ£€ç´¢åˆ°çš„ä¿¡æ¯è¿›è¡Œå¤„ç†ã€å‹ç¼©æˆ–é‡æ–°æ ¼å¼åŒ–ï¼Œåªä¿ç•™ç”Ÿæˆæœ€ç»ˆå“åº”æ‰€éœ€çš„å…³é”®ä¿¡æ¯ã€‚
  - ä½¿ç”¨çº æ­£ RAG å¯¹æ£€ç´¢æ–‡æ¡£æ‰“åˆ†å’Œè¿‡æ»¤ï¼ˆScore and Filter Retrieved Documents with Corrective RAGï¼‰
    - ä½¿ç”¨ä¸€ä¸ªç»è¿‡è®­ç»ƒçš„æ¨¡å‹å¯¹ RAG ç»“æœè¿›è¡Œæ‰“åˆ†ï¼Œå°†ä¸ç›¸å…³æˆ–ä¸å‡†ç¡®çš„æ–‡æ¡£è¿‡æ»¤æ‰ï¼Œåªä¿ç•™æœ‰ç”¨çš„éƒ¨åˆ†ã€‚
  - é€šè¿‡é“¾å¼æ€ç»´æç¤ºå±è”½å™ªéŸ³ï¼ˆTune Out Noise with Chain-of-Thought Promptingï¼‰
  - è®©ç³»ç»Ÿå…·å¤‡è‡ªæˆ‘åæ€èƒ½åŠ›ï¼ˆMake Your System Self-Reflective with Self-RAGï¼‰
  - é€šè¿‡å¾®è°ƒå¿½ç•¥æ— å…³ä¸Šä¸‹æ–‡ï¼ˆIgnore Irrelevant Context Through Fine-Tuningï¼‰
  - ä½¿ç”¨è‡ªç„¶è¯­è¨€æ¨ç†è®© LLMs æ›´å¥½åœ°åº”å¯¹æ— å…³ä¸Šä¸‹æ–‡ï¼ˆUse Natural Language Inference to Make LLMs Robust Against Irrelevant Contextï¼‰
    - ä½¿ç”¨ NLI æ¨¡å‹è¿‡æ»¤æ‰æ— å…³ä¸Šä¸‹æ–‡ï¼Œä»…åœ¨ä½¿ç”¨é—®é¢˜å’Œ LLM ç”Ÿæˆçš„ç­”æ¡ˆè¢«åˆ†ç±»ä¸ºè•´å«æ—¶ï¼Œæ‰ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ã€‚
- [Prompt Tips - ilya](https://x.com/ilyasutsk/status/1832211266129293618)
  - æç¤ºç²¾ç¡®åŒ–:åœ¨ç¼–å†™æç¤ºæ—¶,åŠ›æ±‚è¡¨è¾¾æ¸…æ™°å‡†ç¡®ã€‚æ¸…æ¥šåœ°é˜è¿°ä»»åŠ¡éœ€æ±‚å’Œæ¦‚å¿µå®šä¹‰è‡³å…³é‡è¦ã€‚ä¾‹:ä¸ç”¨"åˆ†ææ–‡æœ¬",è€Œç”¨"åˆ¤æ–­è¿™æ®µè¯çš„æƒ…æ„Ÿå€¾å‘:ç§¯æã€æ¶ˆæè¿˜æ˜¯ä¸­æ€§"ã€‚
    - This tip emphasizes the importance of unambiguous language in prompts. Clarity reduces the chance of misinterpretation by the AI model.
    - Example: Unclear prompt: "Make it better." Clear prompt: "Revise the given text to improve grammar, clarity, and conciseness while maintaining the original meaning."
  - å¿«é€Ÿè¿­ä»£:å–„äºå¿«é€Ÿè¿ç»­è°ƒæ•´æç¤ºã€‚ç†Ÿç»ƒçš„æç¤ºå·¥ç¨‹å¸ˆèƒ½å¤Ÿçµæ´»åœ°è¿›è¡Œå¤šè½®ä¼˜åŒ–ã€‚ä¾‹:ä»"æ€»ç»“æ–‡ç« "åˆ°"ç”¨100å­—æ¦‚æ‹¬æ–‡ç« è¦ç‚¹",å†åˆ°"ç”¨100å­—æ€»ç»“æ–‡ç« ,èšç„¦æ°”å€™å½±å“"ã€‚
    - This approach allows for quick refinement and improvement of results. It's about not being afraid to try multiple variations quickly.
    - Example: First attempt: "Write a poem about spring." Refinement: "Write a haiku about cherry blossoms in spring." Further refinement: "Write a haiku about cherry blossoms in spring, emphasizing their ephemeral nature."
  - è¾¹ç•Œæµ‹è¯•:è®¾è®¡æç¤ºæ—¶,è€ƒè™‘æç«¯æƒ…å†µå’Œéå¸¸è§„åœºæ™¯ã€‚æ€è€ƒæç¤ºåœ¨ç‰¹æ®Šæƒ…å†µä¸‹å¯èƒ½å‡ºç°çš„é—®é¢˜ã€‚ä¾‹:è®¾è®¡æ•°å­¦è§£é¢˜å™¨æ—¶,è€ƒè™‘å¤„ç†è´Ÿæ•°ã€æå¤§å€¼å’Œé™¤é›¶ç­‰ç‰¹æ®Šæƒ…å†µã€‚
    - This tip encourages thinking beyond the typical use case to ensure robustness.
    - Example: Basic prompt: "Calculate the average of these numbers: 5, 10, 15." Edge case consideration: "Calculate the average of these numbers, handling any non-numeric inputs or empty sets: 5, 10, 15, apple, -20, []"
  - æ¨¡æ‹ŸçœŸå®è¾“å…¥:ç”¨ä¸è§„èŒƒã€çœŸå®çš„ç”¨æˆ·è¾“å…¥æµ‹è¯•æç¤ºã€‚ä¸è¦å‡è®¾ç”¨æˆ·æ€»æ˜¯æä¾›å®Œç¾æ ¼å¼çš„æŸ¥è¯¢ã€‚ä¾‹:æµ‹è¯•"1+1ç­‰äºå‡ "ã€"ä¸€åŠ ä¸€æ˜¯å¤šå°‘å•Š"ã€"1+1=?"ç­‰å¤šç§è¡¨è¾¾ã€‚
    - This ensures your prompts can handle real-world scenarios where users might not provide perfect input.
    - Example: Ideal input: "Translate 'Hello, how are you?' to French." Realistic input: "tranlate to french: hello how r u"
  - è¾“å‡ºåˆ†æ:ä»”ç»†æ£€æŸ¥æ¨¡å‹çš„å›ç­”ã€‚ç¡®ä¿æ¨¡å‹ä¸¥æ ¼æŒ‰ç…§æŒ‡ä»¤æ‰§è¡Œä»»åŠ¡ã€‚ä¾‹:è¦æ±‚åˆ—ä¸¾5ç§æ°´æœæ—¶,æ£€æŸ¥æ˜¯å¦ç¡®å®åˆ—å‡º5é¡¹ä¸”æ¯é¡¹éƒ½æ˜¯æ°´æœã€‚
    - This involves critically examining whether the model's response aligns with the intended outcome.
    - Example: Prompt: "List 5 capital cities in Europe." Output analysis: Check if all listed cities are indeed capital cities and located in Europe.
  - æ˜ç¡®ä»»åŠ¡ç»†èŠ‚:æ¶ˆé™¤éšå«å‡è®¾,è¯¦ç»†è¯´æ˜å®Œæˆä»»åŠ¡æ‰€éœ€çš„å…¨éƒ¨ä¿¡æ¯ã€‚ç³»ç»Ÿæ€§åœ°æ‹†è§£ä»»åŠ¡,ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…è¦å…ƒç´ ã€‚ä¾‹:ä¸è¯´"è®¡ç®—é¢ç§¯",è€Œè¯´"è®¡ç®—ä¸€ä¸ª10ç±³é•¿ã€5ç±³å®½çš„é•¿æ–¹å½¢é¢ç§¯,ç”¨å¹³æ–¹ç±³è¡¨ç¤º"ã€‚
    - This tip emphasizes providing all necessary context and avoiding implicit assumptions.
    - Example: Assumption-laden prompt: "Convert the temperature." Clear, detailed prompt: "Convert 25 degrees Celsius to Fahrenheit. Use the formula: Â°F = (Â°C Ã— 9/5) + 32. Round the result to two decimal places."
  - è€ƒè™‘æ¨¡å‹ç†è§£:ç¼–å†™æç¤ºæ—¶,è®¾èº«å¤„åœ°è€ƒè™‘æ¨¡å‹å¯èƒ½çš„ç†è§£æ–¹å¼ã€‚é¢„æƒ³æ¨¡å‹å¯èƒ½è¯¯è§£æŒ‡ä»¤çš„æƒ…å†µã€‚ä¾‹:é¿å…ä½¿ç”¨"å¥½"è¿™æ ·æ¨¡ç³Šçš„è¯,å› ä¸ºå®ƒå¯èƒ½æŒ‡é“å¾·ä¸Šçš„å¥½æˆ–è´¨é‡ä¸Šçš„å¥½ã€‚
    - This involves considering how the AI might interpret instructions differently than a human would.
    - Example: Potential misinterpretation: "Draw a house." Clearer prompt: "Describe in words a simple drawing of a house, including details about its shape, windows, door, and roof."
  - ç‰ˆæœ¬ç®¡ç†:å¯¹æç¤ºè¿›è¡Œç‰ˆæœ¬æ§åˆ¶,è¿½è¸ªå®éªŒè¿‡ç¨‹ã€‚åƒç®¡ç†ä»£ç ä¸€æ ·ç®¡ç†å’Œè¿­ä»£æç¤ºã€‚ä¾‹:ä½¿ç”¨Gitç®¡ç†æç¤ºç‰ˆæœ¬,è®°å½•æ¯æ¬¡ä¿®æ”¹çš„åŸå› å’Œæ•ˆæœã€‚
    - This tip suggests treating prompts like code, using tools to manage iterations and experiments.
    - Example: Version 1: "Summarize the text in 100 words." Version 2: "Summarize the text in 100 words, focusing on key events and main characters." Version 3: "Provide a 100-word summary of the text, highlighting the plot progression and character development."
  - ä¸»åŠ¨æ¾„æ¸…:è¦æ±‚æ¨¡å‹æŒ‡å‡ºæŒ‡ä»¤ä¸­ä¸æ˜ç¡®æˆ–æ¨¡ç³Šçš„éƒ¨åˆ†ã€‚è¿™æœ‰åŠ©äºæ”¹è¿›æç¤ºè´¨é‡ã€‚ä¾‹:åœ¨æç¤ºæœ«å°¾åŠ ä¸Š"å¦‚æœ‰ä¸æ¸…æ¥šä¹‹å¤„,è¯·æŒ‡å‡º"ã€‚
    - This approach leverages the model's capabilities to improve your prompts.
    - Example: Prompt: "Explain quantum entanglement. Then, identify any parts of this instruction that could be made clearer or more specific."
  - ç²¾ç®€è¡¨è¾¾:è¿½æ±‚ç²¾ç¡®ä½†ä¸è¿‡åº¦å¤æ‚åŒ–ã€‚ç»™å‡ºæ˜ç¡®çš„ä»»åŠ¡æè¿°,é¿å…ä¸å¿…è¦çš„æŠ½è±¡ã€‚ä¾‹:ç”¨"ç”Ÿæˆ10ä¸ªéšæœºæ•´æ•°åˆ—è¡¨"è€Œé"åˆ›å»ºå­˜å‚¨å¤šä¸ªæ•´å‹å…ƒç´ çš„æ•°æ®ç»“æ„"ã€‚
    - This balances the need for clarity with the importance of simplicity.
    - Example: Overcomplicated: "Utilizing your vast knowledge of culinary arts and nutritional science, construct a detailed, step-by-step methodology for the creation of a simple yet nutritious sandwich, taking into account dietary restrictions and flavor profiles."
    - Precise and simple: "Provide a recipe for a healthy sandwich, including ingredients and preparation steps."
  - å¹³è¡¡å¤„ç†:åœ¨å¤„ç†å¸¸è§æƒ…å†µå’Œè¾¹ç¼˜æƒ…å†µä¹‹é—´æ‰¾å¹³è¡¡ã€‚å…³æ³¨è¾¹ç¼˜æƒ…å†µçš„åŒæ—¶,ä¸å¿½è§†ä¸»è¦ç”¨ä¾‹ã€‚ä¾‹:è®¾è®¡æ—¥æœŸè§£æå™¨æ—¶,æ—¢å¤„ç†å¸¸è§æ—¥æœŸæ ¼å¼,ä¹Ÿè€ƒè™‘é—°å¹´ç­‰ç‰¹æ®Šæƒ…å†µã€‚
    - This tip reminds us to handle unusual scenarios without losing focus on the main use case.
    - Example: Balanced prompt: "Create a function to calculate the area of a circle. The function should handle positive real numbers for the radius and return 'Invalid input' for negative or non-numeric inputs."
  - ç³»ç»Ÿæ•´åˆ:æ€è€ƒæç¤ºå¦‚ä½•èå…¥æ›´å¤§çš„ç³»ç»Ÿæ¶æ„ã€‚è€ƒè™‘æ•°æ®æ¥æºã€å“åº”æ—¶é—´å’Œæ•´ä½“ç³»ç»Ÿè®¾è®¡ç­‰å› ç´ ã€‚ä¾‹:è®¾è®¡èŠå¤©æœºå™¨äººæç¤ºæ—¶,è€ƒè™‘ä¸ç”¨æˆ·å†å²è®°å½•å’Œå¤–éƒ¨APIçš„é›†æˆã€‚
    - This involves considering broader context and system constraints.
    - Example: System-aware prompt: "Generate a product description in 50 words or less, optimized for mobile display, focusing on key features and benefits."
  - å…¨é¢æ€è€ƒ:ä¸ä»…ä¾èµ–å†™ä½œæŠ€å·§,è¿˜éœ€è¦ç»“åˆæ¸…æ™°æ²Ÿé€šå’Œç³»ç»Ÿæ€§æ€ç»´ã€‚ä¼˜ç§€ä½œå®¶ä¸ä¸€å®šæ˜¯ä¼˜ç§€çš„æç¤ºå·¥ç¨‹å¸ˆ,åä¹‹äº¦ç„¶ã€‚ä¾‹:ä¸ä»…æ¸…æ™°æè¿°ä»»åŠ¡,è¿˜è¦ç³»ç»Ÿè€ƒè™‘å¯èƒ½çš„è¾“å…¥ã€è¾“å‡ºå’Œè¾¹ç•Œæ¡ä»¶ã€‚
    - This tip highlights the multifaceted nature of prompt engineering, combining linguistic and logical skills.
    - Example: Systematic prompt: "1. Analyze the given text for sentiment (positive, negative, or neutral). 2. Identify the main topic. 3. List three key points. 4. Suggest a follow-up question based on the content."
  - å®¢æˆ·æ•™è‚²:ä¸å®¢æˆ·åˆä½œæ—¶,å¸®åŠ©ä»–ä»¬ç†è§£çœŸå®ç”¨æˆ·è¾“å…¥çš„å¤æ‚æ€§ã€‚å¼•å¯¼ä»–ä»¬è€ƒè™‘å®é™…ä½¿ç”¨åœºæ™¯,è€Œéç†æƒ³æƒ…å†µã€‚ä¾‹:å±•ç¤ºç”¨æˆ·å¯èƒ½è¾“å…¥çš„å„ç§ä¸è§„èŒƒæŸ¥è¯¢,è€Œéå‡è®¾æ‰€æœ‰ç”¨æˆ·éƒ½ç”¨æ ‡å‡†æ ¼å¼æé—®ã€‚
    - This involves educating clients about real-world usage patterns and potential variations in user input.
    - Example: Customer education: "Let's consider how users might actually phrase their questions. Instead of 'What's the weather forecast?', they might type 'weather tmrw' or 'is it gonna rain'. How should our system handle these variations?"
  - å¤§é‡å®è·µ:å¤šè§‚å¯Ÿæ•°æ®å’Œæ¨¡å‹è¾“å‡ºã€‚ç†Ÿæ‚‰æ¨¡å‹å¯¹ä¸åŒç±»å‹æç¤ºå’Œè¾“å…¥çš„ååº”æ¨¡å¼ã€‚ä¾‹:å°è¯•åŒä¸€é—®é¢˜çš„ä¸åŒè¡¨è¿°,è§‚å¯Ÿæ¨¡å‹è¾“å‡ºçš„å˜åŒ–,æ‰¾å‡ºæœ€æœ‰æ•ˆçš„è¡¨è¾¾æ–¹å¼ã€‚
    - This tip encourages familiarizing yourself with how the model responds to different inputs through hands-on experience.
    - Example: Practice exercise: Analyze the outputs of the same prompt across different AI models or different versions of the same model, noting differences in style, content, and adherence to instructions.
- [Modular RAG](https://arxiv.org/pdf/2407.21059)
- [Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)
  - Contextual Embeddings and Contextual BM25
  - If your knowledge base is smaller than 200,000 tokens (about 500 pages of material), you can just include the entire knowledge base in the prompt that you give the mode
  - https://github.com/anthropics/anthropic-cookbook/tree/main/skills/contextual-embeddings
    ```
    <document> 
    {{WHOLE_DOCUMENT}}
    </document>
    Here is the chunk we want to situate within the whole document
    <chunk>
    {{CHUNK_CONTENT}}
    </chunk>
    Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else.
    ```
  - Contextual RAG çš„å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š
    - ä¸Šä¸‹æ–‡å¢å¼ºï¼šå¯¹äºæ–‡æ¡£ä¸­çš„æ¯ä¸ª chunkï¼Œç³»ç»Ÿä¼šåœ¨å…¶å‰é¢æ·»åŠ ä¸€æ®µè§£é‡Šæ€§çš„ä¸Šä¸‹æ–‡ç‰‡æ®µï¼Œå¸®åŠ© chunk æ›´å¥½åœ°èå…¥æ•´ä¸ªæ–‡æ¡£çš„è¯­å¢ƒã€‚è¿™ä¸€æ­¥éª¤ä½¿ç”¨ä¸€ä¸ªå°å‹ã€é«˜æ•ˆçš„ LLM æ¥å®Œæˆã€‚
    - æ··åˆæœç´¢ï¼šç³»ç»Ÿä¼šåŒæ—¶ä½¿ç”¨ç¨€ç–ï¼ˆå…³é”®è¯ï¼‰å’Œå¯†é›†ï¼ˆè¯­ä¹‰ï¼‰ä¸¤ç§æ–¹å¼å¯¹ chunk è¿›è¡ŒåµŒå…¥ã€‚è¿™å°±åƒæ˜¯è®© AI åŒæ—¶å…·å¤‡äº†å­—é¢ç†è§£å’Œæ·±å±‚å«ä¹‰ç†è§£çš„èƒ½åŠ›ã€‚
    - æ’åèåˆï¼šä½¿ç”¨é€’å½’æ’åèåˆï¼ˆReciprocal Rank Fusionï¼ŒRRFï¼‰ç®—æ³•æ¥åˆå¹¶æœç´¢ç»“æœã€‚è¿™ä¸ªè¿‡ç¨‹å°±åƒæ˜¯åœ¨å¤šä¸ªä¸“å®¶æ„è§ä¸­å¯»æ‰¾æœ€ä½³ç­”æ¡ˆã€‚
    - é‡æ’åºï¼šç³»ç»Ÿä¼šæ£€ç´¢å‰ 150 ä¸ªchunksï¼Œç„¶åé€šè¿‡ä¸€ä¸ªä¸“é—¨çš„é‡æ’åºæ¨¡å‹ç­›é€‰å‡º top 20 ã€‚è¿™ä¸€æ­¥ç¡®ä¿äº†æœ€ç›¸å…³çš„ä¿¡æ¯è¢«æ¨åˆ°æœ€å‰é¢ã€‚
  - Open Contextual RAG
    - Contextual RAG æ˜¯ä¸€ç§å…ˆè¿›çš„ chunk å¢å¼ºæŠ€æœ¯ï¼Œå®ƒå·§å¦™åœ°åˆ©ç”¨LLMï¼Œæ¯”å¦‚claudeï¼Œä¸ºæ¯ä¸ªæ–‡æ¡£ç‰‡æ®µèµ‹äºˆæ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡
    - å¦‚æœæˆ‘ä»¬çš„å¤§è„‘åœ¨å›å¿†æŸä»¶äº‹æ—¶ï¼Œä¸ä»…èƒ½æƒ³èµ·äº‹ä»¶æœ¬èº«ï¼Œè¿˜èƒ½è‡ªåŠ¨è”æƒ³åˆ°ç›¸å…³çš„å‰å› åæœ
    - https://github.com/togethercomputer/together-cookbook/blob/main/Open_Contextual_RAG.ipynb
- [Multimodal RAG with Milvus](https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/multimodal_rag_with_milvus.ipynb)
  - [Video](https://www.youtube.com/watch?v=AImwkZYbUvE)
  - https://zilliz.com/blog/deploy-multimodal-rag-using-vllm-and-milvus
- [RAG å­˜åœ¨å“ªäº›éœ€è¦è§£å†³çš„éš¾é¢˜](https://mp.weixin.qq.com/s/Za26pIabmREPn6u2bEkBUw)
  - çŸ¥è¯†åˆ†å—çŸ›ç›¾
    - é—®é¢˜Overviewï¼š
      - è¦æƒ³æ£€ç´¢å™¨æ£€ç´¢çš„ç²¾å‡†ï¼Œéœ€è¦å°åˆ†å—ï¼›
      - è¦æƒ³å¤§æ¨¡å‹ç”Ÿæˆæ—¶å€™å‚è€ƒå¾—å¤šï¼Œéœ€è¦å¤§åˆ†å—ï¼›
      - åŒæ—¶ï¼Œå³ä½¿æœ‰overlapï¼Œä½†æ–‡æ¡£è¯­ä¹‰å¾ˆå¯èƒ½æ°æ°åœ¨åˆ†å—å¤„éš”æ–­
    - çŸ¥è¯†åˆ†å—ä¼˜åŒ–
      - å®ç°äº†â€œå…ˆç»“æ„åŒ–åˆ†å‰²-å¯¹å¤§chunkå†é•¿åº¦åˆ†å‰²-å¯¹å°chunkè¿›è¡Œç»“æ„åŒ–åˆå¹¶â€çš„ä¸‰æ­¥åˆ†å‰²é€»è¾‘
      - å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š
        - step1: é€’å½’åˆ†å‰²æ–‡æ¡£ï¼Œå¾—åˆ°æœ€å°æ ‡é¢˜å•å…ƒçš„Chunkï¼ˆä¿ç•™äº†å„çº§æ ‡é¢˜ä¿¡æ¯ï¼‰ã€‚
        - step2: å¯¹æœ€å°æ ‡é¢˜å•å…ƒçš„chunkè¿›è¡Œåˆ¤æ–­ï¼Œè‹¥chunké•¿åº¦è¾ƒé•¿ï¼ŒæŒ‰é•¿åº¦è¿›è¡ŒäºŒæ¬¡åˆ†å‰²ï¼Œè·å–åŒ…å«æ ‡é¢˜ä¿¡æ¯çš„æœ€å°å•å…ƒSegmentsã€‚
        - step3: å¯¹Segmentsè¿›è¡Œåˆ¤æ–­ï¼Œä»æœ€ä½çº§æ ‡é¢˜åˆ°é«˜çº§æ ‡é¢˜å¼€å§‹ä¾æ¬¡åˆ¤æ–­å¹¶åœ¨é•¿åº¦èŒƒå›´å†…åˆå¹¶è·å–åŒ…å«äº†segmentå‘¨å›´å°½å¯èƒ½å¤šè¯­ä¹‰ä¿¡æ¯çš„Blocks
      - æ£€ç´¢-ç”Ÿæˆçš„å—ç²’åº¦è§£è€¦
        - Sentenceï¼šå¯¹chunkè¿›è¡Œå¥å­åˆ†å‰²å¾—åˆ°ï¼Œä¼šå†æ‹¼æ¥æ ‡é¢˜ç­‰ç»“æ„åŒ–ä¿¡æ¯ï¼›ç»†ç²’åº¦çš„çŸ¥è¯†é€‚ç”¨äºæ£€ç´¢é˜¶æ®µã€‚
        - Segmentï¼šå…¶åŒ…å«äº†ç»“æ„åŒ–æ®µè½ä¿¡æ¯ï¼›å®Œæ•´çš„è¯­ä¹‰çŸ¥è¯†é€‚ç”¨äºé‡æ’é˜¶æ®µã€‚
        - Blockï¼šå…¶åŒ…å«äº†Segmentå‘¨å›´å°½å¯èƒ½å¤šçš„è¯­ä¹‰ä¿¡æ¯ï¼›æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯é€‚ç”¨äºå¤§æ¨¡å‹ç”Ÿæˆé˜¶æ®µã€‚
  - çŸ¥è¯†æœ¬èº«ç¼ºå¤±
    - é—®é¢˜
      - ç­”æ¡ˆå¯èƒ½å­˜åœ¨åœ¨æ–‡æ¡£ä¸­ï¼Œä½†ä¸å­˜åœ¨ç¡®åˆ‡çš„æŸä¸€åˆ†å—ä¸­ã€‚ä»queryåˆ°documentæœ¬èº«çš„è¯­ä¹‰é¸¿æ²Ÿæ¥è¯´ï¼Œç”¨æˆ·çš„é—®é¢˜å¯å¤§å¯å°ï¼Œå’Œæ²‰æ·€çš„æ–‡æ¡£çš„è¯­ä¹‰ç»´åº¦ä¸å¯èƒ½å§‹ç»ˆä¸€è‡´
      - ä¸€äº›å…ˆéªŒçš„é¢†åŸŸå‹çŸ¥è¯†å¹¶ä¸åœ¨ç¡®åˆ‡çš„åˆ†å—é‡Œï¼Œä½†å¤§æ¨¡å‹æ²¡æœ‰è¯¥ç±»é¢†åŸŸæ€§å¸¸è¯†æ—¶åœ¨å›ç­”å…·ä½“é—®é¢˜æ—¶è¾ƒä¸ºå›°éš¾
    - çŸ¥è¯†ç²’åº¦æ‰©å……-é€šç”¨æ€§çŸ¥è¯†å¢å¼º
      - å°†queryæ‰©å……åˆ°documentç²’åº¦ - å‚è€ƒHyDE å½“queryè¿›æ¥åï¼Œé¢„å…ˆå»ç”Ÿæˆå¯èƒ½çš„ç­”æ¡ˆï¼Œå†ç”±å¯èƒ½çš„ç­”æ¡ˆå»æ£€ç´¢ç›¸å…³documentã€‚
      - å°†documentç²¾ç‚¼åˆ°queryç²’åº¦ - å€ŸåŠ©å¤§æ¨¡å‹åšæ–‡æ¡£é¢„å…ˆæå–ï¼Œæ–‡æ¡£æ‘˜è¦ï¼Œåšè·¨æ–‡æ¡£çš„é¢„å…ˆå…³è”
      - è§£å†³è·¨æ–‡æ¡£çš„queryé—®é¢˜æœ¬è´¨ä¸Šè¿˜æ˜¯è§£å†³æ–‡æ¡£é—´çš„å…³è”é—®é¢˜ï¼Œæåˆ°å…³è”å¾ˆè‡ªç„¶çš„ä¹Ÿå°±æ¥åˆ°äº†Graphè¿™é¡¹æŠ€æœ¯
    - å…ˆéªŒçŸ¥è¯†æ‰©å……-é¢†åŸŸå‹çŸ¥è¯†æŠ½å–
      - å°†é¢†åŸŸå‹çŸ¥è¯†å†…åŒ–è¿›å¤§æ¨¡å‹ - finetune
      - å°†é¢†åŸŸå‹çŸ¥è¯†æ˜¾å¼ç»™å¤§æ¨¡å‹ - å¯¹queryè¿›è¡ŒçŸ¥è¯†æ£€ç´¢çš„åŒæ—¶ä¹Ÿå»æ£€ç´¢ä¸€éç›¸å…³é¢†åŸŸä¸“æœ‰çŸ¥è¯†ï¼Œç±»ä¼¼äºMemoRAG
        - æ„å»ºé¢†åŸŸå›¾è°±çš„å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š
          - step1: æ¨¡å‹ä¼šå…ˆå¤šæ¬¡è¯»å–æ–‡æ¡£åˆ†å—ï¼Œä»ä¸­æå–å‡ºé¢†åŸŸå®ä½“ï¼ˆå¯ç»“åˆä¸åŒåœºæ™¯è§„å®šå®ä½“ç±»å‹ï¼‰ã€‚
          - step2: åœ¨éå†å®Œæ‰€æœ‰æ–‡æ¡£åˆ†å—åï¼Œæ¨¡å‹ä¼šå†å¤šæ¬¡éå†æå–å‡ºçš„é¢†åŸŸå®ä½“ï¼Œå°†å…¶ä¸­çš„ç›¸ä¼¼ç›¸å…³å®ä½“è¿›è¡Œåˆå¹¶å†æ€»ç»“ã€‚
          - step3: å¯¹åˆå¹¶åçš„å®ä½“ï¼Œæ¨¡å‹å†æ ¹æ®æ–‡æœ¬å—å»æå–å®ä½“ä¹‹é—´çš„å…³è”ã€‚
          - step4: å¯¹æŠ½å–çš„å®ä½“å’Œå…³è”åšç¤¾åŒºå‘ç°ï¼Œå¹¶å¯¹æ‰€èšé›†çš„ç¤¾åŒºåšæŠ¥å‘Šæ‘˜è¦
    - çŸ¥è¯†ç›¸äº’å†²çª
      - å‡è®¾çŸ¥è¯†å…¨éƒ½callå‡ºæ¥ï¼Œä½†callå‡ºæ¥çš„çŸ¥è¯†æœ¬èº«ä¸æ¸…æ™°æˆ–è€…æ˜¯ä¸åŒçš„æ–‡æ¡£ä¸­å¯¹ç›¸ä¼¼é—®é¢˜çš„è¯ é‡Šä¸åŒï¼Œæ¨¡æ£±ä¸¤å¯çš„çŸ¥è¯†å®¹æ˜“è®©å¤§æ¨¡å‹æƒ³ä¸é€šä»¥è‡³äºå¹»è§‰
      - çŸ¥è¯†æ¥æºæ‰©å……-ç»éªŒæ€§çŸ¥è¯†æ²‰æ·€
        - å†å²ä¼šè¯æ€»ç»“ä¸æ‘˜è¦ 
        - å†å²ä¼šè¯é—®ç­”å¯¹æŒ–æ˜
          - ä¸€ç§åˆ†æ­¥æç¤ºï¼ˆMulti-Step Promptingï¼‰ç­–ç•¥ï¼Œè¯¥ç”Ÿæˆç­–ç•¥ç”¨äºè®­ç»ƒæ•°æ®å‡†å¤‡ã€è®­ç»ƒä»»åŠ¡æ„é€ åŠå¤§æ¨¡å‹æ¨ç†ä¸‰ä¸ªéƒ¨åˆ†
          - å…¨å±€é—®ç­”å¯¹æŠ½å–ï¼šç”±äºå¾€å¾€ä¸€ä¸ªå†å²ä¼šè¯å·¥å•ä¸­ç”¨æˆ·æœ‰æœ€åˆè¿›å…¥æé—®çš„ä¸»è¦é—®é¢˜ï¼Œè€Œè¯¥ç±»ä¸»è¦é—®é¢˜çš„è§£å†³æ–¹æ¡ˆå¾€å¾€æ¨ªè·¨äº†æ•´ä¸ªå¯¹è¯
          - å±€éƒ¨é—®ç­”å¯¹æŠ½å–ï¼šè€ƒè™‘åˆ°å†…éƒ¨ç ”å‘é—®é¢˜çš„å¤æ‚åº¦å¾€å¾€è¾ƒé«˜ï¼Œåœ¨å¤šè½®å¯¹è¯ä¸­å¾€å¾€å­˜åœ¨å¤šä¸ªè¡ç”Ÿå­é—®é¢˜ï¼Œè¯¥ç±»é—®é¢˜å¯¹äºçŸ¥è¯†åº“å»ºè®¾ä¹Ÿèµ·ç€è¾ƒä¸ºå…³é”®çš„ä½œç”¨
  - çŸ¥è¯†ç›¸äº’å†²çª
    - å‡è®¾çŸ¥è¯†å…¨éƒ½callå‡ºæ¥ï¼Œä½†callå‡ºæ¥çš„çŸ¥è¯†æœ¬èº«ä¸æ¸…æ™°æˆ–è€…æ˜¯ä¸åŒçš„æ–‡æ¡£ä¸­å¯¹ç›¸ä¼¼é—®é¢˜çš„è¯ é‡Šä¸åŒï¼Œæ¨¡æ£±ä¸¤å¯çš„çŸ¥è¯†å®¹æ˜“è®©å¤§æ¨¡å‹æƒ³ä¸é€šä»¥è‡³äºå¹»è§‰
    - ä»çŸ¥è¯†æ ‡ç­¾åˆ°æ–‡æ¡£ä¼˜å…ˆçº§
      - æ–‡æ¡£ä¼˜å…ˆçº§è¿ç”¨æ€è·¯ ç»“åˆCoTçš„Ref Selection
- [RAG summary](https://mp.weixin.qq.com/s/Ps4nZShTuuGFQo6TH_5LZQ)
  - RAG é¢ä¸´çš„é—®é¢˜ï¼Œä¸»è¦å°±ä¸‰ç±»ï¼š
    - é’ˆå¯¹éç»“æ„åŒ–å¤šæ¨¡æ€æ–‡æ¡£æ— æ³•æä¾›æœ‰æ•ˆé—®ç­”ã€‚
      - åŸºäº VLM å’Œå»¶è¿Ÿäº¤äº’æ¨¡å‹å®ç°å¤šæ¨¡æ€ RAG
    - é‡‡ç”¨çº¯å‘é‡æ•°æ®åº“å¸¦æ¥çš„ä½å¬å›å’Œå‘½ä¸­ç‡ï¼Œä»è€Œæ— æ³•é’ˆå¯¹å®é™…åœºæ™¯æä¾›æœ‰æ•ˆé—®ç­”ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºå‘é‡è¡¨å¾ä¸ä»…ç¼ºä¹å¯¹ç²¾ç¡®ä¿¡æ¯çš„è¡¨è¾¾ï¼Œå¯¹è¯­ä¹‰å¬å›ä¹Ÿæœ‰æŸè€—
      - BM25 å’Œæ··åˆæœç´¢çš„å´›èµ·
    - RAG çš„æœ¬è´¨æ˜¯æœç´¢ï¼Œå®ƒèƒ½å·¥ä½œçš„å‰æåœ¨äºæ ¹æ®ç”¨æˆ·çš„æé—®ï¼Œå¯ä»¥â€œæœâ€åˆ°ç­”æ¡ˆæ‰€åœ¨ã€‚ä½†æ˜¯åœ¨å¾ˆå¤šæƒ…å†µä¸‹ï¼Œè¿™ä¸ªå‰æä¸å­˜åœ¨ï¼Œä¾‹å¦‚ä¸€äº›æ„å›¾ä¸æ˜çš„ç¬¼ç»Ÿæé—®ï¼Œä»¥åŠä¸€äº›éœ€è¦åœ¨å¤šä¸ªå­é—®é¢˜åŸºç¡€ä¹‹ä¸Šç»¼åˆæ‰èƒ½å¾—åˆ°ç­”æ¡ˆçš„æ‰€è°“â€œå¤šè·³â€é—®ç­”ï¼Œ
      - GraphRAG RAG çš„ä¸€äº›æ ¸å¿ƒé—®é¢˜â€”â€”è¿™å°±æ˜¯è¯­ä¹‰é¸¿æ²Ÿ
- [How to use the Usage API and Cost API to monitor your OpenAI usage](https://cookbook.openai.com/examples/completions_usage_api) 
- [QUERYING DATABASES WITH FUNCTION CALLING](https://arxiv.org/pdf/2502.00032)
- [Dify]
  - workflow
    - æ„å»º AI é©±åŠ¨çš„å¤šè½®è¯„å®¡æ¶¦è‰²æµç¨‹
    - https://www.ginonotes.com/dify/wenrun.yml
- LLM Consortium
  - The idea is to have a bunch of LLMs (the Consortium members) answering the same question, collect their responses and ask an arbiter to synthesize them into a final result
  - If the arbiter is not happy with the responses, it can iterate and ask the Consortium to try again
  - https://colab.research.google.com/drive/1OnIipRwuHOZbKHN0haHGD0OnckBGfzqx
- [RAG on PDFs using File Search in the Responses API](https://cookbook.openai.com/examples/file_search_responses)
- [mineru.net](https://mineru.net/) ä¸€ä¸ªå¼€æºçš„pdfè½¬mdæ–‡ä»¶
  - [How to Parse a PDF](https://unstructured.io/blog/how-to-parse-a-pdf-part-1)
- [10 Lessons on RAG Agents in Production](https://www.youtube.com/watch?v=kPL-6-9MVyA)
  - Better Systems > Better Models
  - Expertise is your fuel
- [AI Agent æ¡†æ¶è°ƒç ”](https://4c0rz0rc1r.app.yourware.so/)
- [QA]
  - - chunk æ˜¯æ€ä¹ˆåˆ‡çš„ï¼Ÿå›ºå®šï¼Ÿè¯­ä¹‰ï¼Ÿè¿˜æ˜¯è‡ªé€‚åº”ï¼Ÿ
  - embedding æ¨¡å‹é€‰å‹å’Œç»´åº¦æ€ä¹ˆæ¥çš„ï¼Ÿ
  - rerank ç”¨æ²¡ç”¨ï¼Ÿæ€ä¹ˆèåˆ BM25 å’Œ dense æ£€ç´¢ï¼Ÿ
  - prompt æ˜¯ä½ å†™çš„å—ï¼Ÿæœ‰æ²¡æœ‰è¯„ä¼° hit rateã€hallucinationï¼Ÿ
  - RAG çš„å‰åŠæ®µå‡ ä¹å°±æ˜¯æ¨èç³»ç»Ÿé‚£å¥—å¬å› + æ’åº + ç²¾æ’çš„é€»è¾‘ï¼š
    - embedding = å‘é‡åŒ–ç‰¹å¾å»ºæ¨¡
    - æ£€ç´¢ = å¤šè·¯å¬å›
    - rerank = æ‰“åˆ†æ’åº
- AIè¡Œä¸šæ™®éé¢ä¸´çš„ç—›ç‚¹åœ¨äºâ€œåŸå‹æ˜“ï¼Œç”Ÿäº§éš¾
  - å…·å¤‡ç»¼åˆèƒ½åŠ›çš„â€œæ™ºèƒ½ä½“å·¥ç¨‹å¸ˆâ€ï¼Œä»–ä»¬éœ€è¦æŒæ¡
    - ç²¾æ¹›çš„æç¤ºå·¥ç¨‹ (Prompting)ï¼šä¸LLMè¿›è¡Œé«˜æ•ˆã€ç²¾ç¡®æ²Ÿé€šçš„åŸºç¡€
    - åšå®çš„å·¥ç¨‹èƒ½åŠ› (Engineering)ï¼šæ¶µç›–å·¥å…·é›†æˆã€å¤æ‚æ•°æ®æµæ„å»ºï¼ˆä¸ºLLMæä¾›å…³é”®ä¸Šä¸‹æ–‡ï¼‰ã€ä»¥åŠç¨³å¥çš„éƒ¨ç½²ç­–ç•¥ã€‚
    - æ•é”çš„äº§å“æ€ç»´ (Product Sense)ï¼šæ·±åˆ»ç†è§£ä¸šåŠ¡æµç¨‹ï¼Œå¹¶èƒ½é€šè¿‡æ™ºèƒ½ä½“è¿›è¡Œæœ‰æ•ˆçš„å¤åˆ¶å’Œä¼˜åŒ–ã€‚
    - æ ¸å¿ƒçš„æœºå™¨å­¦ä¹ çŸ¥è¯† (Machine Learning)ï¼šç‰¹åˆ«æ˜¯åœ¨æ™ºèƒ½ä½“è¯„ä¼°ï¼ˆEvalsï¼‰ä»¥é‡åŒ–æ€§èƒ½ã€æ•æ‰éç¡®å®šæ€§ï¼Œä»¥åŠæ¨¡å‹å¾®è°ƒç­‰æ–¹é¢ã€‚
  - å½“å‰æ™ºèƒ½ä½“å‘å±•çš„ä¸‰å¤§æ ¸å¿ƒæ´å¯Ÿ
    - æ¨¡å‹å¯é€‰æ€§è‡³å…³é‡è¦ï¼šæ™ºèƒ½ä½“å¹¶éå•ä¸€æ¨¡å‹çš„äº§ç‰©ã€‚é¢å¯¹åŠŸèƒ½ã€æˆæœ¬ã€é€Ÿåº¦å„å¼‚çš„ä¼—å¤šæ¨¡å‹ï¼Œå¼€å‘è€…äºŸéœ€çµæ´»é€‰æ‹©ã€‚
    - ä¸Šä¸‹æ–‡å·¥ç¨‹å†³å®šå¯é æ€§ï¼šä¼ é€’ç»™LLMçš„æç¤ºï¼ˆä¸Šä¸‹æ–‡ï¼‰çš„è´¨é‡å’Œç»“æ„ï¼Œç›´æ¥å†³å®šäº†æ™ºèƒ½ä½“çš„è¡Œä¸ºå’Œè¾“å‡ºçš„å¯é æ€§ã€‚
    - AIå¯è§‚æµ‹æ€§ï¼šè¶…è¶Šä¼ ç»Ÿï¼Œä¸“ä¸ºæ™ºèƒ½ä½“è€Œç”Ÿ
- AI Agent versus MCP
  - Key characteristics of AI agents are as follows:
    - An agent can perform autonomous actions without constant human intervention. Also, they can have a human in the loop to maintain control.
    - Agents have a memory to store individual preferences and allow for personalization. It can also store knowledge. An LLM can undertake information processing and decision-making functions.
    - Agents must be able to perceive and process the information available from their environment.
  - MCP follows a client-server model with 3 key components:
    - Host: AI applications like Claude
    - MCP Client: Component inside an AI model (like Claude) that allows it to communicate with MCP servers
    - MCP Server: Middleman that connects an AI model to an external system
- [Selecting a Model Based on Stripe Conversion](https://cookbook.openai.com/examples/stripe_model_eval/selecting_a_model_based_on_stripe_conversion)
  - A/B æµ‹è¯•æ¨¡å‹å¯¹ä»˜è´¹è½¬åŒ–çš„å®é™…å½±å“
  - ä½¿ç”¨ä»˜è´¹è½¬åŒ–ï¼ˆä»¥ Stripe è®¢é˜…/æ”¯ä»˜ä¸ºä¾‹ï¼‰ä½œä¸ºæ ¸å¿ƒæ ‡å‡†ï¼Œé€‰æ‹©æœ€é€‚åˆè‡ªèº«ä¸šåŠ¡çš„ AI å¤§æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹æ³•
- RAG, Self-RAG, Agentic RAG, Corrective RAG, Adaptive RAG
  - Standard RAG
    - The foundation - retrieves documents based on similarity and generates responses. Simple, fast, but limited feedback loop.
  - Self-RAG
    - Adds self-reflection capabilities. The model evaluates its own outputs and decides whether to retrieve additional information or regenerate responses.
  - Agentic RAG
    - Goes full autonomous - breaks complex queries into sub-tasks, plans retrieval strategies, and executes multi-step reasoning workflows.
  - Corrective RAG (CRAG)
    - Focuses on accuracy through iterative correction. Continuously fact-checks and refines responses against retrieved knowledge.
  - Adaptive RAG
    - The smart switcher - dynamically chooses the best retrieval strategy based on query complexity, domain, and confidence levels.
  - When should you use each?
    ğŸ¯ Starting out or need speed â†’ Standard RAG
    ğŸ¯ Quality and grounding matter â†’ Self-RAG
    ğŸ¯ Complex reasoning required â†’ Agentic RAG
    ğŸ¯ Mission-critical accuracy â†’ CRAG
    ğŸ¯ Diverse query types â†’ Adaptive RAG
  - Our recommendation: Start with Standard RAG, add Self-RAG for quality, then evolve based on your specific needs.
- [RAG Cost Calculator](https://zilliz.com/rag-cost-calculator/)
  - This calculator quickly estimates the cost of building a RAG pipeline, including chunking, embedding, vector storage/search, and LLM generation.
- [Context Engineering for Agents](https://rlancemartin.github.io/2025/06/23/context_engineering/)
  - [Awesome Context Engineering](https://github.com/Meirtz/Awesome-Context-Engineering)
  - ä¸Šä¸‹æ–‡å†…å®¹å¯èƒ½éšä»£ç†çš„å¤šè½®äº¤äº’è€Œä¸æ–­è†¨èƒ€ï¼Œæ—¢ä¼šå¢åŠ ä»£ä»·ï¼ˆtokenæ•°é‡å’Œæ—¶é—´ï¼‰ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´æ¨¡å‹çš„â€œContext Degradation Syndromeâ€â€”â€”ä¸Šä¸‹æ–‡è¶Šé•¿ï¼Œæ¨¡å‹å¯¹å…³é”®ä¿¡æ¯çš„æŠŠæ¡èƒ½åŠ›å¯èƒ½ä¸‹é™
  - ä¸»è¦ç­–ç•¥ï¼šCurate, Persist, Isolate
    - Curateï¼ˆç²¾ç®€/ç®¡æ§ä¸Šä¸‹æ–‡ï¼‰
      - åœ¨æ¯æ¬¡å¯¹è¯æˆ–å·¥å…·è°ƒç”¨åè¿›è¡Œæ‘˜è¦ï¼Œä»¥ä¾¿å‡å°‘ä¸å¿…è¦çš„tokenå ç”¨ã€‚
      - å¸¸è§åšæ³•åŒ…æ‹¬å¯¹å…¨å±€å¯¹è¯æˆ–ç‰¹å®šå·¥å…·è°ƒç”¨è¿›è¡Œæ€»ç»“ï¼Œå¿…è¦æ—¶å¯åˆ†å±‚æ¬¡æˆ–â€œé€’å½’â€åœ°æ€»ç»“ã€‚
    - Persistï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰
      - å°†ä¿¡æ¯å­˜å‚¨äºæ–‡ä»¶ã€å‘é‡æ•°æ®åº“æˆ–å›¾æ•°æ®åº“ä¸­ï¼Œä¾¿äºç”¨æˆ·/ç³»ç»Ÿåç»­æ£€ç´¢ã€‚
      - å¯åœ¨é€‚å½“æ—¶æœºï¼ˆä¾‹å¦‚ç”¨æˆ·æŠŠå…³æˆ–å¯¹è¯ç»“æŸï¼‰å°†é‡è¦ä¿¡æ¯å†™å…¥è®°å¿†åº“ï¼Œä»¥å®ç°åŠ¨æ€æ›´æ–°ã€‚
      - æ£€ç´¢æœºåˆ¶åˆ™å†³å®šäº†å¦‚ä½•æŒ‘é€‰ç›¸å…³è®°å¿†æ”¾å›ä¸Šä¸‹æ–‡ã€‚
    - Isolateï¼ˆéš”ç¦»ä¸Šä¸‹æ–‡ï¼‰
      - é€šè¿‡åœ¨ç¨‹åºå†…éƒ¨å®šä¹‰ç»“æ„åŒ–â€œçŠ¶æ€æ¶æ„â€(schema)ï¼Œç²¾ç¡®æ§åˆ¶å“ªäº›å†…å®¹éœ€è¦åœ¨ä¸‹ä¸€â€œå›åˆâ€ä¼ ç»™LLMï¼Œé¿å…æ— å…³æˆ–å¤§æ®µä¿¡æ¯ä¸€è‚¡è„‘æŒ¤è¿›ä¸Šä¸‹æ–‡ã€‚
      - å¤šä»£ç†ï¼ˆMulti-agentï¼‰æ–¹æ³•æ˜¯ä¸€ç§æ›´æ¿€è¿›çš„éš”ç¦»ç­–ç•¥ï¼šå°†ä»»åŠ¡æ‹†åˆ†ç»™ä¸åŒå­ä»£ç†ï¼Œå„è‡ªç»´æŠ¤ç‹¬ç«‹ä¸Šä¸‹æ–‡ï¼›ä½†éœ€è¦æ³¨æ„å¹¶è¡Œä¸åè°ƒæˆæœ¬ã€‚
  - å®è·µç»éªŒä¸å»ºè®®ï¼š
     - â€¢ ä¼˜å…ˆå¯¹ä»£ç†çš„è¡Œä¸ºè¿›è¡Œç›‘æ§å’Œæ•°æ®ç»Ÿè®¡ï¼ŒåŠæ—¶å‘ç°tokenç”¨é‡å¼‚å¸¸æˆ–ä¸Šä¸‹æ–‡è†¨èƒ€é—®é¢˜ã€‚
     - â€¢ åœ¨è®¾è®¡ä»£ç†æ—¶ï¼ŒèŠ±æ—¶é—´æ¸…æ™°åœ°å®šä¹‰â€œä»£ç†çŠ¶æ€â€â€”â€”å“ªäº›ä¿¡æ¯éœ€è¦éšæ—¶ç»™æ¨¡å‹ï¼Œå“ªäº›å¯æŒä¹…åŒ–ä»¥å¤‡åç”¨ã€‚
     - â€¢ å·¥å…·è°ƒç”¨è¾¹ç•Œå¤„å¾€å¾€æ˜¯æœ€ä½³â€œç²¾ç®€ä¸Šä¸‹æ–‡â€çš„æ—¶æœºï¼Œå¯å°†å†—é•¿ç»“æœå…ˆè¡Œæ±‡æ€»åå†æ³¨å…¥ä¸»ä¸Šä¸‹æ–‡ã€‚
     - â€¢ â€œè®°å¿†â€å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šä¸ªæ€§åŒ–ä»£ç†ï¼Œä½†å¤„ç†ä¸å½“æ˜“å¼•å‘æ£€ç´¢ä¸å‡†æˆ–ä¸Šä¸‹æ–‡å†²çªï¼Œå»ºè®®ä»æ–½è¡Œç®€å•çš„æ–‡ä»¶æ–¹å¼å¼€å§‹ï¼Œå¾ªåºæ¸è¿›ã€‚
     - â€¢ å¤šä»£ç†é€‚åˆå¯å¹¶è¡ŒåŒ–ã€ä¸”å¯¹æœ€ç»ˆç»“æœè¿è´¯æ€§è¦æ±‚ä¸é«˜çš„ä»»åŠ¡ï¼›è‹¥å¯¹å•ä¸€æ–‡æ¡£çš„å†™ä½œå’Œæ•´ä½“åè°ƒåº¦è¦æ±‚è¾ƒé«˜ï¼Œéœ€è°¨æ…è€ƒè™‘æ‹†åˆ†ç­–ç•¥ã€‚
  - On top of context engineering itself, an LLM app has to:
    - break up problems just right into control flows
    - pack the context windows just right
    - dispatch calls to LLMs of the right kind and capability
    - handle generation-verification UIUX flows
    - a lot more - guardrails, security, evals, parallelism, prefetching, ...
  - What is the Context
    - Instructions / System Prompt: An initial set of instructions that define the behavior of the model during a conversation, can/should include examples, rules â€¦.
    - User Prompt: Immediate task or question from the user.
    - State / History (short-term Memory): The current conversation, including user and model responses that have led to this moment.
    - Long-Term Memory: Persistent knowledge base, gathered across many prior conversations, containing learned user preferences, summaries of past projects, or facts it has been told to remember for future use.
    - Retrieved Information (RAG): External, up-to-date knowledge, relevant information from documents, databases, or APIs to answer specific questions.
    - Available Tools: Definitions of all the functions or built-in tools it can call (e.g., check_inventory, send_email).
    - Structured Output: Definitions on the format of the model's response, e.g. a JSON object.
  - [Context Engineering](https://blog.langchain.com/context-engineering-for-agents/)
    - Writing context means saving it outside the context window to help an agent perform a task.
    - Selecting context means pulling it into the context window to help an agent perform a task.
    - Compressing context involves retaining only the tokens required to perform a task.
    - Isolating context involves splitting it up to help an agent perform a task.
  - [How to Fix Your Context](https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html)
    - é•¿ä¸Šä¸‹æ–‡ï¼ˆlong contextï¼‰å¯èƒ½å¯¼è‡´çš„å¸¸è§é—®é¢˜ï¼Œå¹¶æå‡ºäº†å…­å¤§ç­–ç•¥æ¥é¿å…æˆ–å‡è½»è¿™äº›é—®é¢˜ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šä¸Šä¸‹æ–‡å¹¶éè¶Šé•¿è¶Šå¥½ï¼Œå› å…¶ä¿¡æ¯ä¼šç›´æ¥å½±å“æ¨¡å‹çš„è¾“å‡ºè´¨é‡ã€‚
    - å¸¸è§é—®é¢˜
      - Context Poisoningï¼šä¸Šä¸‹æ–‡é‡Œæ··å…¥äº†é”™è¯¯æˆ–å¹»è§‰ä¿¡æ¯ï¼Œæ¨¡å‹åå¤å¼•ç”¨è¿™äº›é”™è¯¯å†…å®¹ã€‚Gemini playing Pokemon hallucinated an item + tried to re-use it
      - Context Distractionï¼šä¸Šä¸‹æ–‡å¤ªé•¿æ—¶ï¼Œæ¨¡å‹è¿‡åº¦ä¾èµ–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¿½ç•¥äº†åŸå…ˆçš„è®­ç»ƒçŸ¥è¯†ã€‚Gemini favored repeated actions over new plans as context > 100k tok
      - Context Confusionï¼šä¸Šä¸‹æ–‡ä¸­å«æœ‰è¿‡å¤šæ— å…³ä¿¡æ¯ï¼Œå¯¼è‡´å›å¤è´¨é‡ä¸‹é™ã€‚Models perform worse with more tools, esp if tools are similar
      - Context Clashï¼šä¸Šä¸‹æ–‡é‡Œæ–°å¢çš„ä¿¡æ¯ä¸å·²æœ‰å†…å®¹å†²çªï¼Œå¼•å‘çŸ›ç›¾ç­”æ¡ˆã€‚Models perform worse if back-to-back tool calls contradict each other
    - [è§£å†³ç­–ç•¥](https://docs.google.com/presentation/d/16aaXLu40GugY-kOpqDU4e-S0hD1FmHcNyF0rRRnb1OU/edit?slide=id.p#slide=id.p)
      - RAGï¼ˆRetrieval-Augmented Generationï¼‰ï¼šåªæ ¹æ®éœ€æ±‚æ£€ç´¢å¹¶æ·»åŠ ä¸å½“å‰ä»»åŠ¡ç›¸å…³çš„æ–‡æ¡£ï¼Œä»è€Œé¿å…æŠŠæ‰€æœ‰å†…å®¹ä¸€è‚¡è„‘åŠ å…¥ä¸Šä¸‹æ–‡å¯¼è‡´æ··ä¹±ã€‚
        - Mix of retrieval methods + re-ranking (see: Varunâ€™s take from Windsurf).
        - Systems to assemble retrievals into prompts (see: Preempt in Cursor).
        - Retrieve relevant tools based upon tool descriptions (see: Drewâ€™s post).
        - RAG è¦æœ‰é€‰æ‹©æ€§çš„æ·»åŠ ï¼Œè€Œä¸æ˜¯å…¨éƒ¨è´´ä¸Šï¼›é‡ç‚¹æ˜¯å›´ç»•å½“å‰ä»»åŠ¡æ„å»ºè¯­ä¹‰å¢å¼º
        - Manus çš„åšæ³•æ˜¯å¹²è„†æ”¾å¼ƒæŸ¥å…¥ï¼ŒæŠŠä¿¡æ¯æŒ‚è½½åœ¨æ–‡ä»¶ç³»ç»Ÿï¼Œç•™ path + æ‘˜è¦ + å¯è°ƒç”¨å·¥å…·
      - Tool Loadoutï¼šåœ¨ä¸Šä¸‹æ–‡é‡Œåªé€‰ç”¨å½“å‰æ‰€éœ€çš„å·¥å…·æˆ–å‡½æ•°å®šä¹‰ï¼Œé¿å…å·¥å…·å®šä¹‰è¿‡å¤šç›¸äº’å¹²æ‰°ã€‚å¼•ç”¨çš„ç ”ç©¶å‘ç°ï¼Œè¶…è¿‡ä¸€å®šæ•°é‡çš„å·¥å…·æè¿°åï¼Œæ¨¡å‹å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ã€‚
        - Manus çš„å“²å­¦æ˜¯å·¥å…·å…¨é›†ä¿æŒä¸å˜ï¼Œç”¨ mask æ§åˆ¶ç›´æ¥æŠŠæƒé‡å¹²æˆè´Ÿæ•°
        - åªè¦ä½ å¸Œæœ›ä¸Šä¸‹æ–‡å‘½ä¸­ç‡é«˜ã€æ¨¡å‹è¡Œä¸ºç¨³å®šï¼Œå°±å¿…é¡»æ„å»ºä¸€ä¸ªâ€œè¡Œä¸ºå¯å˜ä½†ç»“æ„ä¸å˜â€çš„ç³»ç»Ÿã€‚
      - Context Quarantineï¼šç”¨å¤šä»£ç†ã€å¤šçº¿ç¨‹çš„æ–¹å¼ï¼Œå°†ä¸åŒä¸Šä¸‹æ–‡åˆ†å‰²åœ¨ç‹¬ç«‹çš„ä»»åŠ¡æˆ–çº¿ç¨‹é‡Œï¼Œå„è‡ªç‹¬ç«‹å¤„ç†ï¼Œå‡å°‘ä¸Šä¸‹æ–‡è¿‡è½½ã€‚Anthropic çš„å¤šä»£ç†ç ”ç©¶ç³»ç»Ÿå°±æ˜¯å…¸å‹æ¡ˆä¾‹ã€‚
      - Context Pruningï¼šå®šæœŸæˆ–åœ¨åˆé€‚çš„æ—¶æœºå¯¹å·²æœ‰çš„ä¸Šä¸‹æ–‡è¿›è¡Œâ€œä¿®å‰ªâ€ï¼Œåˆ é™¤ä¸å†éœ€è¦æˆ–ä¸ç›¸å…³çš„ä¿¡æ¯ã€‚å¯ä»¥ç”¨ä¸“é—¨çš„å·¥å…·ï¼ˆå¦‚ Provenceï¼‰è‡ªåŠ¨ç­›é™¤ä¸é—®é¢˜æ— å…³çš„æ–‡æœ¬ã€‚
        - çœŸæ­£çš„ pruningï¼Œæ˜¯åˆ é™¤â€œç»“æ„ä¸Šå·²ç»å¤±æ•ˆçš„ä¿¡æ¯â€ã€‚
        - ä»–ä»¬çš„â€œèƒ½ offload çš„å°± offloadï¼Œä¸èƒ½ offload çš„å°±æ‘˜è¦â€ ä¸€æ®µå¸¦æ‘˜è¦çš„ contextï¼Œè¿œæ¯”ä¸€å †ç‰‡æ®µæ›´æœ‰æ¨ç†ä»·å€¼
      - Context Summarizationï¼šå°†ä¸Šä¸‹æ–‡æç‚¼æˆç®€çŸ­æ‘˜è¦ï¼Œä»¥é˜²ä¸Šä¸‹æ–‡è¿‡é•¿é€ æˆå¹²æ‰°ã€‚å°¤å…¶åœ¨ä¸Šä¸‹æ–‡è¶…è¿‡ä¸€å®šå¤§å°åï¼Œæ¨¡å‹å¯èƒ½å€¾å‘é‡å¤æ˜”æ—¥ç­”æ¡ˆè€Œéäº§ç”Ÿæ–°çš„è§è§£ã€‚
        - Summarize agent message history (see: Drewâ€™s post, Claude Code).
        - Prune irrelevant parts of message history (see: Drewâ€™s post).
        - Summarize / prune tool call outputs (see: open-deep-research).
        - Summarize / prune at agent-agent handoffs (see: Cognition).
        - But, care careful of information loss (see: Cognition and Manus)
      - Context Offloadingï¼šä¸æŠŠæ‰€æœ‰è¿‡ç¨‹æˆ–ä¿¡æ¯éƒ½æ”¾åœ¨ä¸»ä¸Šä¸‹æ–‡é‡Œï¼Œè€Œæ˜¯å°†å…¶ç§»åˆ°å¤–éƒ¨å­˜å‚¨æˆ–å·¥å…·ï¼ˆå¦‚â€œscratchpadâ€ï¼‰é‡Œï¼Œåªæœ‰éœ€è¦æ—¶å†å¼•ç”¨ï¼Œèƒ½æ˜¾è‘—æå‡æ•ˆç‡å’Œå‡†ç¡®åº¦ã€‚
        - Use file system for notes (see: Drewâ€™s post, Anthropic multi-agent).
        - Use file system (e.g., todo.md) to plan/track progress (see: Manus).
        - Use file system read/write tok-heavy context (see: Manus).
        - Use files for long-term memories (see: Ambient Agents course/repo)
        - Manus çš„åšæ³•æ˜¯æŠŠå¤±è´¥ä¿¡æ¯ offload åˆ°å¤–éƒ¨ trace æ–‡ä»¶ä¸­ï¼Œå†åœ¨åç»­å›é¡¾æˆ– summary é˜¶æ®µå¼•ç”¨
        - Context Offloading æ˜¯å°‘æ•°èƒ½ä»è®¤çŸ¥å±‚é¢ã€å·¥ç¨‹å±‚é¢ã€å¯æ‰©å±•æ€§å±‚é¢éƒ½é—­ç¯çš„è®¾è®¡ç­–ç•¥ã€‚
      - Isolate context
        - Split context across multi-agents (see: Drewâ€™s post, Anthropic).
        - But, be careful (see: Cognition/Walden Yan)!
        - Multi-agents make conflicting decisions (see: Cognition/Walden Yan).
        - Sub-agents lower risk if avoid decisions (see: open-deep-research).
      - Cache Context
        - Cached input tokens for Claude-sonnet 10x cheaper!
        - Cache agent instructions, tool descriptions to prefix.
        - Add mutable context / recent observations to suffix.
    - Codes https://github.com/langchain-ai/how_to_fix_your_context
  - [ä¸Šä¸‹æ–‡å·¥ç¨‹åŸç†](https://github.com/ForceInjection/AI-fundermentals/blob/main/context/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86.md)
  - [Why â€œContext Engineeringâ€ Matters](https://www.dbreunig.com/2025/07/24/why-the-term-context-engineering-matters.html)
  - [è–›å®šè°”çš„ç¼“å­˜](https://mp.weixin.qq.com/s/A0D4wF1yv3nC3wye5Hcb4g)
    - Go è¯­è¨€çš„ map éå†ç¡®å®æ˜¯éšæœºçš„ï¼Œä½†åœ¨å…¶æ ‡å‡†åº“è¿›è¡Œ JSON åºåˆ—åŒ–æ—¶ï¼Œå®ƒé»˜è®¤ä¼šå¯¹ map çš„é”®ï¼ˆkeyï¼‰åšä¸€æ¬¡æ’åº
    - Transformer æ¶æ„é‡‡ç”¨äº†ä¸€ç§æä¸ºé«˜æ•ˆçš„â€œçŠ¶æ€ä¼ é€’â€æœºåˆ¶ã€‚è¿™ä¸ªçŠ¶æ€ï¼Œå°±æ˜¯æˆ‘ä»¬å¸¸è¯´çš„ KV (Key-Value) å¯¹
      - é¢„å¡«å…… (Prefill) â€” è®¡ç®—åˆå§‹çŠ¶æ€
        - å½“æ¨¡å‹æ”¶åˆ°ä½ çš„ Prompt æ—¶ï¼Œå®ƒä¼šå¹¶è¡Œå¤„ç†æ‰€æœ‰è¾“å…¥çš„ Tokenï¼Œå¹¶ä¸ºæ¯ä¸€ä¸ª Token ç”Ÿæˆä¸€ç»„ K-V å‘é‡ã€‚è¿™äº› K-V å‘é‡å¯ä»¥è¢«çœ‹ä½œæ˜¯æ•´ä¸ªè¾“å…¥ Prompt åœ¨æ¨¡å‹å†…éƒ¨çš„â€œè®°å¿†å¿«ç…§â€æˆ–â€œåˆå§‹çŠ¶æ€â€
      - è§£ç  (Decoding) â€” å¢é‡æ›´æ–°çŠ¶æ€å¹¶ç”Ÿæˆ
    - åºåˆ—åŒ–çš„ç»å¯¹ç¡®å®šæ€§æ˜¯ç¼“å­˜çš„ç”Ÿå‘½çº¿
  - Claude Code çš„åšæ³•æ˜¯å¤§é“è‡³ç®€ï¼š
    - å½“å‰ä¼šè¯æ‰€æœ‰å†å²è®°å½•ä¿ç•™ï¼ˆ90%ä¸Šä¸‹æ–‡ä¹‹å‰ä¸ä¼šä¸»åŠ¨å‹ç¼©ï¼‰ï¼Œä¸å˜æ¢å·¥å…·åˆ—è¡¨ è¿™æ ·å¯ä»¥ä¿è¯ä¸Šä¸‹æ–‡ä¸å› ä¸ºå‹ç¼©æŸè€—ï¼Œä¸ä¿®æ”¹å†å²ä¼šè¯è®°å½•ä¹Ÿå¯ä»¥ç¡®ä¿å‘½ä¸­ Prompt Caching èŠ‚çº¦æˆæœ¬
    - é€šè¿‡å­ Agent ï¼ˆTask å·¥å…·ï¼‰ï¼Œæ—¢å¯ä»¥è®©å­ Agent çš„ä¸Šä¸‹æ–‡ç‹¬ç«‹å®Œæ•´ï¼Œåˆå¯ä»¥è®©ä¸» Agent çš„ä¸Šä¸‹æ–‡æ¸…æ™°ç®€æ´ã€‚ å°±åƒä¸€ä¸ªä¸“ä¸šçš„ç®¡ç†è€…ï¼Œè§„åˆ’å¥½åè®©ä¸‹å±å»å®Œæˆå„ç§å­ä»»åŠ¡ï¼Œè‡ªå·±èšç„¦äºä¸»ä»»åŠ¡
    - ç”¨ TODO å·¥å…·ï¼Œåšè®¡åˆ’ï¼Œå®æ—¶æ›´æ–°è¿›åº¦ï¼Œè®©æ‰§è¡Œè·¯å¾„æ¸…æ™°ï¼Œå¹¶å¯ä»¥è®© AI ä¸è¿·å¤±åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œèšç„¦äºè¦æ‰§è¡Œçš„ TODO List Item
  - [Deep agent](https://blog.langchain.com/deep-agents/)
    - A detailed system prompt
    - Planning tool
    - Sub agents
    - File system
    - https://github.com/hwchase17/deepagents
  - Context Engineering æ ¸å¿ƒæ˜¯ä¸¤ç‚¹ï¼š
    - æ›´å°‘çš„ä¸Šä¸‹æ–‡
      - æç¤ºè¯å¤ªé•¿ä¼šå½±å“ç”Ÿæˆç»“æœï¼Œäº§ç”Ÿå¹»è§‰ï¼Œå°¤å…¶æ˜¯å¤ªå¤šæ— å…³çš„å†…å®¹åœ¨ä¸Šä¸‹æ–‡æ›´ä¼šå¦‚æ­¤ã€‚
      - å¤šå¼€æ–°ä¼šè¯è€Œä¸æ˜¯åŒä¸€ä¸ªä¼šè¯ä¸€ç›´èŠ
        - å½“ä½ ä¼šè¯å¤ªé•¿ï¼Œåç»­ä½ å‘çš„å†…å®¹ï¼ŒAI ä¸å®¹æ˜“æŠ“ä½é‡ç‚¹ï¼Œå¯èƒ½ä¼šå¿˜è®°ä½ å‰é¢è¯´çš„ï¼Œæœ€å¥½æ˜¯åˆ°ä¸€å®šç¨‹åº¦ï¼Œè®© AI å¸®ä½ æ€»ç»“ä¸€ä¸‹é‡ç‚¹ï¼Œç„¶åæ–°å¼€ä¼šè¯ã€‚å¦‚æœæ˜¯å’Œå½“å‰ä¼šè¯æ— å…³çš„ä»»åŠ¡ï¼Œç›´æ¥æ–°å¼€ä¼šè¯ã€‚
      - ä¸€æ¬¡ä¸€ä¸ªå°çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯å¤ªå¤æ‚çš„ä»»åŠ¡
        - è¿™æœ‰ç‚¹åƒäººï¼Œå½“ä½ ä»»åŠ¡å¤ªå¤šå¤ªå¤æ‚ï¼ŒAI å¾ˆéš¾å®Œæˆå¥½ï¼Œä½†æ˜¯ä½ è®© AI ä¸€æ¬¡å®Œæˆä¸€ä¸ªå°ä»»åŠ¡ï¼Œå°±å¥½å¾ˆå¤šã€‚
    - æ›´å‡†ç¡®çš„ä¸Šä¸‹æ–‡
      - æˆ‘ä»¬æä¾›å‡†ç¡®å’Œå……è¶³çš„ä¸Šä¸‹æ–‡ç»™ AI
        - AI å¹¶ä¸çŸ¥é“æˆ‘ä»¬çŸ¥é“çš„ä¿¡æ¯ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸»åŠ¨å‘Šè¯‰AIæˆ‘ä»¬çŸ¥é“å®ƒä¸çŸ¥é“çš„ä¿¡æ¯ï¼Œæ¯”å¦‚è¯´è®©AIå¸®æˆ‘å†™ç®€å†ï¼Œé‚£æˆ‘å¾—æŠŠæˆ‘çš„ä¿¡æ¯éƒ½å‘Šè¯‰AIï¼Œä¸ç„¶å®ƒä¹Ÿå†™ä¸å‡ºæ¥ã€‚
        - ä½¿ç”¨AIå†™ä»£ç ï¼Œä¸€ä¸ªå®ç”¨çš„æŠ€å·§å°±æ˜¯æŠŠä½ çŸ¥é“çš„ç›¸å…³çš„æ–‡ä»¶éƒ½æä¾›ç»™å®ƒå‚è€ƒï¼Œè®©å®ƒå¯ä»¥è¯»åˆ°æ–‡ä»¶å†…å®¹ï¼Œè¿™æ ·å®ƒå°±ä¸ä¼šé—æ¼é‡è¦ä¿¡æ¯ã€‚
      - è®© AI å¸®æˆ‘ä»¬æ‰¾åˆ°ä¸Šä¸‹æ–‡
        - ç°åœ¨ AI Agent éƒ½æœ‰èƒ½åŠ›å¸®æˆ‘ä»¬æ‰¾ä¸Šä¸‹æ–‡ï¼Œä½†èƒ½åŠ›æœ‰å¥½ä¼˜åŒ–ï¼Œå¯¹äºæ™®é€šäººæ¥è¯´ï¼Œè¿™å‡ ç‚¹ç›´è§‚é‡è¦ï¼š
          - é€‰æ“…é•¿ Agent ä»»åŠ¡æ¨¡å‹ Claude 4 Opus/Sonnet, OpenAI o3 æ˜¯ Agent æ•ˆæœæœ€å¥½çš„
          - ä¸º AI æä¾›åˆé€‚çš„å·¥å…· Agent æœ€é‡è¦çš„å°±æ˜¯æœ‰å·¥å…·èƒ½åŠ›ï¼Œèƒ½å€ŸåŠ©å·¥å…·å»æ‰¾ä¸Šä¸‹æ–‡ï¼Œä½†æ˜¯å®ƒåªæœ‰å†…ç½®çš„å‡ ä¸ªå·¥å…·
          - è®© AI å…ˆåšè®¡åˆ’ï¼Œé¿å…åœ¨é”™è¯¯çš„æ–¹å‘è¶Šèµ°è¶Šè¿œ 
- [Redefining Document Retrieval with Vision-Language Models](https://zilliz.com/blog/colpali-milvus-redefine-document-retrieval-with-vision-language-models?utm_source=x)
  - ä¼ ç»Ÿæ£€ç´¢æµç¨‹ç—›ç‚¹ï¼š
    â€¢ éœ€è¦è¿›è¡Œ OCRã€å¸ƒå±€æ£€æµ‹ã€æ®µè½/è¡¨æ ¼è¯†åˆ«ã€æ–‡æœ¬åˆ‡åˆ†ä¸åµŒå…¥ç­‰è¯¸å¤šæ­¥éª¤ï¼Œæå…¶å¤æ‚ä¸”æ˜“å‡ºé”™ã€‚
    â€¢ è¡¨æ ¼ã€å›¾è¡¨ç­‰è§†è§‰ä¿¡æ¯å¾€å¾€ä¸¢å¤±ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆæœä¸ç†æƒ³ã€‚
  - ColPali çš„åˆ›æ–°åšæ³•ï¼š
    â€¢ é€šè¿‡å°† PDF ç­‰æ–‡æ¡£é¡µé¢ç›´æ¥è§†ä¸ºå›¾åƒè¾“å…¥ï¼Œå€ŸåŠ© vision-language æ¨¡å‹ï¼ˆPaliGemmaï¼‰åŒæ—¶è·å–è§†è§‰ä¸æ–‡æœ¬è¯­ä¹‰ã€‚
    â€¢ ç»“åˆå¤šå‘é‡è¡¨ç¤ºä¸ ColBERT çš„â€œæ™šæœŸäº¤äº’ï¼ˆlate interactionï¼‰â€ç­–ç•¥ï¼Œé’ˆå¯¹æŸ¥è¯¢ä¸­çš„æ¯ä¸ª token éƒ½èƒ½æ‰¾åˆ°æ–‡æ¡£ä¸­æœ€ç›¸ä¼¼çš„å›¾æ–‡ç‰‡æ®µå¹¶ç´¯åŠ ï¼Œæå‡åŒ¹é…ç²¾åº¦ã€‚
    â€¢ æ— éœ€ç¹ççš„ OCR æˆ–é¢å¤–çš„å¸ƒå±€åˆ†æï¼Œæ˜¾è‘—ç®€åŒ–å¤„ç†ç®¡çº¿ã€‚
- ğ—”ğ—´ğ—²ğ—»ğ˜ğ—¶ğ—° ğ—¥ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹
  - By integrating an agent into your retrieval process, you can move from static pipelines to dynamic, adaptive reasoning.
  - â€¢  The Smart Router: You can point the agent to multiple data collections (e.g., 'Products', 'UserReviews', 'SupportDocs').
     - When a query like "Recommend vintage clothes and nice shoes below $60â€ comes in, the query agent automatically understands it needs to query *multiple* collections.
  - â€¢  More than Just Retrieval: The query agent doesn't just do one thing. It analyzes the query and decides the best strategy.
    -  It sees "vintage clothes" and initiates a semantic search for similar concepts.
    -  It sees "below $60" and knows to apply a filtered aggregation or a metadata filter, a task that basic vector search alone cannot handle.
  - â€¢  The Final Synthesizer: It takes the results from its multi-step, multi-collection search, synthesizes them into a single, coherent context, and then generates a precise natural language answer using a generative model.
- 10 Principles of Building AI Agents:
  - 1. Donâ€™t Use Agents Just to Say You Did
    - Nobody cares if it's an AI agent or a simple script, as long as it works. If a good old if/else is faster, cheaper, and more reliable, use that. Save the agents for when you really need them.
  - 2. Small, Specialized, and Decoupled
    - Think "team of specialists," not "one agent to rule them all." A planner plans. A summarizer summarizes. A verifier checks. Decoupled agents are cheaper to run, easier to fix, and way more predictable.
  - 3. Enforce Structured Output
    - Freeform text is a mess to deal with. JSON gives you sanity. Itâ€™s easier to debug, cheaper to parse, and acts like a contract between agents. Bonus: you can validate it automatically and stop weird errors before they spread.
  - 4. Explain the Why, Not Just the What
    - When you give a task to an agent, donâ€™t just say â€œdo this.â€ Tell it why it matters and the context in which you need it. I've found that this helps agents make better decisions.
  - 5. Orchestration > Autonomy
    - Autonomy sounds great until an agent goes rogue in production. Move all business logic (if/then, loops, retries, error handling) out of agent prompts into the orchestration layer.
  - 6. Prompt Engineering > Fine Tuning
    - Before you jump to fine-tuning (and burn cash), pause. Ask: Why is the model failing?
    - If itâ€™s missing facts â†’ try RAG.
    - If itâ€™s formatting wrong or off-brand â†’ maybe fine-tune. But 80% of the time, itâ€™s just a prompt problem.
  - 7. Double Down on Tool Descriptions
    - Treat tool description as a micro-prompt that guides the agent's reasoning. Tell the agent when and why to use it, what to avoid, and include examples. Bonus: Descriptions provided by MCP servers are often insufficient. Also, consider explaining how to use multiple tools together.
  - 8. Cache Like You Mean It
    - If an agent runs the same task on the same data over and overâ€¦ stop paying for it each time. Cache responses (e.g., hash of agent ID + input) to reduce latency and API costs.
  - 9. Use Shared Artefacts
    - Agents shouldnâ€™t act like email users in the â€˜90s passing around files. Empower your agents to collaborate by co-editing shared docs, plans, or code.
  - 10. Log Everything (Seriously)
    - No logs = no learning. Track every move: inputs, outputs, retries, tool calls, agent thoughts. Add your own app-specific dimensions (e.g., customer type, use case). Then build funnels.
- RAG Summary
  - Naive RAG - LLM å®¹æ˜“â€œå¹»è§‰â€ï¼Œå‚æ•°åŒ–çŸ¥è¯†éš¾æ›´æ–°ï¼›éœ€å¤–éƒ¨æ£€ç´¢è¡¥å……çŸ¥è¯†å¹¶æä¾›å¯è¿½æº¯çš„è¯æ®ã€‚
    - ä¸‰æ­¥æµç¨‹ï¼šæ–‡æ¡£åˆ‡å— â†’ å‘é‡æ£€ç´¢ â†’ æ‹¼æ¥æç¤ºç”Ÿæˆ
    - ä¸€ä½“åŒ–ç«¯åˆ°ç«¯å¾®è°ƒï¼ˆRAG-Sequence & RAG-Tokenï¼‰
    - å‡å°‘å‚æ•°åŒ–æ¨¡å‹çš„å¹»è§‰ï¼Œæå‡å¼€æ”¾åŸŸ QA å‡†ç¡®ç‡
  - Advanced RAG - ç”¨æˆ·æŸ¥è¯¢ä¸çŸ¥è¯†åº“è¯­ä¹‰ä¸å¯¹é½ï¼›Naive RAG æ£€ç´¢å™ªå£°å¤šã€ç”Ÿæˆè´¨é‡æœ‰é™ã€‚
    - é¢„æ£€ç´¢(Pre Retrieval)ï¼šæŸ¥è¯¢é‡å†™/æ‰©å±• (Rewrite)
    - æ£€ç´¢(Retrieval)ï¼šè¯­ä¹‰å‘é‡æ£€ç´¢
    - åæ£€ç´¢(Post Retrieval)ï¼šç»“æœé‡æ’åºã€æ‘˜è¦å‹ç¼©
  - Modular RAG - éšç€æ£€ç´¢å™¨ã€LLM ç­‰ç»„ä»¶é£é€Ÿè¿­ä»£ï¼Œä¼ ç»Ÿç®¡é“éš¾å¿«é€Ÿé›†æˆæ–°åŠŸèƒ½ã€ç»´æŠ¤æˆæœ¬é«˜ã€‚
    - ä¸ƒå¤§æ¨¡å—: Indexing, Pre Retrieval, Retrievel, Post Retrievel, Memory, Generation, Orchestration
    - å°†æ£€ç´¢ã€é‡æ’åºã€å‹ç¼©ã€ç”Ÿæˆç­‰æ‹†åˆ†ä¸ºå¯æ’æ‹”æ¨¡å—
    - å¼•å…¥è·¯ç”±ã€è°ƒåº¦ã€èåˆç®—å­
    - æ¨¡å—åŒ–è®¾è®¡ï¼Œçµæ´»æ‰©å±•ï¼Œæ”¯æŒå¤šç§ RAG æ¨¡å¼ï¼ˆçº¿æ€§ã€æ¡ä»¶ã€åˆ†æ”¯ã€å¾ªç¯ï¼‰
  - Agentic RAG - éœ€å¤„ç†å¤æ‚å¤šæ­¥ä»»åŠ¡ã€å¤šè½®å†³ç­–ï¼Œå•è½®é™æ€æµç¨‹ä¸å¤Ÿï¼›å¸Œæœ›ç»“åˆæ£€ç´¢ä¸è§„åˆ’èƒ½åŠ›ã€‚
    - å¤šæ™ºèƒ½ä½“æ¶æ„ï¼šä¸»æ™ºèƒ½ä½“åè°ƒå­æ™ºèƒ½ä½“
    - åŠ¨æ€å†³ç­–ï¼šè‡ªä¸»åˆ¤æ–­ä½•æ—¶æ£€ç´¢ã€ä½•æ—¶ç”Ÿæˆ
    - æ”¯æŒå¤šè½®è¿­ä»£ã€ä»»åŠ¡è‡ªæ ¡æ­£ï¼Œæé«˜å¤æ‚ä»»åŠ¡çš„é€‚åº”æ€§ä¸é²æ£’æ€§
- [AIæ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼šManusçš„æ„å»ºå¿ƒå¾—](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)
  - ä¸è‡ªå·±è®­ç»ƒæ¨¡å‹ï¼Œä¾èµ–ä¸Šä¸‹æ–‡å·¥ç¨‹æ¥æ„é€ è®°å¿†å’Œæµç¨‹
  - æå‡ Prompt ç¼“å­˜å‘½ä¸­ç‡ ç°åœ¨ä¸»æµ LLM éƒ½æä¾›äº† Prompt Caching
    - æé«˜ KV ç¼“å­˜å‘½ä¸­ç‡ æŠŠç¼“å­˜å‘½ä¸­ç‡å½“ä½œæ ¸å¿ƒä¼˜åŒ–æŒ‡æ ‡ï¼Œå“ªæ€•ä¸ºæ­¤ç‰ºç‰² prompt çµæ´»æ€§éƒ½åœ¨æ‰€ä¸æƒœã€‚
      - ä¿æŒæç¤ºå‰ç¼€çš„ç¨³å®šæ€§ã€‚ç”±äºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªå›å½’ç‰¹æ€§ï¼Œå“ªæ€•åªæœ‰ä¸€ä¸ªä»¤ç‰Œçš„å·®å¼‚ï¼Œä¹Ÿä¼šå¯¼è‡´ä»è¯¥ä»¤ç‰Œå¼€å§‹çš„åç»­ç¼“å­˜å…¨éƒ¨å¤±æ•ˆ
      - è®©ä¸Šä¸‹æ–‡åªå¢ä¸å‡ã€‚é¿å…ä¿®æ”¹ä¹‹å‰çš„åŠ¨ä½œæˆ–è§‚å¯Ÿç»“æœã€‚ç¡®ä¿åºåˆ—åŒ–è¿‡ç¨‹æ˜¯ç¡®å®šæ€§çš„
      - åœ¨éœ€è¦æ—¶æ˜ç¡®æ ‡è®°ç¼“å­˜æ–­ç‚¹ã€‚ä¸€äº›æ¨¡å‹æä¾›å•†æˆ–æ¨ç†æ¡†æ¶ä¸æ”¯æŒè‡ªåŠ¨å¢é‡å‰ç¼€ç¼“å­˜ï¼Œè€Œæ˜¯éœ€è¦æ‰‹åŠ¨åœ¨ä¸Šä¸‹æ–‡ä¸­æ’å…¥ç¼“å­˜æ–­ç‚¹ã€‚
  - ä¸åŠ¨æ€ä¿®æ”¹å·¥å…·åˆ—è¡¨
    - ä¸»è¦åŸå› ä¹Ÿæ˜¯å› ä¸º Prompt Cachingï¼Œé€šå¸¸å·¥å…·éƒ½æ˜¯å®šä¹‰åœ¨System Messageï¼Œä½ ä¿®æ”¹äº†å°±ä¼šå¯¼è‡´ Prompt å‰é¢å˜äº†æ²¡æ³• Cache äº†ã€‚å¦å¤–å·¥å…·ä¸€ç›´åœ¨å˜ä¹Ÿæ›´å®¹æ˜“å¯¼è‡´å¹»è§‰ã€‚
    - é™¤éç»å¯¹å¿…è¦ï¼Œå¦åˆ™é¿å…åœ¨è¿­ä»£ä¸­é€”åŠ¨æ€æ·»åŠ æˆ–ç§»é™¤å·¥å…·ã€‚è¿™ä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼š
      - åœ¨å¤§å¤šæ•°å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼Œå·¥å…·å®šä¹‰ç»è¿‡åºåˆ—åŒ–åä½äºä¸Šä¸‹æ–‡çš„å‰éƒ¨ï¼Œé€šå¸¸åœ¨ç³»ç»Ÿæç¤ºä¹‹å‰æˆ–ä¹‹åã€‚å› æ­¤ï¼Œä»»ä½•æ”¹åŠ¨éƒ½ä¼šä½¿åç»­æ‰€æœ‰åŠ¨ä½œå’Œè§‚å¯Ÿç»“æœçš„ KV ç¼“å­˜å¤±æ•ˆã€‚
      - å½“ä¹‹å‰çš„åŠ¨ä½œå’Œè§‚å¯Ÿç»“æœä»ç„¶å¼•ç”¨å½“å‰ä¸Šä¸‹æ–‡ä¸­å·²ä¸å†å®šä¹‰çš„å·¥å…·æ—¶ï¼Œæ¨¡å‹ä¼šæ„Ÿåˆ°å›°æƒ‘ã€‚å¦‚æœä¸ä½¿ç”¨çº¦æŸè§£ç ï¼Œè¿™é€šå¸¸ä¼šå¯¼è‡´æ¨¡å¼ï¼ˆschemaï¼‰è¿è§„æˆ–å¹»è§‰å‡ºä¸å­˜åœ¨çš„åŠ¨ä½œã€‚
    - Manus ä½¿ç”¨äº†ä¸€ä¸ªèƒ½å¤Ÿæ„ŸçŸ¥ä¸Šä¸‹æ–‡çš„çŠ¶æ€æœºæ¥ç®¡ç†å·¥å…·çš„å¯ç”¨æ€§ã€‚å®ƒä¸æ˜¯ç§»é™¤å·¥å…·ï¼Œè€Œæ˜¯åœ¨è§£ç æ—¶é€šè¿‡æ©ç›–ä»¤ç‰Œçš„å¯¹æ•°å‡ ç‡ï¼ˆlogitsï¼‰æ¥é˜»æ­¢ï¼ˆæˆ–å¼ºåˆ¶ï¼‰æ ¹æ®å½“å‰ä¸Šä¸‹æ–‡é€‰æ‹©æŸäº›åŠ¨ä½œã€‚
    - å¤§å¤šæ•°æ¨¡å‹æä¾›å•†å’Œæ¨ç†æ¡†æ¶éƒ½æ”¯æŒæŸç§å½¢å¼çš„å“åº”é¢„å¡«å……ï¼Œè¿™å…è®¸ä½ åœ¨ä¸ä¿®æ”¹å·¥å…·å®šä¹‰çš„æƒ…å†µä¸‹çº¦æŸåŠ¨ä½œç©ºé—´ã€‚å‡½æ•°è°ƒç”¨é€šå¸¸æœ‰ä¸‰ç§æ¨¡å¼ NousResearch çš„ Hermes æ ¼å¼
      - è‡ªåŠ¨ (Auto) â€“ æ¨¡å‹å¯ä»¥é€‰æ‹©è°ƒç”¨å‡½æ•°ï¼Œä¹Ÿå¯ä»¥ä¸è°ƒç”¨ã€‚é€šè¿‡ä»…é¢„å¡«å……å›å¤å‰ç¼€æ¥å®ç°ï¼š<|im_start|>assistant
      - å¿…éœ€ (Required) â€“ æ¨¡å‹å¿…é¡»è°ƒç”¨ä¸€ä¸ªå‡½æ•°ï¼Œä½†å…·ä½“è°ƒç”¨å“ªä¸ªä¸å—é™åˆ¶ã€‚é€šè¿‡é¢„å¡«å……åˆ°å·¥å…·è°ƒç”¨ä»¤ç‰Œæ¥å®ç°ï¼š<|im_start|>assistant<tool_call>
      - æŒ‡å®š (Specified) â€“ æ¨¡å‹å¿…é¡»ä»ä¸€ä¸ªç‰¹å®šçš„å­é›†ä¸­è°ƒç”¨å‡½æ•°ã€‚é€šè¿‡é¢„å¡«å……åˆ°å‡½æ•°åçš„å¼€å¤´æ¥å®ç°ï¼š<|im_start|>assistant<tool_call>{"name": "browser_
    - æˆ‘ä»¬è¿˜æœ‰æ„åœ°å°†åŠ¨ä½œåç§°è®¾è®¡æˆå…·æœ‰ä¸€è‡´çš„å‰ç¼€â€”â€”ä¾‹å¦‚ï¼Œæ‰€æœ‰æµè§ˆå™¨ç›¸å…³çš„å·¥å…·éƒ½ä»¥ browser_ å¼€å¤´ï¼Œå‘½ä»¤è¡Œå·¥å…·åˆ™ä»¥ shell_ å¼€å¤´ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè½»æ¾åœ°åœ¨ç‰¹å®šçŠ¶æ€ä¸‹å¼ºåˆ¶ä»£ç†åªä»æŸä¸€ç»„å·¥å…·ä¸­è¿›è¡Œé€‰æ‹©
  - å°†æ–‡ä»¶ç³»ç»Ÿä½œä¸ºä¸Šä¸‹æ–‡
    - å°†æ–‡ä»¶ç³»ç»Ÿè§†ä¸ºç»ˆæä¸Šä¸‹æ–‡ï¼šå®ƒçš„å¤§å°æ— é™ï¼Œæœ¬è´¨ä¸Šæ˜¯æŒä¹…çš„ï¼Œå¹¶ä¸”å¯ç”±æ™ºèƒ½ä»£ç†ç›´æ¥æ“ä½œã€‚
    - æ¨¡å‹å­¦ä¼šäº†æŒ‰éœ€è¯»å†™æ–‡ä»¶â€”â€”ä¸ä»…ä»…æ˜¯å°†æ–‡ä»¶ç³»ç»Ÿç”¨ä½œå­˜å‚¨ï¼Œè€Œæ˜¯å°†å…¶ä½œä¸ºç»“æ„åŒ–çš„å¤–éƒ¨åŒ–è®°å¿†ã€‚
  - é€šè¿‡å¤è¿°æ“æ§æ³¨æ„åŠ›
    - å¦‚æœä½ ç”¨è¿‡ Manus æˆ–è€… Claude Codeï¼Œå°±ä¼šæ³¨æ„åˆ°å®ƒä»¬åœ¨æ‰§è¡Œå¤æ‚ä»»åŠ¡çš„æ—¶å€™ï¼Œæ¯ä¸€æ­¥éƒ½ä¼šå†™å…¥ä¸€ä¸ª ToDo Listï¼Œå®Œæˆäº†å“ªäº›ä»»åŠ¡ï¼Œæ¥ä¸‹æ¥è¦åšä»€ä¹ˆäº‹æƒ…
    - å®ƒæ˜¯ä¸€ç§æœ‰æ„ä¸ºä¹‹çš„æ“æ§æ³¨æ„åŠ›çš„æœºåˆ¶
    - Manus æ­£åœ¨å°†å®ƒçš„ç›®æ ‡â€œå¤è¿°â€åˆ°ä¸Šä¸‹æ–‡çš„æœ«å°¾ã€‚è¿™å°†å…¨å±€è®¡åˆ’æ¨å…¥æ¨¡å‹çš„è¿‘æœŸæ³¨æ„åŠ›èŒƒå›´ï¼Œé¿å…äº†â€œä¸­é—´é—å¿˜â€ï¼ˆlost-in-the-middleï¼‰é—®é¢˜ï¼Œå¹¶å‡å°‘äº†ç›®æ ‡åç¦»
  - ä¿ç•™é”™è¯¯çš„å†…å®¹
    - LLM ä¼šäº§ç”Ÿå¹»è§‰ï¼Œå°±ç®—10æ¬¡é‡Œé¢9æ¬¡éƒ½æ˜¯å¯¹çš„ï¼Œåªæœ‰1æ¬¡æ˜¯é”™çš„ï¼Œè¿™äº›é”™è¯¯ç´¯åŠ èµ·æ¥ä¹Ÿæ˜¯å¾ˆå¤šçš„ï¼Œæ‰€ä»¥å®ƒéœ€è¦æœ‰çº é”™æœºåˆ¶ï¼Œæœ€ç®€å•çš„æ–¹å¼å°±æ˜¯è®©å®ƒé‡è¯•
    - å°†èµ°é”™çš„å¼¯è·¯ä¿ç•™åœ¨ä¸Šä¸‹æ–‡ä¸­ã€‚å½“æ¨¡å‹çœ‹åˆ°ä¸€ä¸ªå¤±è´¥çš„åŠ¨ä½œâ€”â€”ä»¥åŠç”±æ­¤äº§ç”Ÿçš„è§‚å¯Ÿç»“æœæˆ–å †æ ˆè·Ÿè¸ªâ€”â€”å®ƒä¼šå«è“„åœ°æ›´æ–°å…¶å†…éƒ¨è®¤çŸ¥ã€‚è¿™ä¼šä½¿å…¶å…ˆéªŒæ¦‚ç‡åç¦»ç±»ä¼¼çš„æ“ä½œï¼Œä»è€Œå‡å°‘é‡å¤åŒæ ·é”™è¯¯çš„æœºä¼šã€‚
  - è­¦æƒ•â€œå°‘æ ·æœ¬å­¦ä¹ â€é™·é˜±
    - å°‘æ ·æœ¬æ˜¯å¾ˆæœ‰ç”¨çš„æç¤ºè¯æŠ€å·§ï¼Œä¹Ÿå°±æ˜¯ä½ åœ¨æç¤ºè¯ä¸­å¯ä»¥åŠ å…¥ä¸€äº›æç¤ºè¯ç¤ºä¾‹ï¼Œè®©å®ƒå¯ä»¥æ‰¾è‘«èŠ¦ç”»ç“¢ã€‚
    - few-shot prompting åœ¨å¾ˆå¤šä»»åŠ¡ä¸­éå¸¸å¥½ç”¨ï¼Œä½†åœ¨å¤šè½®ã€åŠ¨æ€ä»»åŠ¡ä¸­ï¼Œå¦‚æœä½ ç»™çš„ç¤ºä¾‹å¤ªç›¸ä¼¼ã€ç»“æ„å¤ªå›ºå®šï¼Œæ¨¡å‹å¾ˆå®¹æ˜“é™·å…¥â€œæ¨¡å¼ä¾èµ–â€ï¼Œå˜æˆâ€œç…§æ¬æœºå™¨â€
    - è§£å†³æ–¹æ³•æ˜¯å¢åŠ å¤šæ ·æ€§ã€‚Manus åœ¨åŠ¨ä½œå’Œè§‚å¯Ÿç»“æœä¸­å¼•å…¥äº†å°‘é‡çš„ç»“æ„åŒ–å˜ä½“â€”â€”ä¸åŒçš„åºåˆ—åŒ–æ¨¡æ¿ã€æ›¿ä»£æ€§çš„æªè¾ã€é¡ºåºæˆ–æ ¼å¼ä¸Šçš„å¾®å°å™ªéŸ³
      - åœ¨æ™ºèƒ½ä½“çš„åŠ¨ä½œå’Œè§‚å¯Ÿä¸­ï¼Œæœ‰æ„è¯†åœ°å¼•å…¥å°‘é‡ä½†ç»“æ„åŒ–çš„å˜ä½“ï¼Œç»™çš„ç¤ºä¾‹è¯­ä¹‰ä¸€è‡´ä½†è¡¨è¾¾æ–¹å¼ä¸åŒã€‚é€šè¿‡æ‰“ç ´ä¸€æˆä¸å˜çš„æ¨¡å¼ï¼Œæœ‰æ•ˆåœ°ä½¿æ¨¡å‹çš„æ³¨æ„åŠ›å¤šæ ·åŒ–
  - Summary
    - åš AI åº”ç”¨å¼€å‘ï¼ŒPrompt Caching æ˜¯å¿…é¡»è¦è€ƒè™‘çš„é‡è¦å› ç´ ï¼Œåˆ‡è®°ï¼
    - ä¸Šä¸‹æ–‡ä¸­æœ€å®è´µçš„ä½ç½®æ˜¯å¼€å¤´å’Œç»“å°¾ï¼Œé‡è¦çš„ä¿¡æ¯è¦æ”¾åœ¨æœ€å¼€å¤´æˆ–è€…æœ€åï¼Œé•¿æ—¶é—´çš„ä»»åŠ¡è¦åœ¨æ¯ä¸ªå°ä»»åŠ¡ç»“æŸåå¤è¿° TODO Listã€‚
    - ä¸€äº›å¾ˆé•¿çš„å†…å®¹å¯ä»¥æ”¾åˆ°å¤–éƒ¨æ–‡ä»¶ä¸­ï¼Œéœ€è¦æ—¶å†è¯»å–
    - é€šè¿‡é¢„å¡«å……å›å¤å†…å®¹å¯ä»¥å¼•å¯¼ LLM å®Œæˆä»»åŠ¡ï¼Œè°ƒç”¨æˆ–å±è”½ç‰¹å®šå·¥å…·
    - å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯å¯ä»¥ LLM çº æ­£é”™è¯¯
    - è¦é¿å… AI å—åˆ°åŒè´¨åŒ–çš„å†å²æ¶ˆæ¯å½±å“åç»­ç»“æœ
  - https://mp.weixin.qq.com/s/5DQOnDausramvMZJUvPVVA
- Agent çš„çœŸæ­£éš¾åº¦ï¼Œåœ¨äºèƒ½ä¸èƒ½è®©å®ƒåœ¨ç¨³å®šã€è¿ç»­çš„å‰æä¸‹ï¼Œæ”¯æ’‘èµ·çœŸå®ä¸šåŠ¡æµç¨‹çš„æ­£ç¡®æ€§ã€å¯è¿½æº¯æ€§ã€å¯æ§æ€§
  - è®¾è®¡æ¨¡å¼ç†è§£ä¸é€‰æ‹©èƒ½åŠ›
    - æ˜¯å¦èƒ½åŒºåˆ†å¹¶è®²æ¸… ReAct / CodeAct / Agentic RAG / Self-Reflection ç­‰æ¨¡å¼çš„æ¨ç†æ–¹å¼ã€æ§åˆ¶é€»è¾‘ä¸é€‚ç”¨åœºæ™¯ï¼Ÿ
  - å¤š Agent åä½œæœºåˆ¶
    - æ˜¯å¦è®¾è®¡è¿‡å¤šæ™ºèƒ½ä½“ä¹‹é—´çš„ä»»åŠ¡åˆ†é…ã€çŠ¶æ€éš”ç¦»ã€ç»“æœåˆå¹¶ä¸å†²çªå¤„ç†ï¼Ÿæ˜¯å¦ç†è§£ planner-subagent ç»“æ„çš„è¿è¡Œç»†èŠ‚ï¼Ÿ
  - ä¸Šä¸‹æ–‡ä¸è®°å¿†æ¶æ„è®¾è®¡ 
    - memory æ˜¯ä¸´æ—¶è¡¥å…¨è¿˜æ˜¯é•¿æœŸè¯­ä¹‰è®°å¿†ï¼Ÿå¦‚ä½•æ§åˆ¶å†™å…¥/æ¸…ç†ï¼Ÿæ˜¯å¦äº†è§£ agentic memory / KV memory ç­‰æ–°å‹ç»„ç»‡æ–¹å¼ï¼Ÿ
  - å·¥å…·è°ƒç”¨ä¸ API æ³¨å…¥æœºåˆ¶ 
    - æ˜¯å¦è®¾è®¡è¿‡å·¥å…·çš„åŠ¨æ€æ³¨å†Œï¼Ÿå¦‚ä½•è§£æ schemaï¼Ÿæ˜¯å¦æ”¯æŒå·¥å…·é€‰æ‹©ã€å‚æ•°å¯¹é½ã€è°ƒç”¨ fallbackï¼Ÿèƒ½å¦æŠ½è±¡å‡ºç»Ÿä¸€å·¥å…·æ‰§è¡Œæ¥å£ï¼Ÿ
  - æ§åˆ¶æµä¸è°ƒåº¦èƒ½åŠ› 
    - æ˜¯å¦å…·å¤‡ DAG å·¥ä½œæµè®¾è®¡èƒ½åŠ›ï¼Ÿä»»åŠ¡èƒ½å¦å¹‚ç­‰æ‰§è¡Œï¼Ÿæ˜¯å¦æ”¯æŒå¤±è´¥å›æ»šã€ä¼˜å…ˆçº§è°ƒåº¦ã€å¼‚æ­¥ååŒç­‰æœºåˆ¶ï¼Ÿ
  - æ€§èƒ½ä¸ç³»ç»Ÿç›‘æ§èƒ½åŠ› 
    - æ˜¯å¦è¯„ä¼°è¿‡ Agent çš„å“åº”å»¶è¿Ÿã€token æˆæœ¬ã€memory æ£€ç´¢æ•ˆç‡ï¼Ÿæ˜¯å¦ä½¿ç”¨ tracing / caching / LangSmith / PromptLayer ç­‰å·¥å…·è¿›è¡Œä¼˜åŒ–ï¼Ÿ
  - å®‰å…¨æ€§ä¸åˆè§„æ„è¯† 
    - æ˜¯å¦è®¾è®¡è¿‡æƒé™è¾¹ç•Œï¼Ÿæ˜¯å¦è€ƒè™‘ prompt æ³¨å…¥ã€æ•°æ®è¶Šæƒã€æ•æ„Ÿä¿¡æ¯ä¿æŠ¤ï¼ŸAgent æ—¥å¿—æ˜¯å¦æ”¯æŒå®¡è®¡ä¸åˆè§„å›æº¯ï¼Ÿ
  - æ¡†æ¶é€‰å‹ä¸æŠ½è±¡èƒ½åŠ› 
    - æ˜¯å¦èƒ½æ¯”è¾ƒ LangGraphã€CrewAI ç­‰ä¸»æµå¼€æºæ¡†æ¶åœ¨è°ƒåº¦æœºåˆ¶ã€æ‰©å±•æ€§ã€åä½œæ¨¡å‹ä¸Šçš„é€‚é…è¾¹ç•Œï¼Ÿæ˜¯å¦å…·å¤‡åœ¨å…¶ä¹‹ä¸Šæ„å»ºæŠ½è±¡å±‚æˆ–æ¥å£é€‚é…èƒ½åŠ›ï¼Ÿæ˜¯å¦ç†è§£ Manus ç­‰é—­æºç³»ç»Ÿçš„æ¶æ„ç†å¿µï¼Œèƒ½å¦ä»ä¸­æç‚¼å‡ºå¯è¿ç§»çš„ä¸Šä¸‹æ–‡ç»“æ„å’Œæ§åˆ¶æµæ€è·¯ï¼Œä¸å¼€æºç³»ç»Ÿå½¢æˆå¯¹æ¯”ï¼Ÿ










